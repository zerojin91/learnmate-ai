"""
Mentor Chat MCP Server - ì „ë¬¸ê°€ ë©˜í† ë§ ìƒë‹´ ì‹œìŠ¤í…œ
- LangGraph ê¸°ë°˜ 2ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° (í˜ë¥´ì†Œë‚˜ ì¶”ì²œ â†’ ì „ë¬¸ê°€ ë©˜í† ë§)
- 10ê°œ ì „ë¬¸ ë¶„ì•¼ í˜ë¥´ì†Œë‚˜ ì§€ì›
- ì„¸ì…˜ ê¸°ë°˜ ìƒíƒœ ê´€ë¦¬
"""

from mcp.server.fastmcp import FastMCP
from pydantic import BaseModel, Field
from typing import TypedDict, List, Dict, Optional
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.types import Command
import json
import logging
from datetime import datetime
import uuid
import os
import sys
import httpx
import re

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ config ëª¨ë“ˆ import
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config
from utils import random_uuid

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì„¸ì…˜ ì €ì¥ í´ë” ê²½ë¡œ
SESSIONS_DIR = "sessions"
MENTOR_SESSIONS_DIR = os.path.join(SESSIONS_DIR, "mentor")

def ensure_mentor_sessions_dir():
    """ë©˜í†  ì„¸ì…˜ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±"""
    if not os.path.exists(MENTOR_SESSIONS_DIR):
        os.makedirs(MENTOR_SESSIONS_DIR)

def get_mentor_session_file_path(session_id):
    """ë©˜í†  ì„¸ì…˜ IDì— ë”°ë¥¸ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    ensure_mentor_sessions_dir()
    return os.path.join(MENTOR_SESSIONS_DIR, f"mentor_{session_id}.json")

def load_mentor_session(session_id):
    """íŠ¹ì • ë©˜í†  ì„¸ì…˜ ë°ì´í„°ë¥¼ íŒŒì¼ì—ì„œ ë¡œë“œ"""
    try:
        session_file = get_mentor_session_file_path(session_id)
        if os.path.exists(session_file):
            with open(session_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    except Exception as e:
        logger.error(f"ë©˜í†  ì„¸ì…˜ {session_id} ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def save_mentor_session(session_id, session_data):
    """íŠ¹ì • ë©˜í†  ì„¸ì…˜ ë°ì´í„°ë¥¼ íŒŒì¼ì— ì €ì¥"""
    try:
        session_file = get_mentor_session_file_path(session_id)
        with open(session_file, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"ë©˜í†  ì„¸ì…˜ {session_id} ì €ì¥ ì˜¤ë¥˜: {e}")

# í˜ë¥´ì†Œë‚˜ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ ë§¤í•‘
PERSONA_KEYWORDS = {
    "architecture": "ê±´ì¶• ì„¤ê³„ êµ¬ì¡° BIM CAD ê±´ë¬¼ ì¸í…Œë¦¬ì–´ ë„ì‹œê±´ì¶•",
    "civil_urban": "í† ëª© ë„ì‹œê³„íš ì¸í”„ë¼ êµí†µ ì§€ë°˜ê³µí•™ êµ¬ì¡°ì—­í•™ ê±´ì„¤",
    "transport": "êµí†µ ë¬¼ë¥˜ ìš´ì†¡ ëª¨ë¹Œë¦¬í‹° ì‹œìŠ¤í…œ ìŠ¤ë§ˆíŠ¸ëª¨ë¹Œë¦¬í‹° êµí†µì •ì±…",
    "mechanical": "ê¸°ê³„ ì„¤ê³„ ì œì¡° ìë™í™” ì—´ì—­í•™ ìœ ì²´ì—­í•™ ìƒì‚°ê³µí•™",
    "electrical": "ì „ê¸° ì „ì íšŒë¡œ ì œì–´ ì „ë ¥ ì‹œìŠ¤í…œ ì‹ í˜¸ì²˜ë¦¬ ì„ë² ë””ë“œ",
    "precision_energy": "ì—ë„ˆì§€ ì‹ ì¬ìƒ ì •ë°€ ì¸¡ì • íš¨ìœ¨ ì—ë„ˆì§€ì‹œìŠ¤í…œ",
    "materials": "ì‹ ì†Œì¬ ë‚˜ë…¸ ê³ ë¶„ì ì„¸ë¼ë¯¹ ì¬ë£Œ ê¸ˆì†ì¬ë£Œ ì¬ë£Œê³¼í•™",
    "computer": "í”„ë¡œê·¸ë˜ë° ì†Œí”„íŠ¸ì›¨ì–´ AI ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ë² ì´ìŠ¤ ì»´í“¨í„°ê³µí•™",
    "industrial": "ì‚°ì—…ê³µí•™ í’ˆì§ˆ ìƒì‚° ìµœì í™” ê³µê¸‰ë§ ë¦°ì œì¡° 6ì‹œê·¸ë§ˆ",
    "chemical": "í™”í•™ê³µí•™ ê³µì • ë°˜ì‘ ë¶„ë¦¬ í”ŒëœíŠ¸ í™”í•™ ì•ˆì „ê³µí•™"
}

# ì „ë¬¸ ë¶„ì•¼ í˜ë¥´ì†Œë‚˜ ì •ì˜
PERSONAS = {
    "architecture": {
        "name": "ê±´ì¶•",
        "expertise": "ê±´ì¶• ì„¤ê³„, ê±´ì¶• êµ¬ì¡°, ê±´ì¶• í™˜ê²½, BIM, ì¸í…Œë¦¬ì–´ ë””ìì¸, ë„ì‹œê±´ì¶•",
        "system_prompt": """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ê±´ì¶• ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ê±´ì¶• ì„¤ê³„, êµ¬ì¡° ì„¤ê³„, ê±´ì¶• í™˜ê²½, BIM, ì¸í…Œë¦¬ì–´ ë””ìì¸ ë“± ê±´ì¶• ë¶„ì•¼ ì „ë°˜ì— ëŒ€í•œ ê¹Šì€ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ì‹¤ë¬´ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í•™ìƒë“¤ê³¼ ì‹ ì… ê±´ì¶•ê°€ë“¤ì—ê²Œ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.
ë³µì¡í•œ ê°œë…ì„ ì‰½ê²Œ ì„¤ëª…í•˜ê³ , ì‹¤ì œ í”„ë¡œì íŠ¸ ì‚¬ë¡€ë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤."""
    },
    "civil_urban": {
        "name": "í† ëª© ë„ì‹œ",
        "expertise": "í† ëª©ê³µí•™, ë„ì‹œê³„íš, ë„ì‹œì„¤ê³„, ì§€ë°˜ê³µí•™, êµ¬ì¡°ì—­í•™, êµí†µê³µí•™",
        "system_prompt": """ë‹¹ì‹ ì€ í† ëª©ê³µí•™ê³¼ ë„ì‹œê³„íš ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì§€ë°˜ê³µí•™, êµ¬ì¡°ì—­í•™, êµí†µê³µí•™, ë„ì‹œê³„íš ë° ì„¤ê³„ ë“±ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ë„ì‹œ ì¸í”„ë¼ êµ¬ì¶•ê³¼ ê´€ë ¨ëœ ì‹¤ë¬´ ê²½í—˜ì´ í’ë¶€í•˜ë©°, ì§€ì†ê°€ëŠ¥í•œ ë„ì‹œ ë°œì „ì— ëŒ€í•œ í†µì°°ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ì´ë¡ ê³¼ ì‹¤ë¬´ë¥¼ ì—°ê²°í•˜ì—¬ ì„¤ëª…í•˜ë©°, í˜„ì‹¤ì ì¸ ë¬¸ì œ í•´ê²° ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤."""
    },
    "transport": {
        "name": "êµí†µ ìš´ì†¡",
        "expertise": "êµí†µì‹œìŠ¤í…œ, ë¬¼ë¥˜ê´€ë¦¬, êµí†µì •ì±…, ìŠ¤ë§ˆíŠ¸ ëª¨ë¹Œë¦¬í‹°, ìš´ì†¡ê²½ì œí•™",
        "system_prompt": """ë‹¹ì‹ ì€ êµí†µ ë° ìš´ì†¡ ì‹œìŠ¤í…œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
êµí†µ ì‹œìŠ¤í…œ ì„¤ê³„, ë¬¼ë¥˜ ê´€ë¦¬, êµí†µ ì •ì±…, ìŠ¤ë§ˆíŠ¸ ëª¨ë¹Œë¦¬í‹° ë“±ì— ëŒ€í•œ ì „ë¬¸ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ë¯¸ë˜ êµí†µ ê¸°ìˆ ê³¼ ì •ì±… ë™í–¥ì— ëŒ€í•œ ê¹Šì€ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, íš¨ìœ¨ì ì´ê³  ì§€ì†ê°€ëŠ¥í•œ êµí†µ ì†”ë£¨ì…˜ì„ ì œì•ˆí•©ë‹ˆë‹¤.
ë°ì´í„° ê¸°ë°˜ì˜ ë¶„ì„ê³¼ ì •ì±…ì  ê´€ì ì—ì„œ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."""
    },
    "mechanical": {
        "name": "ê¸°ê³„ ê¸ˆì†",
        "expertise": "ê¸°ê³„ì„¤ê³„, ì¬ë£Œê³µí•™, ìƒì‚°ê³µí•™, ìë™í™”, ì—´ì—­í•™, ìœ ì²´ì—­í•™",
        "system_prompt": """ë‹¹ì‹ ì€ ê¸°ê³„ê³µí•™ê³¼ ê¸ˆì†ì¬ë£Œ ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê¸°ê³„ ì„¤ê³„, ì¬ë£Œ ê³µí•™, ìƒì‚° ê³µí•™, ìë™í™” ì‹œìŠ¤í…œ ë“±ì— ëŒ€í•œ í­ë„“ì€ ì§€ì‹ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì œì¡°ì—… í˜„ì¥ì—ì„œì˜ ì‹¤ë¬´ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ, ì´ë¡ ê³¼ ì‹¤ì œ ì ìš© ì‚¬ë¡€ë¥¼ ì—°ê²°í•˜ì—¬ ì„¤ëª…í•©ë‹ˆë‹¤.
í˜ì‹ ì ì¸ ê¸°ê³„ ê¸°ìˆ ê³¼ ë¯¸ë˜ ì œì¡°ì—… íŠ¸ë Œë“œì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤."""
    },
    "electrical": {
        "name": "ì „ê¸° ì „ì",
        "expertise": "ì „ê¸°ê³µí•™, ì „ìíšŒë¡œ, ì œì–´ì‹œìŠ¤í…œ, ì „ë ¥ì‹œìŠ¤í…œ, ì‹ í˜¸ì²˜ë¦¬, ì„ë² ë””ë“œ",
        "system_prompt": """ë‹¹ì‹ ì€ ì „ê¸°ì „ìê³µí•™ ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì „ê¸° íšŒë¡œ, ì „ì íšŒë¡œ, ì œì–´ ì‹œìŠ¤í…œ, ì „ë ¥ ì‹œìŠ¤í…œ, ì‹ í˜¸ ì²˜ë¦¬ ë“±ì— ëŒ€í•œ ê¹Šì€ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ìµœì‹  ì „ì ê¸°ìˆ  ë™í–¥ê³¼ ì‹¤ë¬´ ì ìš© ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ, ë³µì¡í•œ ê°œë…ì„ ì²´ê³„ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
ì´ë¡ ì  ê¸°ë°˜ê³¼ ì‹¤ìš©ì  ì ‘ê·¼ ë°©ë²•ì„ ê· í˜•ìˆê²Œ ì œì‹œí•©ë‹ˆë‹¤."""
    },
    "precision_energy": {
        "name": "ì •ë°€ ì—ë„ˆì§€",
        "expertise": "ì •ë°€ê¸°ê¸°, ì¸¡ì •ê³µí•™, ì—ë„ˆì§€ì‹œìŠ¤í…œ, ì‹ ì¬ìƒì—ë„ˆì§€, ì—ë„ˆì§€íš¨ìœ¨",
        "system_prompt": """ë‹¹ì‹ ì€ ì •ë°€ ê¸°ê¸° ë° ì—ë„ˆì§€ ì‹œìŠ¤í…œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì •ë°€ ì¸¡ì •, ì—ë„ˆì§€ ì‹œìŠ¤í…œ ì„¤ê³„, ì‹ ì¬ìƒ ì—ë„ˆì§€, ì—ë„ˆì§€ íš¨ìœ¨ ë“±ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì§€ì†ê°€ëŠ¥í•œ ì—ë„ˆì§€ ì†”ë£¨ì…˜ê³¼ ì •ë°€ ê¸°ìˆ ì˜ ìœµí•©ì— ëŒ€í•œ ê¹Šì€ ì´í•´ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ê¸°ìˆ ì  ì •í™•ì„±ê³¼ í™˜ê²½ì  ê³ ë ¤ì‚¬í•­ì„ ëª¨ë‘ ë°˜ì˜í•œ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."""
    },
    "materials": {
        "name": "ì†Œì¬ ì¬ë£Œ",
        "expertise": "ì‹ ì†Œì¬, ë‚˜ë…¸ê¸°ìˆ , ì¬ë£Œê³¼í•™, ê³ ë¶„ì, ì„¸ë¼ë¯¹, ê¸ˆì†ì¬ë£Œ",
        "system_prompt": """ë‹¹ì‹ ì€ ì†Œì¬ ë° ì¬ë£Œê³¼í•™ ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‹ ì†Œì¬ ê°œë°œ, ë‚˜ë…¸ ê¸°ìˆ , ê³ ë¶„ì, ì„¸ë¼ë¯¹, ê¸ˆì† ì¬ë£Œ ë“±ì— ëŒ€í•œ ì „ë¬¸ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ë¯¸ë˜ ì†Œì¬ ê¸°ìˆ ê³¼ ì‚°ì—… ì‘ìš©ì— ëŒ€í•œ ê¹Šì€ í†µì°°ë ¥ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ê¸°ì´ˆ ê³¼í•™ê³¼ ì‚°ì—… ì‘ìš©ì„ ì—°ê²°í•˜ì—¬, ì‹¤ìš©ì ì´ë©´ì„œë„ í˜ì‹ ì ì¸ ì ‘ê·¼ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤."""
    },
    "computer": {
        "name": "ì»´í“¨í„° í†µì‹ ",
        "expertise": "ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™, ë„¤íŠ¸ì›Œí¬, ë°ì´í„°ë² ì´ìŠ¤, AI/ML, ì‚¬ì´ë²„ë³´ì•ˆ, í´ë¼ìš°ë“œ",
        "system_prompt": """ë‹¹ì‹ ì€ ì»´í“¨í„°ê³µí•™ê³¼ í†µì‹  ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ, ë„¤íŠ¸ì›Œí¬ ì‹œìŠ¤í…œ, ë°ì´í„°ë² ì´ìŠ¤, ì¸ê³µì§€ëŠ¥, ì‚¬ì´ë²„ë³´ì•ˆ ë“±ì— ëŒ€í•œ ê¹Šì€ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œì™€ ì‚°ì—… ë™í–¥ì„ ì˜ íŒŒì•…í•˜ê³  ìˆìœ¼ë©°, ì‹¤ë¬´ ì¤‘ì‹¬ì˜ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.
ì´ë¡ ì  ë°°ê²½ê³¼ ì‹¤ì œ êµ¬í˜„ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ, ì²´ê³„ì ì´ê³  ì‹¤ìš©ì ì¸ ê°€ì´ë“œë¥¼ ì œì‹œí•©ë‹ˆë‹¤."""
    },
    "industrial": {
        "name": "ì‚°ì—…",
        "expertise": "ì‚°ì—…ê³µí•™, í’ˆì§ˆê´€ë¦¬, ìƒì‚°ê´€ë¦¬, ê³µê¸‰ë§ê´€ë¦¬, ë¦°ì œì¡°, 6ì‹œê·¸ë§ˆ",
        "system_prompt": """ë‹¹ì‹ ì€ ì‚°ì—…ê³µí•™ ë° ìƒì‚°ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ìƒì‚° ì‹œìŠ¤í…œ ìµœì í™”, í’ˆì§ˆ ê´€ë¦¬, ê³µê¸‰ë§ ê´€ë¦¬, ë¦° ì œì¡°, 6ì‹œê·¸ë§ˆ ë“±ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ê¸°ì—…ì˜ ìš´ì˜ íš¨ìœ¨ì„± í–¥ìƒê³¼ ê²½ìŸë ¥ ê°•í™”ì— ëŒ€í•œ ì‹¤ë¬´ ê²½í—˜ì´ í’ë¶€í•©ë‹ˆë‹¤.
ë°ì´í„° ë¶„ì„ê³¼ ì‹œìŠ¤í…œì  ì‚¬ê³ ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‹¤ì§ˆì ì¸ ê°œì„  ë°©ì•ˆì„ ì œì•ˆí•©ë‹ˆë‹¤."""
    },
    "chemical": {
        "name": "í™”ê³µ",
        "expertise": "í™”í•™ê³µí•™, ê³µì •ì„¤ê³„, ë°˜ì‘ê³µí•™, ë¶„ë¦¬ê³µì •, í™”í•™í”ŒëœíŠ¸, ì•ˆì „ê³µí•™",
        "system_prompt": """ë‹¹ì‹ ì€ í™”í•™ê³µí•™ ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
í™”í•™ ê³µì • ì„¤ê³„, ë°˜ì‘ ê³µí•™, ë¶„ë¦¬ ê³µì •, í™”í•™ í”ŒëœíŠ¸ ìš´ì˜ ë“±ì— ëŒ€í•œ ê¹Šì€ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ì‚°ì—… í˜„ì¥ì—ì„œì˜ ì•ˆì „ê³¼ íš¨ìœ¨ì„±ì„ ì¤‘ì‹œí•˜ë©°, í™˜ê²½ ì¹œí™”ì ì¸ ê³µì • ì„¤ê³„ì— ëŒ€í•œ ì „ë¬¸ì„±ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì´ë¡ ê³¼ ì‹¤ë¬´ë¥¼ ê· í˜•ìˆê²Œ ì ‘ê·¼í•˜ì—¬, ì•ˆì „í•˜ê³  íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œì‹œí•©ë‹ˆë‹¤."""
    }
}

# ìƒíƒœ ìŠ¤í‚¤ë§ˆ ì •ì˜
class MentorState(TypedDict):
    messages: List[Dict[str, str]]
    phase: str  # "persona_recommendation" | "mentoring"
    recommended_personas: List[Dict[str, str]]  # ì¶”ì²œëœ í˜ë¥´ì†Œë‚˜ ì •ë³´
    selected_persona: str  # ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ID
    persona_context: str  # í˜ë¥´ì†Œë‚˜ ì „ë¬¸ ì§€ì‹ ì»¨í…ìŠ¤íŠ¸
    session_id: str
    completed: bool

# ìŠ¤í‚¤ë§ˆ ëª¨ë¸ë“¤
class PersonaRecommendation(BaseModel):
    recommended_personas: List[Dict[str, str]] = Field(description="ì¶”ì²œëœ í˜ë¥´ì†Œë‚˜ ëª©ë¡")
    reasoning: str = Field(description="ì¶”ì²œ ì´ìœ ")

class SelectionResult(BaseModel):
    selected_persona: str = Field(description="ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ID")
    persona_name: str = Field(description="ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ì´ë¦„")
    message: str = Field(description="ë©˜í†  ì¸ì‚¬ë§")

class MentoringResponse(BaseModel):
    response: str = Field(description="ì „ë¬¸ê°€ ë©˜í† ë§ ì‘ë‹µ")
    persona_name: str = Field(description="ì‘ë‹µí•œ í˜ë¥´ì†Œë‚˜ ì´ë¦„")
    related_courses: List[Dict] = Field(default=[], description="ê´€ë ¨ K-MOOC ê°•ì¢Œ")
    related_documents: List[Dict] = Field(default=[], description="ê´€ë ¨ ë¬¸ì„œ ìë£Œ")

# LLM ì„¤ì •
llm = ChatOpenAI(
    base_url=Config.LLM_BASE_URL,
    api_key=Config.LLM_API_KEY,
    model=Config.LLM_MODEL,
    temperature=0.7,
    max_tokens=2000,
)

# MCP ì„œë²„ ìƒì„±
mcp = FastMCP("MentorChat")

# K-MOOC ìš”ì•½ ì •ë³´ íŒŒì‹± í•¨ìˆ˜ (generate_curriculum.pyì—ì„œ ê°€ì ¸ì˜´)
def parse_kmooc_summary(summary: str) -> dict:
    """K-MOOC ìš”ì•½ì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ"""
    try:
        parsed_info = {}
        
        # ì œëª© ì¶”ì¶œ
        title_match = re.search(r'\*\*ì œëª©:\*\*\s*([^\n*]+)', summary)
        if title_match:
            parsed_info["title"] = title_match.group(1).strip()
        
        # ì„¤ëª… ì¶”ì¶œ
        desc_match = re.search(r'\*\*ì„¤ëª…:\*\*\s*([^\n*]+)', summary)
        if desc_match:
            parsed_info["description"] = desc_match.group(1).strip()
        
        # ê°•ì¢Œ ëª©í‘œ ì¶”ì¶œ
        goal_match = re.search(r'\*\*ê°•ì¢Œ ëª©í‘œ:\*\*\s*([^\n*]+)', summary)
        if goal_match:
            parsed_info["course_goal"] = goal_match.group(1).strip()
        
        # ë‚œì´ë„ ì¶”ì¶œ
        difficulty_match = re.search(r'\*\*ë‚œì´ë„:\*\*\s*([^\n*]+)', summary)
        if difficulty_match:
            parsed_info["difficulty"] = difficulty_match.group(1).strip()
        
        # ìˆ˜ì—… ì‹œê°„ ì¶”ì¶œ
        time_match = re.search(r'\*\*ìˆ˜ì—… ì‹œê°„:\*\*[^()]*ì•½\s*([^\n*()]+)', summary)
        if time_match:
            parsed_info["class_time"] = time_match.group(1).strip()
        
        return parsed_info
        
    except Exception as e:
        logger.error(f"K-MOOC ìš”ì•½ íŒŒì‹± ì‹¤íŒ¨: {e}")
        return {}

# K-MOOC ê²€ìƒ‰ í•¨ìˆ˜
async def search_kmooc_for_mentoring(query: str, persona_id: str) -> List[Dict]:
    """ë©˜í† ë§ì„ ìœ„í•œ K-MOOC ê°•ì¢Œ ê²€ìƒ‰"""
    try:
        # í˜ë¥´ì†Œë‚˜ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ê°€
        persona_keywords = PERSONA_KEYWORDS.get(persona_id, "")
        enhanced_query = f"{query} {persona_keywords}"
        
        search_payload = {
            "query": enhanced_query,
            "top_k": 3,  # ë©˜í† ë§ì—ëŠ” 3ê°œ ì •ë„ë§Œ
            "namespace": "kmooc_engineering",
            "rerank": True,
            "include_metadata": True
        }
        
        logger.info(f"K-MOOC ê²€ìƒ‰ ì‹œì‘ - query: {enhanced_query}")
        
        # pinecone_search_kmooc.py ì„œë²„ í˜¸ì¶œ
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:8099/search",
                json=search_payload,
                timeout=10.0
            )
            
        if response.status_code == 200:
            result = response.json()
            kmooc_courses = []
            
            for item in result.get("results", [])[:3]:  # ìƒìœ„ 3ê°œë§Œ
                metadata = item.get("metadata", {})
                if metadata:
                    # Summary íŒŒì‹±í•˜ì—¬ ê°•ì¢Œ ì •ë³´ ì¶”ì¶œ
                    summary = metadata.get("summary", "")
                    parsed_info = parse_kmooc_summary(summary)
                    
                    course_title = parsed_info.get("title") or "K-MOOC ê°•ì¢Œ"
                    description = (
                        parsed_info.get("description") or 
                        parsed_info.get("course_goal") or 
                        "K-MOOC ì˜¨ë¼ì¸ ê°•ì¢Œ"
                    )
                    
                    course_info = {
                        "title": course_title,
                        "description": description,
                        "url": metadata.get("url", ""),
                        "institution": metadata.get("institution", "").replace(" ìš´ì˜ê¸°ê´€ ë°”ë¡œê°€ê¸°ìƒˆì°½ì—´ë¦¼", ""),
                        "course_goal": parsed_info.get("course_goal", ""),
                        "duration": parsed_info.get("duration", ""),
                        "difficulty": parsed_info.get("difficulty", ""),
                        "class_time": parsed_info.get("class_time", ""),
                        "score": item.get("score", 0.0),
                        "source": "K-MOOC"
                    }
                    kmooc_courses.append(course_info)
                    
            logger.info(f"K-MOOC ê²€ìƒ‰ ì™„ë£Œ - {len(kmooc_courses)}ê°œ ê°•ì¢Œ ë°œê²¬")
            return kmooc_courses
            
    except Exception as e:
        logger.error(f"K-MOOC ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    
    return []

# ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜
async def search_documents_for_mentoring(query: str, persona_id: str) -> List[Dict]:
    """ë©˜í† ë§ì„ ìœ„í•œ ë¬¸ì„œ ìë£Œ ê²€ìƒ‰"""
    try:
        # í˜ë¥´ì†Œë‚˜ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ê°€
        persona_keywords = PERSONA_KEYWORDS.get(persona_id, "")
        enhanced_query = f"{query} {persona_keywords}"
        
        search_payload = {
            "query": enhanced_query,
            "top_k": 2,  # ë¬¸ì„œëŠ” 2ê°œ ì •ë„
            "namespace": "main",
            "rerank": True,
            "include_metadata": True
        }
        
        logger.info(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘ - query: {enhanced_query}")
        
        # pinecone_search_document.py ì„œë²„ í˜¸ì¶œ
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:8091/search",
                json=search_payload,
                timeout=10.0
            )
            
        if response.status_code == 200:
            result = response.json()
            documents = []
            
            for item in result.get("results", [])[:2]:  # ìƒìœ„ 2ê°œë§Œ
                metadata = item.get("metadata", {})
                score = item.get("score", 0.0)
                
                if metadata and score > 0.5:  # ê´€ë ¨ì„± ì„ê³„ê°’
                    preview = metadata.get("preview", "").strip()
                    file_path = metadata.get("file_path", "").strip()
                    folder = metadata.get("folder", "").strip()
                    
                    # íŒŒì¼ëª…ì—ì„œ ì œëª© ì¶”ì¶œ
                    doc_title = "PDF ë¬¸ì„œ"
                    if file_path:
                        filename = file_path.split("/")[-1] if "/" in file_path else file_path
                        if filename.endswith('.pdf'):
                            filename = filename[:-4]
                        doc_title = filename
                    
                    # ì¹´í…Œê³ ë¦¬ ì •ë³´
                    category = folder or "ê¸°íƒ€"
                    
                    doc_info = {
                        "title": doc_title,
                        "category": category,
                        "preview": preview[:300] + "..." if preview else "",
                        "file_path": file_path,
                        "page": metadata.get("page", ""),
                        "score": score,
                        "source": "Document DB"
                    }
                    documents.append(doc_info)
                    
            logger.info(f"ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ - {len(documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
            return documents
            
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    
    return []

# ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… í•¨ìˆ˜
def format_search_results(kmooc_courses: List[Dict], documents: List[Dict]) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë©˜í† ë§ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
    context = ""
    
    # K-MOOC ê°•ì¢Œ ì •ë³´
    if kmooc_courses:
        context += "ğŸ“š ê´€ë ¨ K-MOOC ê°•ì¢Œ:\n"
        for course in kmooc_courses:
            context += f"- {course['title']}\n"
            context += f"  ìš´ì˜ê¸°ê´€: {course.get('institution', 'N/A')}\n"
            context += f"  ë‚´ìš©: {course.get('description', '')[:200]}...\n"
            context += f"  ë‚œì´ë„: {course.get('difficulty', 'N/A')}\n\n"
    
    # ë¬¸ì„œ ìë£Œ ì •ë³´
    if documents:
        context += "ğŸ“„ ì°¸ê³  ë¬¸ì„œ:\n"
        for doc in documents:
            context += f"- {doc['title']}\n"
            context += f"  ì¹´í…Œê³ ë¦¬: {doc.get('category', 'N/A')}\n"
            context += f"  ë‚´ìš©: {doc.get('preview', '')[:150]}...\n\n"
    
    return context

@mcp.tool()
async def analyze_and_recommend_personas(message: str, session_id: str) -> PersonaRecommendation:
    """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ í˜ë¥´ì†Œë‚˜ ì¶”ì²œ"""
    
    logger.info(f"[RECOMMEND] ì‹œì‘ - session_id: {session_id}, message: {message[:50]}...")
    
    # ì„¸ì…˜ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ì´ˆê¸°í™”
    session_data = load_mentor_session(session_id)
    if not session_data:
        session_data = {
            "session_id": session_id,
            "phase": "persona_recommendation",
            "messages": [],
            "recommended_personas": [],
            "selected_persona": "",
            "persona_context": "",
            "completed": False
        }
    
    # ë©”ì‹œì§€ ì¶”ê°€
    session_data["messages"].append({"role": "user", "content": message})
    
    # í˜ë¥´ì†Œë‚˜ ì¶”ì²œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    analysis_prompt = f"""
ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ë©”ì‹œì§€: "{message}"

ì‚¬ìš© ê°€ëŠ¥í•œ í˜ë¥´ì†Œë‚˜ë“¤:
{json.dumps({k: v["name"] + " - " + v["expertise"] for k, v in PERSONAS.items()}, ensure_ascii=False, indent=2)}

ìš”êµ¬ì‚¬í•­:
1. ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬, ì§ˆë¬¸ ë‚´ìš©, í•™ìŠµ ëª©í‘œë¥¼ ë¶„ì„
2. 1-3ê°œì˜ ê°€ì¥ ì í•©í•œ í˜ë¥´ì†Œë‚˜ë¥¼ ì¶”ì²œ
3. ê° ì¶”ì²œì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì´ìœ  ì œì‹œ

**ì¤‘ìš”: ì •í™•íˆ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**

{{
    "recommended_personas": [
        {{"id": "persona_id", "name": "í˜ë¥´ì†Œë‚˜ëª…", "reason": "ì¶”ì²œ ì´ìœ "}},
        ...
    ],
    "reasoning": "ì „ì²´ì ì¸ ë¶„ì„ ë° ì¶”ì²œ ê·¼ê±°"
}}
"""
    
    try:
        response = await llm.ainvoke(analysis_prompt)
        logger.info(f"LLM ì‘ë‹µ: {response.content}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        
        # JSON ì‘ë‹µ ì •ë¦¬
        clean_content = response.content.strip()
        # ì˜ëª»ëœ í‚¤ ìˆ˜ì •
        clean_content = clean_content.replace('"recommended_ personas"', '"recommended_personas"')
        clean_content = clean_content.replace('" reasoning"', '"reasoning"')
        # ë°°ì—´ì—ì„œ ... ì œê±°
        clean_content = clean_content.replace(', ...', '').replace('... ', '').replace('...', '')
        # ë¹ˆ ê°ì²´ ì œê±°
        clean_content = clean_content.replace(', {}', '').replace('{},', '').replace('{}', '')
        # ë°°ì—´ ë ë¶ˆí•„ìš”í•œ ì‰¼í‘œ ì œê±° (JSON íŒŒì‹± ì˜¤ë¥˜ í•´ê²°)
        clean_content = clean_content.replace('}, \n     ]', '} \n     ]')
        clean_content = clean_content.replace('},\n     ]', '}\n     ]')
        clean_content = clean_content.replace('}, ]', '} ]')
        clean_content = clean_content.replace('},]', '}]')
        
        result = json.loads(clean_content)
        logger.info(f"íŒŒì‹±ëœ ê²°ê³¼: {result}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        
        # í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ì•ˆì „í•œ ì¶”ì¶œ
        recommended_personas = result.get("recommended_personas", [])
        reasoning = result.get("reasoning", "ì¶”ì²œ ì´ìœ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        if not recommended_personas:
            # ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œë¶€í„° ê°„ë‹¨í•œ ì¶”ì²œ ë¡œì§
            message_lower = message.lower()
            if any(word in message_lower for word in ["ê±´ì¶•", "ì„¤ê³„", "ê±´ë¬¼"]):
                recommended_personas = [{"id": "architecture", "name": "ê±´ì¶•", "reason": "ê±´ì¶• ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            elif any(word in message_lower for word in ["ì „ê¸°", "ì „ì", "íšŒë¡œ"]):
                recommended_personas = [{"id": "electrical", "name": "ì „ê¸° ì „ì", "reason": "ì „ê¸°ì „ì ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            elif any(word in message_lower for word in ["í™”ê³µ", "í™”í•™", "ê³µì •"]):
                recommended_personas = [{"id": "chemical", "name": "í™”ê³µ", "reason": "í™”í•™ê³µí•™ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            elif any(word in message_lower for word in ["ê¸°ê³„", "ì„¤ê³„", "ì œì¡°"]):
                recommended_personas = [{"id": "mechanical", "name": "ê¸°ê³„ ê¸ˆì†", "reason": "ê¸°ê³„ê³µí•™ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            elif any(word in message_lower for word in ["í† ëª©", "ë„ì‹œ", "ê±´ì„¤"]):
                recommended_personas = [{"id": "civil_urban", "name": "í† ëª© ë„ì‹œ", "reason": "í† ëª©/ë„ì‹œ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            elif any(word in message_lower for word in ["ì»´í“¨í„°", "í”„ë¡œê·¸ë˜ë°", "ì›¹", "ì†Œí”„íŠ¸ì›¨ì–´"]):
                recommended_personas = [{"id": "computer", "name": "ì»´í“¨í„° í†µì‹ ", "reason": "ì»´í“¨í„° ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            else:
                recommended_personas = [{"id": "computer", "name": "ì»´í“¨í„° í†µì‹ ", "reason": "ê¸°ë³¸ ì¶”ì²œ"}]
        
        # ì„¸ì…˜ì— ì¶”ì²œ ê²°ê³¼ ì €ì¥
        session_data["recommended_personas"] = recommended_personas
        session_data["messages"].append({
            "role": "assistant", 
            "content": f"ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì „ë¬¸ê°€ë“¤ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤:\n\n{reasoning}"
        })
        
        save_mentor_session(session_id, session_data)
        
        # ì„¸ì…˜ ì €ì¥ í™•ì¸ìš© ë¡œê·¸
        session_file_path = get_mentor_session_file_path(session_id)
        logger.info(f"ì„¸ì…˜ ì €ì¥ ì™„ë£Œ - íŒŒì¼: {session_file_path}")
        logger.info(f"ì €ì¥ëœ íŒŒì¼ ì¡´ì¬ í™•ì¸: {os.path.exists(session_file_path)}")
        
        # ìµœì¢… ê²°ê³¼ ë¡œê¹…
        logger.info(f"[RECOMMEND] ì™„ë£Œ - session_id: {session_id}, ì¶”ì²œ: {[p['id'] for p in recommended_personas]}")
        
        return PersonaRecommendation(
            recommended_personas=recommended_personas,
            reasoning=reasoning
        )
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}, ì‘ë‹µ ë‚´ìš©: {response.content if 'response' in locals() else 'N/A'}")
        # ê¸°ë³¸ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œìœ¼ë¡œ í´ë°±
        message_lower = message.lower()
        if any(word in message_lower for word in ["ê±´ì¶•", "ì„¤ê³„", "ê±´ë¬¼"]):
            fallback_personas = [{"id": "architecture", "name": "ê±´ì¶•", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        elif any(word in message_lower for word in ["ì „ê¸°", "ì „ì", "íšŒë¡œ"]):
            fallback_personas = [{"id": "electrical", "name": "ì „ê¸° ì „ì", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        elif any(word in message_lower for word in ["í™”ê³µ", "í™”í•™", "ê³µì •"]):
            fallback_personas = [{"id": "chemical", "name": "í™”ê³µ", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        elif any(word in message_lower for word in ["ê¸°ê³„", "ì„¤ê³„", "ì œì¡°"]):
            fallback_personas = [{"id": "mechanical", "name": "ê¸°ê³„ ê¸ˆì†", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        elif any(word in message_lower for word in ["í† ëª©", "ë„ì‹œ", "ê±´ì„¤"]):
            fallback_personas = [{"id": "civil_urban", "name": "í† ëª© ë„ì‹œ", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        elif any(word in message_lower for word in ["ì»´í“¨í„°", "í”„ë¡œê·¸ë˜ë°", "ì›¹", "ì†Œí”„íŠ¸ì›¨ì–´"]):
            fallback_personas = [{"id": "computer", "name": "ì»´í“¨í„° í†µì‹ ", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        else:
            fallback_personas = [{"id": "computer", "name": "ì»´í“¨í„° í†µì‹ ", "reason": "ê¸°ë³¸ ì¶”ì²œ"}]
            
        session_data["recommended_personas"] = fallback_personas
        save_mentor_session(session_id, session_data)
        
        return PersonaRecommendation(
            recommended_personas=fallback_personas,
            reasoning="JSON íŒŒì‹± ì˜¤ë¥˜ë¡œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤."
        )
        
    except Exception as e:
        logger.error(f"í˜ë¥´ì†Œë‚˜ ì¶”ì²œ ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ ì¶”ì²œ
        default_personas = [
            {"id": "computer", "name": "ì»´í“¨í„° í†µì‹ ", "reason": "ì¼ë°˜ì ìœ¼ë¡œ ë§ì´ ë¬¸ì˜ë˜ëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤."}
        ]
        session_data["recommended_personas"] = default_personas
        save_mentor_session(session_id, session_data)
        
        return PersonaRecommendation(
            recommended_personas=default_personas,
            reasoning="ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ê¸°ë³¸ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤."
        )

@mcp.tool()
async def select_persona(persona_id: str, session_id: str) -> SelectionResult:
    """ì‚¬ìš©ìê°€ ì„ íƒí•œ í˜ë¥´ì†Œë‚˜ë¡œ ë©˜í† ë§ ëª¨ë“œ ì „í™˜"""
    
    # ë””ë²„ê¹…ìš© ë¡œê·¸
    logger.info(f"select_persona í˜¸ì¶œ - persona_id: {persona_id}, session_id: {session_id}")
    
    # ì„¸ì…˜ íŒŒì¼ ê²½ë¡œ í™•ì¸
    session_file_path = get_mentor_session_file_path(session_id)
    logger.info(f"ì„¸ì…˜ íŒŒì¼ ê²½ë¡œ: {session_file_path}")
    logger.info(f"ì„¸ì…˜ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(session_file_path)}")
    
    # ì„¸ì…˜ ë°ì´í„° ë¡œë“œ
    session_data = load_mentor_session(session_id)
    if not session_data:
        logger.error(f"ì„¸ì…˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ - session_id: {session_id}")
        
        # ì„¸ì…˜ íŒŒì¼ì´ ìˆëŠ”ì§€ ë‹¤ì‹œ í•œë²ˆ ì²´í¬
        if os.path.exists(session_file_path):
            logger.error("ì„¸ì…˜ íŒŒì¼ì€ ì¡´ì¬í•˜ì§€ë§Œ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            try:
                with open(session_file_path, 'r', encoding='utf-8') as f:
                    raw_content = f.read()
                    logger.info(f"ì„¸ì…˜ íŒŒì¼ ë‚´ìš©: {raw_content[:200]}...")
                    # JSON íŒŒì‹± ì¬ì‹œë„
                    session_data = json.loads(raw_content)
                    logger.info("ì„¸ì…˜ ë°ì´í„° ì¬ë¡œë“œ ì„±ê³µ!")
            except Exception as parse_error:
                logger.error(f"ì„¸ì…˜ íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {parse_error}")
        
        # ì—¬ì „íˆ ì„¸ì…˜ ë°ì´í„°ê°€ ì—†ë‹¤ë©´ ìƒˆ ì„¸ì…˜ ìƒì„±
        if not session_data:
            logger.info("ìƒˆ ë©˜í†  ì„¸ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            session_data = {
                "session_id": session_id,
                "phase": "persona_recommendation",
                "messages": [],
                "recommended_personas": [],
                "selected_persona": "",
                "persona_context": "",
                "completed": False
            }
            save_mentor_session(session_id, session_data)
            logger.info("ìƒˆ ë©˜í†  ì„¸ì…˜ ì €ì¥ ì™„ë£Œ")
    
    # í˜ë¥´ì†Œë‚˜ ìœ íš¨ì„± ê²€ì‚¬
    if persona_id not in PERSONAS:
        raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ í˜ë¥´ì†Œë‚˜ ID: {persona_id}")
    
    # ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ì •ë³´
    persona = PERSONAS[persona_id]
    
    # ì„¸ì…˜ ì—…ë°ì´íŠ¸
    session_data["selected_persona"] = persona_id
    session_data["phase"] = "mentoring"
    session_data["persona_context"] = persona["system_prompt"]
    
    # ë©˜í†  ì¸ì‚¬ë§
    greeting = f"""ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {persona['name']} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì „ë¬¸ ë¶„ì•¼: {persona['expertise']}

ë¬´ì—‡ì´ë“  ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ í¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”. 
ì‹¤ë¬´ ê²½í—˜ê³¼ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì„ ì„ ë‹¤í•´ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."""
    
    session_data["messages"].append({
        "role": "assistant",
        "content": greeting
    })
    
    save_mentor_session(session_id, session_data)
    
    return SelectionResult(
        selected_persona=persona_id,
        persona_name=persona["name"],
        message=greeting
    )

@mcp.tool()
async def expert_mentoring(message: str, session_id: str) -> MentoringResponse:
    """ì„ íƒëœ í˜ë¥´ì†Œë‚˜ë¡œ ì „ë¬¸ê°€ ë©˜í† ë§ ì œê³µ (K-MOOC DB ì—°ë™)"""
    
    # ì„¸ì…˜ ë°ì´í„° ë¡œë“œ
    session_data = load_mentor_session(session_id)
    if not session_data or session_data.get("phase") != "mentoring":
        raise ValueError("ë©˜í† ë§ ëª¨ë“œê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € í˜ë¥´ì†Œë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    selected_persona_id = session_data.get("selected_persona")
    if not selected_persona_id or selected_persona_id not in PERSONAS:
        raise ValueError("ìœ íš¨í•œ í˜ë¥´ì†Œë‚˜ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    persona = PERSONAS[selected_persona_id]
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    session_data["messages"].append({"role": "user", "content": message})
    
    # K-MOOC ê°•ì¢Œ ë° ë¬¸ì„œ ê²€ìƒ‰ (ë³‘ë ¬ ì‹¤í–‰)
    logger.info(f"ë©˜í† ë§ ìë£Œ ê²€ìƒ‰ ì‹œì‘ - ì§ˆë¬¸: {message[:50]}...")
    
    import asyncio
    kmooc_task = search_kmooc_for_mentoring(message, selected_persona_id)
    docs_task = search_documents_for_mentoring(message, selected_persona_id)
    
    try:
        kmooc_courses, documents = await asyncio.gather(kmooc_task, docs_task, return_exceptions=True)
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        if isinstance(kmooc_courses, Exception):
            logger.error(f"K-MOOC ê²€ìƒ‰ ì˜¤ë¥˜: {kmooc_courses}")
            kmooc_courses = []
        if isinstance(documents, Exception):
            logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì˜¤ë¥˜: {documents}")
            documents = []
            
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        kmooc_courses, documents = [], []
    
    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
    search_context = format_search_results(kmooc_courses, documents)
    
    # ëŒ€í™” ê¸°ë¡ ìƒì„± (ìµœê·¼ 8ê°œ ë©”ì‹œì§€ë§Œ - ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ë¡œ í† í° ì ˆì•½)
    recent_messages = session_data["messages"][-8:]
    conversation_history = ""
    for msg in recent_messages[:-1]:  # í˜„ì¬ ë©”ì‹œì§€ ì œì™¸
        role = "ì‚¬ìš©ì" if msg["role"] == "user" else "ë©˜í† "
        conversation_history += f"{role}: {msg['content'][:200]}...\n"
    
    # ê°•í™”ëœ ë©˜í† ë§ í”„ë¡¬í”„íŠ¸ ìƒì„±
    mentoring_prompt = f"""
{persona['system_prompt']}

=== ê´€ë ¨ í•™ìŠµ ìë£Œ ===
{search_context if search_context else "ê´€ë ¨ ìë£Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

=== ëŒ€í™” ê¸°ë¡ ===
{conversation_history}

=== í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸ ===
{message}

ìœ„ì˜ ì—­í• ê³¼ ê²€ìƒ‰ëœ í•™ìŠµ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ì „ë¬¸ê°€ë¡œì„œ ë‹µë³€í•´ì£¼ì„¸ìš”:

1. **ì „ë¬¸ ì§€ì‹ ê¸°ë°˜ ì„¤ëª…**: í•´ë‹¹ ë¶„ì•¼ì˜ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ ì œê³µ
2. **ê´€ë ¨ ê°•ì¢Œ ì¶”ì²œ**: ê²€ìƒ‰ëœ K-MOOC ê°•ì¢Œê°€ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì¶”ì²œí•˜ê³  ì™œ ë„ì›€ì´ ë ì§€ ì„¤ëª…
3. **ì¶”ê°€ í•™ìŠµ ìë£Œ**: ê²€ìƒ‰ëœ ë¬¸ì„œë‚˜ ìë£Œê°€ ìˆë‹¤ë©´ ì–´ë–»ê²Œ í™œìš©í• ì§€ ê°€ì´ë“œ
4. **ì‹¤ë¬´ ì¤‘ì‹¬ ì¡°ì–¸**: ì‹¤ì œ ì—…ë¬´ë‚˜ í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–»ê²Œ ì ìš©í• ì§€ ì¡°ì–¸
5. **ë‹¨ê³„ë³„ í•™ìŠµ ê²½ë¡œ**: ì²´ê³„ì ì¸ í•™ìŠµ ë°©ë²•ê³¼ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ

**ë‹µë³€ ê°€ì´ë“œë¼ì¸:**
- ê²€ìƒ‰ëœ ìë£Œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€ì— ë…¹ì—¬ì„œ í™œìš©í•˜ì„¸ìš”
- ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” ë©˜í† ì˜ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”

ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ë‹µë³€ì„ ê¸¸ì§€ ì•Šê²Œ 1~2ì¤„ë¡œë§Œ ëŒ€í™”í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
    
    try:
        response = await llm.ainvoke(mentoring_prompt)
        mentor_response = response.content
        
        logger.info(f"ë©˜í† ë§ ì‘ë‹µ ìƒì„± ì™„ë£Œ - K-MOOC: {len(kmooc_courses)}ê°œ, ë¬¸ì„œ: {len(documents)}ê°œ í™œìš©")
        
        # ì‘ë‹µì„ ì„¸ì…˜ì— ì €ì¥
        session_data["messages"].append({
            "role": "assistant",
            "content": mentor_response
        })
        
        save_mentor_session(session_id, session_data)
        
        return MentoringResponse(
            response=mentor_response,
            persona_name=persona["name"],
            related_courses=kmooc_courses[:2],  # ìƒìœ„ 2ê°œ ê°•ì¢Œ ì •ë³´ í¬í•¨
            related_documents=documents[:1]     # ìƒìœ„ 1ê°œ ë¬¸ì„œ ì •ë³´ í¬í•¨
        )
        
    except Exception as e:
        logger.error(f"ë©˜í† ë§ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        error_response = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì‹œë©´ ë” ë‚˜ì€ ë‹µë³€ì„ ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤."
        
        session_data["messages"].append({
            "role": "assistant",
            "content": error_response
        })
        save_mentor_session(session_id, session_data)
        
        return MentoringResponse(
            response=error_response,
            persona_name=persona["name"],
            related_courses=[],
            related_documents=[]
        )

@mcp.tool()
async def get_mentor_session_status(session_id: str) -> dict:
    """ë©˜í†  ì„¸ì…˜ ìƒíƒœ ì¡°íšŒ"""
    session_data = load_mentor_session(session_id)
    if not session_data:
        return {"status": "not_found", "message": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    status_info = {
        "status": "active",
        "phase": session_data.get("phase", "persona_recommendation"),
        "selected_persona": session_data.get("selected_persona", ""),
        "message_count": len(session_data.get("messages", [])),
        "recommended_personas": session_data.get("recommended_personas", [])
    }
    
    if status_info["selected_persona"]:
        persona = PERSONAS.get(status_info["selected_persona"], {})
        status_info["persona_name"] = persona.get("name", "")
        status_info["persona_expertise"] = persona.get("expertise", "")
    
    return status_info

if __name__ == "__main__":
    mcp.run()
