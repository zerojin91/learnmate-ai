from pydantic import BaseModel, Field
from typing import TypedDict, List, Literal
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, START, END
import json
import re
from dotenv import load_dotenv
load_dotenv()

class ChatTemplateConstants:
    BEGIN_OF_TEXT = "<|begin_of_text|>"
    START_HEADER_ID = "<|start_header_id|>"
    END_HEADER_ID = "<|end_header_id|>"
    EOT_ID = "<|eot_id|>"

def get_message_info(message):
    if isinstance(message, dict):
        return message.get('role'), message.get('content')
    if hasattr(message, 'role') and hasattr(message, 'content'):
        return message.role, message.content
    message_type = type(message).__name__.lower()
    if 'system' in message_type:
        role = 'system'
    elif 'human' in message_type or 'user' in message_type:
        role = 'user'
    elif 'ai' in message_type or 'assistant' in message_type:
        role = 'assistant'
    else:
        role = getattr(message, 'role', 'user')
    content = getattr(message, 'content', str(message))
    return role, content

def apply_chat_template(state_messages, turns=10, system_message=None):
    template = ChatTemplateConstants.BEGIN_OF_TEXT
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì²˜ë¦¬
    if system_message:
        template += (
            ChatTemplateConstants.START_HEADER_ID + "system" + ChatTemplateConstants.END_HEADER_ID + "\n\n" +
            system_message + ChatTemplateConstants.EOT_ID
        )
    
    # ìµœê·¼ ë©”ì‹œì§€ë“¤ë§Œ ì²˜ë¦¬
    for msg in state_messages[-turns:]:
        if msg["type"] == "human":
            role = "user"
        elif msg["type"] == "ai":
            role = "assistant"
        else:
            continue
            
        template += (
            ChatTemplateConstants.START_HEADER_ID + role + ChatTemplateConstants.END_HEADER_ID + "\n\n" +
            msg["content"] + ChatTemplateConstants.EOT_ID
        )
    
    # ë§ˆì§€ë§‰ì´ user ë©”ì‹œì§€ë©´ assistant í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    if state_messages and state_messages[-1]["type"] == "human":
        template += (
            ChatTemplateConstants.START_HEADER_ID + "assistant" + ChatTemplateConstants.END_HEADER_ID + "\n\n"
        )
    
    return template

def history(messages_list):
    try:
        rename = {"ai": "assistant", "human": "user"}
        text = '\n'.join([f"{rename[i['type']]}:{i['content']}" for i in messages_list])
        return text
    except:
        return ''
    
# ìƒíƒœ ì •ì˜
class ConversationState(TypedDict):
    messages: List[dict]
    topic: str
    constraints: str
    goal: str

def user_assessment_node(state: ConversationState) -> ConversationState:
    prompt = f'''### ì—­í• 
ë‹¹ì‹ ì€ LearnMate AI (ëŸ¬ë‹ë©”ì´íŠ¸ AI) ì…ë‹ˆë‹¤.
ìì‹ ë§Œì˜ ë§ì¶¤í˜• í•™ìŠµ ë©˜í† ë¡œì¨ ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ë¥¼ í†µí•´ í˜„ì¬ ìƒíƒœë¥¼ íŒŒì•…í•˜ëŠ”ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

### ëŒ€í™” ê¸°ë¡
{history(state.get('messages', ''))}

### í˜„ì¬ ì‚¬ìš©ì ì •ë³´
- ê³µë¶€í•˜ê³ ì í•˜ëŠ” ì£¼ì œ: {state.get('topic', 'ë¯¸íŒŒì•…')}
  (ì‚¬ìš©ìê°€ í•™ìŠµí•˜ê³ ì í•˜ëŠ” ì „ë°˜ì ì¸ ë¶„ì•¼ë‚˜ ì˜ì—­ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì˜ˆ: í”„ë¡œê·¸ë˜ë°, ì˜ì–´, ìê²©ì¦ ë“±)
- ì œì•½ ì¡°ê±´: {state.get('constraints', 'ë¯¸íŒŒì•…')}
  (ì‚¬ìš©ìê°€ í•™ìŠµ ì‹œ ê³ ë ¤í•´ì•¼ í•  êµ¬ì²´ì ì¸ ì œí•œì‚¬í•­ ë˜ëŠ” í™˜ê²½ ì¡°ê±´ì…ë‹ˆë‹¤. ì˜ˆ: ì‹œê°„, ìˆ˜ì¤€, ì¥ë¹„, ì¥ì†Œ ë“±)
- ëª©í‘œ: {state.get('goal', 'ë¯¸íŒŒì•…')}
  (í•´ë‹¹ ì£¼ì œì—ì„œ ì‚¬ìš©ìê°€ êµ¬ì²´ì ìœ¼ë¡œ ë°°ìš°ê³  ì‹¶ê±°ë‚˜ ë‹¬ì„±í•˜ê³ ì í•˜ëŠ” ëª©í‘œë‚˜ í™œë™ì…ë‹ˆë‹¤. ì˜ˆ: ì›¹ ê°œë°œìê°€ ë˜ê³  ì‹¶ë‹¤, ì˜ì–´ íšŒí™” ëŠ¥ë ¥ì„ í‚¤ìš°ê³  ì‹¶ë‹¤)

### ì§€ì‹œì‚¬í•­
í˜„ì¬ ì‚¬ìš©ì ì •ë³´ì—ì„œ 'ë¯¸íŒŒì•…'ëœ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ ì‚¬ìš©ì ì •ë³´ì™€ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì´ì•¼ê¸°í•˜ì„¸ìš”.
'''
    response = llm.invoke(prompt)
    state["messages"].append({"type": "ai", "content": response.content})
    print("ğŸ¤– ", response.content)

    # ìœ ì € ì‘ë‹µ
    user_input = input("ğŸ‘¤  ")
    state["messages"].append({"type": "human", "content": user_input})

    return state

class UserInfoSchema(BaseModel):
    topic: str = Field(
        default="",
        description=(
            "ì‚¬ìš©ìê°€ ê³µë¶€í•˜ê³ ì í•˜ëŠ” ì „ë°˜ì ì¸ ì£¼ì œë‚˜ ë¶„ì•¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. "
            "ì˜ˆ: í”„ë¡œê·¸ë˜ë°, ì˜ì–´, ìê²©ì¦ ë“±. "
            "ë” êµ¬ì²´ì ì¸ í•™ìŠµ ëª©í‘œë‚˜ í•˜ê³  ì‹¶ì€ í™œë™ì€ ë³„ë„ì˜ 'goal' í•„ë“œì— ê¸°ë¡ë©ë‹ˆë‹¤."
        )
    )
    constraints: str = Field(
        default="",
        description=(
            "ì‚¬ìš©ìê°€ ëª…í™•í•˜ê²Œ ì–¸ê¸‰í•œ êµ¬ì²´ì ì¸ ì œì•½ ì¡°ê±´(ì˜ˆ: ì‹œê°„, í™˜ê²½, ìˆ˜ì¤€ ë“±). "
            "ì¼ë°˜ì ì¸ í–‰ìœ„ë‚˜ ë™ì‚¬ëŠ” í¬í•¨í•˜ì§€ ë§ê³ , "
            "êµ¬ì²´ì ì¸ ì œì•½ ì‚¬í•­ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ë‘¡ë‹ˆë‹¤."
        )
    )
    goal: str = Field(
        default="",
        description="ì‚¬ìš©ìê°€ í•´ë‹¹ ì£¼ì œì—ì„œ êµ¬ì²´ì ìœ¼ë¡œ ë°°ìš°ê³  ì‹¶ê±°ë‚˜ í•˜ê³  ì‹¶ì€ í™œë™, ëª©í‘œ ë“±"
    )
    
def extract_user_info_node(state: ConversationState) -> ConversationState:
    system_prompt = f'''### ì—­í• 
ë‹¹ì‹ ì€ LearnMate AI ì…ë‹ˆë‹¤. ë‹¤ìŒ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ì‚¬ìš©ì ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

### ê·œì¹™
1. ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ëª¨ë“  ì£¼ìš” ì •ë³´ í•­ëª©ë“¤ì„ í•µì‹¬ í‚¤ì›Œë“œ ë˜ëŠ” ëª…ì‚¬ í˜•íƒœë¡œ ê°„ê²°í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”.
2. íŠ¹ì • ì •ë³´ê°€ ëª…í™•í•˜ê²Œ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ë‹¤ë©´ í•´ë‹¹ í•­ëª©ì€ ë¹ˆ ë¬¸ìì—´("")ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
3. ë¶ˆí•„ìš”í•œ ì„¤ëª…ì´ë‚˜ ì¶”ë¡ ì€ í•˜ì§€ ë§ˆì‹œê³ , ìˆëŠ” ì •ë³´ë§Œ ì •í™•íˆ ë°˜ì˜í•˜ì„¸ìš”.
4. í•­ìƒ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ë©°, ëª¨ë“  í•„ë“œ(ìˆëŠ” ê²ƒ, ì—†ëŠ” ê²ƒ)ë¥¼ í¬í•¨í•˜ì„¸ìš”.

### ëŒ€í™” ê¸°ë¡
'''
    prompt = apply_chat_template(state["messages"], system_message=system_prompt)

    # ëª¨ë¸ì„ pydantic ìŠ¤í‚¤ë§ˆ ë°”ì¸ë”©í•´ êµ¬ì¡°í™” ì¶œë ¥ ìƒì„±
    model_with_structure = llm.with_structured_output(UserInfoSchema)
    structured_output = model_with_structure.invoke(prompt)

    # ê°’ ì¶”ì¶œ í›„ state ë°˜ì˜
    state['topic'] = structured_output.topic
    state['constraints'] = structured_output.constraints
    state['goal'] = structured_output.goal

    return state

def check_completion(state):
    print("check_completion")
    print("topic:",state.get('topic'))
    print("constraints:",state.get('constraints'))
    print("goal:",state.get('goal'))
    print("=="*20)
    if state.get('topic') and state.get('constraints') and state.get('goal'):
        return True
    else:
        return False

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(
    base_url="http://localhost:11434/v1",
    api_key="ollama",
    model="midm-2.0-base-q8",
    temperature=0.7,
    max_tokens=1024,
)

# StateGraph ìƒì„±
workflow = StateGraph(ConversationState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("user_assessment_node", user_assessment_node)
workflow.add_node("extract_user_info_node", extract_user_info_node)

# ì—£ì§€ ì¶”ê°€
workflow.add_edge(START, "user_assessment_node")
workflow.add_edge("user_assessment_node", "extract_user_info_node")
workflow.add_conditional_edges(
    "extract_user_info_node",
    check_completion,
    {
        True: END,
        False: "user_assessment_node",
    },
)

# ê·¸ë˜í”„ ì»´íŒŒì¼
app = workflow.compile()
