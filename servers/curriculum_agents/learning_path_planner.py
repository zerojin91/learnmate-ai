"""
Learning Path Planner Agent - ì „ì²´ í•™ìŠµ ê²½ë¡œ ë¶„ì„ ë° ì„¤ê³„
"""
import asyncio
import json
import os
import re
from typing import Dict, List, Any
from langchain_neo4j import Neo4jGraph
from langchain_openai import ChatOpenAI
from neo4j.time import DateTime
from config import Config
from .base_agent import BaseAgent
from .state import CurriculumState, ProcessingPhase


class LearningPathPlannerAgent(BaseAgent):
    """ì „ì²´ í•™ìŠµ ê²½ë¡œë¥¼ ë¶„ì„í•˜ê³  ì„¤ê³„í•˜ëŠ” ì—ì´ì „íŠ¸"""

    # í´ë˜ìŠ¤ ë ˆë²¨ì—ì„œ Neo4j ì—°ê²° í’€ë§
    _neo4j_graph = None
    _connection_failed = False
    _document_cache = {}  # ë¬¸ì„œ ì½˜í…ì¸  ìºì‹±

    def __init__(self, llm=None):
        # BaseAgent ì´ˆê¸°í™”ë¥¼ ìœ„í•´ ë”ë¯¸ llmì´ë¼ë„ ì „ë‹¬í•´ì•¼ í•¨
        if llm is None:
            llm = ChatOpenAI(model="gpt-3.5-turbo", api_key="dummy")
        super().__init__(llm)

        # OpenAI GPT-4o-mini ì „ìš© LLM ì¸ìŠ¤í„´ìŠ¤
        self.openai_llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            api_key=os.getenv("OPENAI_API_KEY")
        )
        # workflowì—ì„œ ì „ë‹¬ë˜ëŠ” llmì€ ë¬´ì‹œí•˜ê³  OpenAI ì‚¬ìš©

        # Neo4j ì—°ê²° ì´ˆê¸°í™”
        self._ensure_neo4j_connection()

    def _ensure_neo4j_connection(self):
        """Neo4j ì—°ê²° í™•ë³´ (ì‹±ê¸€í†¤ íŒ¨í„´)"""
        if LearningPathPlannerAgent._connection_failed:
            return False

        if LearningPathPlannerAgent._neo4j_graph is None:
            try:
                LearningPathPlannerAgent._neo4j_graph = Neo4jGraph(
                    url=Config.NEO4J_BASE_URL,
                    username=Config.NEO4J_USERNAME,
                    password=os.getenv("NEO4J_PASSWORD")
                )
                self.log_debug("Neo4j ì—°ê²° í’€ ìƒì„± ì„±ê³µ")
                return True
            except Exception as e:
                self.log_debug(f"Neo4j ì—°ê²° ì‹¤íŒ¨: {e}")
                LearningPathPlannerAgent._connection_failed = True
                return False
        return True

    async def _call_openai_llm(self, system_prompt: str, user_prompt: str) -> str:
        """OpenAI GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ LLM í˜¸ì¶œ"""
        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            response = await self.openai_llm.ainvoke(messages)
            return response.content
        except Exception as e:
            self.log_debug(f"OpenAI LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            # fallback to base agent's LLM
            return await self.call_llm(system_prompt, user_prompt)

    def _convert_neo4j_datetime(self, obj):
        """Neo4j DateTime ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
        if isinstance(obj, DateTime):
            return obj.isoformat()
        elif isinstance(obj, dict):
            return {key: self._convert_neo4j_datetime(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_neo4j_datetime(item) for item in obj]
        else:
            return obj

    async def execute(self, state: CurriculumState) -> CurriculumState:
        """í•™ìŠµ ê²½ë¡œ ê³„íš ì‹¤í–‰"""
        try:
            self.safe_update_phase(state, ProcessingPhase.LEARNING_PATH_PLANNING, "ğŸ§  í•™ìŠµ ê²½ë¡œ ë¶„ì„ ì¤‘...")

            focus_text = ', '.join(state["focus_areas"]) if state["focus_areas"] else 'General coverage'

            # 1. ê¸°ë³¸ í•™ìŠµ ê²½ë¡œ ë¶„ì„
            analysis_text = await self._analyze_learning_path(
                topic=state["topic"],
                level=state["level"],
                duration_weeks=state["duration_weeks"],
                focus_areas=focus_text
            )

            # 2. Neo4j ê·¸ë˜í”„ì—ì„œ ì‹¤ì œ í•™ìŠµ ë¦¬ì†ŒìŠ¤ ê²€ìƒ‰
            graph_curriculum = await self._search_graph_curriculum(
                topic=state["topic"],
                goal=state["goal"],
                level=state["level"]
            )

            # ìƒíƒœ ì—…ë°ì´íŠ¸
            state["learning_path_analysis"] = analysis_text
            state["graph_curriculum"] = graph_curriculum

            self.log_debug(f"Learning path analysis completed: {len(analysis_text)} characters")
            if graph_curriculum:
                self.log_debug(f"Graph curriculum found: {len(graph_curriculum)} procedures")
            else:
                self.log_debug("No graph curriculum found")

            return state

        except Exception as e:
            return self.handle_error(state, e, "Learning path planning failed")

    async def _analyze_learning_path(self, topic: str, level: str, duration_weeks: int, focus_areas: str) -> str:
        """í•™ìŠµ ê²½ë¡œ ë¶„ì„"""

        system_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ ì„¤ê³„ìì…ë‹ˆë‹¤. í•™ìŠµìì˜ ìš”êµ¬ì— ë§ëŠ” ìµœì ì˜ í•™ìŠµ ê²½ë¡œë¥¼ ë¶„ì„í•˜ê³  ì„¤ê³„í•´ì£¼ì„¸ìš”."""

        user_prompt = f"""ë‹¤ìŒ í•™ìŠµ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ì²´ê³„ì ì¸ í•™ìŠµ ê³„íšì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”:

í•™ìŠµ ì£¼ì œ: {topic}
í•™ìŠµ ë ˆë²¨: {level}
í•™ìŠµ ê¸°ê°„: {duration_weeks}ì£¼
í¬ì»¤ìŠ¤ ì˜ì—­: {focus_areas}

ë¨¼ì € ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì´ ì£¼ì œì˜ í•µì‹¬ í•™ìŠµ ì˜ì—­ì€ ë¬´ì—‡ì¸ê°€?
2. {level} ìˆ˜ì¤€ì—ì„œ ì‹œì‘í•˜ì—¬ ì–´ë–¤ ìˆœì„œë¡œ í•™ìŠµí•´ì•¼ í•˜ëŠ”ê°€?
3. {focus_areas}ë¥¼ ê³ ë ¤í•  ë•Œ ì¤‘ì ì„ ë‘¬ì•¼ í•  ë¶€ë¶„ì€?
4. {duration_weeks}ì£¼ ë™ì•ˆ í˜„ì‹¤ì ìœ¼ë¡œ ë‹¬ì„± ê°€ëŠ¥í•œ ëª©í‘œëŠ”?

ë¶„ì„ ê²°ê³¼ë¥¼ ìì„¸íˆ ì„¤ëª…í•˜ê³ , ì „ì²´ í•™ìŠµ ë¡œë“œë§µì„ ì œì‹œí•´ì£¼ì„¸ìš”."""

        analysis_text = await self._call_openai_llm(system_prompt, user_prompt)
        return analysis_text

    async def _search_graph_curriculum(self, topic: str, goal: str, level: str) -> Dict[str, Any]:
        """Neo4j ê·¸ë˜í”„ì—ì„œ í•™ìŠµ ì»¤ë¦¬í˜ëŸ¼ ê²€ìƒ‰"""
        try:
            self.log_debug(f"Starting Neo4j graph search for topic: {topic}")

            # ì—°ê²° í’€ì—ì„œ ê¸°ì¡´ ì—°ê²° ì‚¬ìš©
            if not self._ensure_neo4j_connection():
                self.log_debug("Neo4j ì—°ê²° ì‚¬ìš© ë¶ˆê°€, fallback ì‚¬ìš©")
                return self._create_fallback_graph_curriculum(topic, goal, level)

            graph = LearningPathPlannerAgent._neo4j_graph
            self.log_debug("Using existing Neo4j connection pool")

            # ì‚¬ìš©ì í”„ë¡œíŒŒì¼ êµ¬ì„±
            user_profile = {
                "ì£¼ì œ": topic,
                "ëª©í‘œ": goal,
                "ì‹œê°„": "ì£¼2ì‹œê°„",  # ê¸°ë³¸ê°’
                "ìˆ˜ì¤€": level or "ì´ˆê¸‰"
            }

            # ê·¸ë˜í”„ ê²€ìƒ‰ ì‹¤í–‰
            curriculum_result = await self._graph_search(graph, user_profile)

            if curriculum_result:
                self.log_debug("Graph search completed successfully")
                return curriculum_result
            else:
                self.log_debug("Graph search returned empty result, using fallback")
                return self._create_fallback_graph_curriculum(topic, goal, level)

        except Exception as e:
            self.log_debug(f"Graph search failed: {e}")
            return self._create_fallback_graph_curriculum(topic, goal, level)

    async def _graph_search(self, graph, user_profile: Dict[str, str]) -> Dict[str, Any]:
        """ê·¸ë˜í”„ì—ì„œ í•™ìŠµ ì»¤ë¦¬í˜ëŸ¼ ê²€ìƒ‰ (neo4j_search_test.py ê¸°ë°˜)"""

        # ìºì‹œëœ ìŠ¤í‚¬ ëª©ë¡ ì‚¬ìš© (í´ë˜ìŠ¤ ë ˆë²¨ ìºì‹±)
        if not hasattr(LearningPathPlannerAgent, '_cached_skills'):
            self.log_debug("ìŠ¤í‚¬ ëª©ë¡ ìºì‹± ì¤‘...")
            # ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤í‚¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            skills_query = """
            MATCH (s:Skill)
            RETURN s.name as name, s.keywords as keywords, s.category as category, s.description as description
            ORDER BY s.name
            """

            try:
                skills_result = await asyncio.to_thread(graph.query, skills_query)
                LearningPathPlannerAgent._cached_skills = skills_result
                self.log_debug(f"ìŠ¤í‚¬ ëª©ë¡ ìºì‹± ì™„ë£Œ: {len(skills_result)}ê°œ")
            except Exception as e:
                self.log_debug(f"ìŠ¤í‚¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
                return None
        else:
            skills_result = LearningPathPlannerAgent._cached_skills
            self.log_debug(f"ìºì‹œëœ ìŠ¤í‚¬ ëª©ë¡ ì‚¬ìš©: {len(skills_result)}ê°œ")

        # ìŠ¤í‚¬ ì •ë³´ë¥¼ ì •ë¦¬
        skills_context = ""
        skills_list = []
        for i, skill in enumerate(skills_result, 1):
            skill_name = skill['name']
            skills_list.append(skill_name)
            skills_context += f"'{skill_name}'\n"

        self.log_debug(f"ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤í‚¬ ê°œìˆ˜: {len(skills_list)}ê°œ")

        # í•™ìŠµ ì ˆì°¨ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
        prompt = f"""
ì‚¬ìš©ì í”„ë¡œíŒŒì¼ì„ ë¶„ì„í•˜ì—¬ í•™ìŠµ ì ˆì°¨ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì í”„ë¡œíŒŒì¼:
- ì£¼ì œ: {user_profile['ì£¼ì œ']}
- ëª©í‘œ: {user_profile['ëª©í‘œ']}
- ì‹œê°„: {user_profile['ì‹œê°„']}
- ìˆ˜ì¤€: {user_profile['ìˆ˜ì¤€']}

=== ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤í‚¬ ëª©ë¡ (ì´ {len(skills_list)}ê°œ) ===
{skills_context}

=== ì ˆëŒ€ì  ì œì•½ ì¡°ê±´ ===
**ì¤‘ìš”: ìŠ¤í‚¬ëª…ì€ ë°˜ë“œì‹œ ìœ„ ëª©ë¡ì—ì„œ ë”°ì˜´í‘œ ì•ˆì˜ ë‚´ìš©ì„ ì •í™•í•˜ê²Œ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”**
1. ìœ„ì— ë‚˜ì—´ëœ ìŠ¤í‚¬ëª…ì„ í•œ ê¸€ìë„ ë°”ê¾¸ì§€ ë§ê³  ë”°ì˜´í‘œ ì•ˆì˜ ë‚´ìš©ì„ ì •í™•íˆ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”
2. ìŠ¤í‚¬ëª…ì˜ ëŒ€ì†Œë¬¸ì, ê³µë°±, íŠ¹ìˆ˜ë¬¸ì, í•œê¸€/ì˜ì–´ ëª¨ë‘ ì •í™•íˆ ì¼ì¹˜ì‹œì¼œì•¼ í•©ë‹ˆë‹¤
3. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìŠ¤í‚¬ëª…ì„ ì„ì˜ë¡œ ë§Œë“¤ê±°ë‚˜ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”
4. ë°˜ë“œì‹œ ìœ„ ëª©ë¡ì— ìˆëŠ” ìŠ¤í‚¬ëª…ë§Œ ì‚¬ìš©í•˜ì„¸ìš”!

=== ì‘ì—… ìš”êµ¬ì‚¬í•­ ===
1. ì‚¬ìš©ìì˜ ëª©í‘œì™€ ìˆ˜ì¤€ì— ë§ëŠ” 3-7ê°œì˜ í•™ìŠµ ì ˆì°¨ ìƒì„±
2. ê° ì ˆì°¨ë³„ë¡œ ê´€ë ¨ ìŠ¤í‚¬ 3-5ê°œ ì„ íƒ
3. ì ˆì°¨ëŠ” ë…¼ë¦¬ì  ìˆœì„œë¡œ ë°°ì—´
4. ìˆ˜ì¤€ì— ë§ëŠ” ì ì ˆí•œ ë‚œì´ë„ë¡œ êµ¬ì„±

=== ì¶œë ¥ í˜•ì‹ ===
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{{
    "ì ˆì°¨1": {{
        "title": "êµ¬ì²´ì ì¸ í•™ìŠµ ë‹¨ê³„ ì œëª©",
        "skills": ["ìŠ¤í‚¬ëª©ë¡ì—_ìˆëŠ”_ìŠ¤í‚¬ëª…1", "ìŠ¤í‚¬ëª©ë¡ì—_ìˆëŠ”_ìŠ¤í‚¬ëª…2", "ìŠ¤í‚¬ëª©ë¡ì—_ìˆëŠ”_ìŠ¤í‚¬ëª…3"]
    }},
    "ì ˆì°¨2": {{
        "title": "êµ¬ì²´ì ì¸ í•™ìŠµ ë‹¨ê³„ ì œëª©",
        "skills": ["ìŠ¤í‚¬ëª©ë¡ì—_ìˆëŠ”_ìŠ¤í‚¬ëª…4", "ìŠ¤í‚¬ëª©ë¡ì—_ìˆëŠ”_ìŠ¤í‚¬ëª…5"]
    }}
}}

âš ï¸ ê²½ê³ : ëª©ë¡ì— ì—†ëŠ” ìŠ¤í‚¬ëª…ì„ ì‚¬ìš©í•˜ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ„ ëª©ë¡ì˜ ìŠ¤í‚¬ëª…ì„ ì •í™•íˆ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.

JSONë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""

        # LLM í˜¸ì¶œ ë° ê²€ì¦ ì¬ì‹œë„ ë¡œì§
        max_retries = 3
        learning_path = None

        for attempt in range(max_retries):
            try:
                self.log_debug(f"í•™ìŠµ ì ˆì°¨ ìƒì„± ì‹œë„ ({attempt + 1}/{max_retries})...")

                # LLM í˜¸ì¶œí•˜ì—¬ í•™ìŠµ ì ˆì°¨ ìƒì„±
                response = await self._call_openai_llm(
                    "ë‹¹ì‹ ì€ êµìœ¡ê³¼ì • ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ìŠ¤í‚¬ ëª©ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì¸ í•™ìŠµ ì ˆì°¨ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                    prompt
                )

                # ì‘ë‹µ ì •ë¦¬
                content = response.strip()
                if content.startswith('```json'):
                    content = content[7:]
                if content.startswith('```'):
                    content = content[3:]
                if content.endswith('```'):
                    content = content[:-3]
                content = content.strip()

                # JSON íŒŒì‹±
                parsed_json = json.loads(content)

                # êµ¬ì¡° ê²€ì¦
                self._validate_learning_path_structure(parsed_json)
                self._validate_skill_names(parsed_json, skills_list)

                learning_path = parsed_json
                self.log_debug("í•™ìŠµ ì ˆì°¨ ìƒì„± ì„±ê³µ!")
                break

            except json.JSONDecodeError as e:
                self.log_debug(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            except ValueError as e:
                self.log_debug(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: ê²€ì¦ ì‹¤íŒ¨: {e}")
            except Exception as e:
                self.log_debug(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")

            if attempt < max_retries - 1:
                await asyncio.sleep(2)

        if learning_path is None:
            self.log_debug(f"ìµœëŒ€ ì¬ì‹œë„ ({max_retries}íšŒ) í›„ì—ë„ í•™ìŠµ ì ˆì°¨ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return None

        self.log_debug(f"í•™ìŠµ ì ˆì°¨ ìƒì„± ì™„ë£Œ: {len(learning_path)}ê°œ ì ˆì°¨")

        # ë¬¸ì„œ ë° ì „ë¬¸ê°€ ì •ë³´ ìˆ˜ì§‘
        enriched_learning_path = await self._enrich_with_documents_and_experts(graph, learning_path)

        return enriched_learning_path

    async def _enrich_with_documents_and_experts(self, graph, learning_path: Dict) -> Dict[str, Any]:
        """í•™ìŠµ ì ˆì°¨ì— ë¬¸ì„œì™€ ì „ë¬¸ê°€ ì •ë³´ ì¶”ê°€ (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”)"""

        # ëª¨ë“  ìŠ¤í‚¬ ì´ë¦„ ìˆ˜ì§‘
        all_skills = []
        for procedure_data in learning_path.values():
            all_skills.extend(procedure_data['skills'])

        # ë°°ì¹˜ë¡œ ëª¨ë“  ìŠ¤í‚¬ì˜ ë¬¸ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        batch_skill_to_doc_query = """
        MATCH (s:Skill)<-[:COVERS]-(d:Document)
        WHERE s.name IN $skill_names
           OR ANY(skill IN $skill_names WHERE s.name CONTAINS skill OR s.keywords CONTAINS skill)
        RETURN s, d
        """

        try:
            self.log_debug(f"ë°°ì¹˜ë¡œ {len(all_skills)}ê°œ ìŠ¤í‚¬ì˜ ë¬¸ì„œ ì •ë³´ ì¡°íšŒ ì¤‘...")
            batch_docs_result = await asyncio.to_thread(graph.query, batch_skill_to_doc_query, {"skill_names": all_skills})
            self.log_debug(f"ë°°ì¹˜ ì¡°íšŒ ì™„ë£Œ: {len(batch_docs_result)}ê°œ ê²°ê³¼")
        except Exception as e:
            self.log_debug(f"ë°°ì¹˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            batch_docs_result = []

        # ìŠ¤í‚¬ë³„ë¡œ ê²°ê³¼ ê·¸ë£¹í™”
        skill_docs_map = {}
        for record in batch_docs_result:
            skill_name = record['s']['name']
            if skill_name not in skill_docs_map:
                skill_docs_map[skill_name] = []
            skill_docs_map[skill_name].append(record)

        async def process_skill(skill_name: str):
            """ë‹¨ì¼ ìŠ¤í‚¬ì— ëŒ€í•œ ë¬¸ì„œì™€ ì „ë¬¸ê°€ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
            self.log_debug(f"ìŠ¤í‚¬ ì²˜ë¦¬: {skill_name}")

            skill_data = {
                "skill_info": {},
                "documents": {}
            }

            # ë°°ì¹˜ ê²°ê³¼ì—ì„œ í•´ë‹¹ ìŠ¤í‚¬ ì°¾ê¸°
            skill_docs_result = []
            for mapped_skill, records in skill_docs_map.items():
                if (skill_name == mapped_skill or
                    skill_name in mapped_skill or
                    mapped_skill in skill_name):
                    skill_docs_result.extend(records)
                    break

            try:
                if not skill_docs_result:
                    self.log_debug(f"    -> ë¬¸ì„œ 0ê°œ ë°œê²¬")
                    return skill_name, skill_data

                first_result = skill_docs_result[0]
                skill_data["skill_info"] = self._convert_neo4j_datetime({
                    "name": first_result['s']['name'],
                    "category": first_result['s'].get('category', ''),
                    "description": first_result['s'].get('description', ''),
                    "keywords": first_result['s'].get('keywords', ''),
                    "difficulty": first_result['s'].get('difficulty', ''),
                    "importance_score": first_result['s'].get('importance_score', '')
                })

                async def get_experts_for_doc(doc_record):
                    doc_id = doc_record['d']['doc_id']
                    doc_title = doc_record['d']['title']
                    doc_info = self._convert_neo4j_datetime({
                        "doc_id": doc_id,
                        "title": doc_title,
                        "department": doc_record['d'].get('department', ''),
                        "document_type": doc_record['d'].get('document_type', ''),
                        "target_audience": doc_record['d'].get('target_audience', ''),
                        "difficulty_level": doc_record['d'].get('difficulty_level', ''),
                        "estimated_time": doc_record['d'].get('estimated_time', ''),
                        "confidential_level": doc_record['d'].get('confidential_level', ''),
                        "folder_path": doc_record['d'].get('folder_path', ''),
                        "created_date": doc_record['d'].get('created_date', ''),
                        "updated_date": doc_record['d'].get('updated_date', ''),
                        "experts": {}
                    })

                    # ë¬¸ì„œ ì½˜í…ì¸  ì½ê¸°
                    if doc_title:
                        content = self._read_document_content_by_title(doc_title)
                        if content:
                            doc_info["content"] = content
                            doc_info["content_length"] = len(content)
                        else:
                            doc_info["content"] = ""
                            doc_info["content_length"] = 0

                    doc_to_expert_query = """
                    MATCH (d:Document)<-[:AUTHORED]-(p:Person)
                    WHERE d.doc_id = $doc_id
                    RETURN p
                    """
                    experts_result = await asyncio.to_thread(graph.query, doc_to_expert_query, {"doc_id": doc_id})

                    for expert_record in experts_result:
                        expert_name = expert_record['p']['name']
                        doc_info["experts"][expert_name] = self._convert_neo4j_datetime({
                            "name": expert_name,
                            "department": expert_record['p'].get('department', ''),
                            "role": expert_record['p'].get('role', ''),
                            "expertise": expert_record['p'].get('expertise', ''),
                            "updated_date": expert_record['p'].get('updated_date', '')
                        })
                    return doc_id, doc_info

                expert_tasks = [get_experts_for_doc(record) for record in skill_docs_result]
                document_results = await asyncio.gather(*expert_tasks)

                for doc_id, doc_info in document_results:
                    skill_data["documents"][doc_id] = doc_info

                self.log_debug(f"    -> ë¬¸ì„œ {len(skill_data['documents'])}ê°œ ë°œê²¬")

            except Exception as e:
                self.log_debug(f"    -> ì˜¤ë¥˜ ë°œìƒ: {e}")
                skill_data["error"] = str(e)

            return skill_name, skill_data

        async def process_procedure(procedure_key, procedure_data):
            self.log_debug(f"ì ˆì°¨ ì²˜ë¦¬: {procedure_key} - {procedure_data['title']}")

            skill_tasks = [process_skill(skill_name) for skill_name in procedure_data['skills']]
            processed_skills = await asyncio.gather(*skill_tasks)

            enriched_procedure = {
                "title": procedure_data['title'],
                "skills": dict(processed_skills)
            }

            self.log_debug(f"  {procedure_key} ì™„ë£Œ!")
            return procedure_key, enriched_procedure

        procedure_tasks = [
            process_procedure(key, data) for key, data in learning_path.items()
        ]

        processed_procedures = await asyncio.gather(*procedure_tasks)

        enriched_learning_path = dict(processed_procedures)

        # ì „ì²´ ê²°ê³¼ì— DateTime ë³€í™˜ ì ìš©
        enriched_learning_path = self._convert_neo4j_datetime(enriched_learning_path)

        self.log_debug("í•™ìŠµ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì™„ë£Œ")
        return enriched_learning_path

    def _validate_learning_path_structure(self, data: Dict) -> None:
        """í•™ìŠµ ê²½ë¡œ êµ¬ì¡° ê²€ì¦"""
        if not isinstance(data, dict):
            raise ValueError("ê²°ê³¼ëŠ” ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤")

        for key, value in data.items():
            if not key.startswith('ì ˆì°¨'):
                raise ValueError(f"í‚¤ëŠ” 'ì ˆì°¨'ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤: {key}")

            if 'title' not in value or 'skills' not in value:
                raise ValueError(f"{key}ì— í•„ìˆ˜ í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤")

            if not isinstance(value['skills'], list):
                raise ValueError(f"{key}ì˜ 'skills'ëŠ” ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤")

    def _validate_skill_names(self, learning_path: Dict, available_skills: List[str]) -> None:
        """ì„ íƒëœ ìŠ¤í‚¬ëª…ì´ ì‹¤ì œ DBì— ì¡´ì¬í•˜ëŠ”ì§€ ê²€ì¦"""
        available_skills_set = set(available_skills)

        for procedure_key, procedure_data in learning_path.items():
            for skill_name in procedure_data['skills']:
                if skill_name not in available_skills_set:
                    self.log_debug(f"ê²½ê³ : '{skill_name}'ì€ DBì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìŠ¤í‚¬ì…ë‹ˆë‹¤ ({procedure_key})")
                    raise ValueError(f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìŠ¤í‚¬: {skill_name}")


    def _create_fallback_graph_curriculum(self, topic: str, goal: str, level: str) -> Dict[str, Any]:
        """Neo4j ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ graph_curriculum ìƒì„±"""
        self.log_debug("Creating fallback graph curriculum")

        # ê¸°ë³¸ì ì¸ í•™ìŠµ ì ˆì°¨ ìƒì„±
        fallback_curriculum = {
            "ì ˆì°¨1": {
                "title": f"{topic} ê¸°ì´ˆ ì´í•´",
                "skills": {
                    f"{topic} ê¸°ì´ˆ": {
                        "skill_info": {
                            "name": f"{topic} ê¸°ì´ˆ",
                            "category": "ê¸°ì´ˆ",
                            "description": f"{topic}ì˜ ê¸°ë³¸ ê°œë…ê³¼ ì›ë¦¬ í•™ìŠµ",
                            "keywords": [topic, "ê¸°ì´ˆ", "ê°œë…"],
                            "difficulty": level,
                            "importance_score": 8
                        },
                        "documents": {
                            "basic_doc": {
                                "doc_id": "fallback_basic",
                                "title": f"{topic} ê¸°ì´ˆ í•™ìŠµ ê°€ì´ë“œ",
                                "department": "êµìœ¡",
                                "document_type": "guide",
                                "target_audience": f"{topic} í•™ìŠµì",
                                "difficulty_level": level,
                                "estimated_time": 120,
                                "experts": {
                                    "êµìœ¡ì „ë¬¸ê°€": {
                                        "name": "êµìœ¡ì „ë¬¸ê°€",
                                        "department": "êµìœ¡",
                                        "role": "ì „ë¬¸ê°€",
                                        "expertise": f"{topic} êµìœ¡ ë° ì»¨ì„¤íŒ…"
                                    }
                                }
                            }
                        }
                    }
                }
            },
            "ì ˆì°¨2": {
                "title": f"{topic} ì‹¤ìŠµ ë° ì‘ìš©",
                "skills": {
                    f"{topic} ì‹¤ìŠµ": {
                        "skill_info": {
                            "name": f"{topic} ì‹¤ìŠµ",
                            "category": "ì‹¤ìŠµ",
                            "description": f"{topic}ì„ í™œìš©í•œ ì‹¤ì œ í”„ë¡œì íŠ¸ ìˆ˜í–‰",
                            "keywords": [topic, "ì‹¤ìŠµ", "í”„ë¡œì íŠ¸"],
                            "difficulty": level,
                            "importance_score": 9
                        },
                        "documents": {
                            "practice_doc": {
                                "doc_id": "fallback_practice",
                                "title": f"{topic} ì‹¤ìŠµ í”„ë¡œì íŠ¸ ê°€ì´ë“œ",
                                "department": "êµìœ¡",
                                "document_type": "project",
                                "target_audience": f"{topic} í•™ìŠµì",
                                "difficulty_level": level,
                                "estimated_time": 180,
                                "experts": {
                                    "í”„ë¡œì íŠ¸ë§¤ë‹ˆì €": {
                                        "name": "í”„ë¡œì íŠ¸ë§¤ë‹ˆì €",
                                        "department": "êµìœ¡",
                                        "role": "ë§¤ë‹ˆì €",
                                        "expertise": f"{topic} í”„ë¡œì íŠ¸ ê´€ë¦¬"
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }

        return fallback_curriculum

    def _read_document_content_by_title(self, title: str, docs_directory: str = None) -> str:
        """
        ë¬¸ì„œ ì œëª©ì„ ê¸°ë°˜ìœ¼ë¡œ docs ë””ë ‰í† ë¦¬ì—ì„œ í•´ë‹¹ JSON íŒŒì¼ì„ ì°¾ì•„ ì½˜í…ì¸ ë¥¼ ì½ì–´ì˜¤ëŠ” í•¨ìˆ˜ (ìºì‹±)

        Args:
            title (str): ë¬¸ì„œ ì œëª© (ì˜ˆ: "MESìš´ì˜ë§¤ë‰´ì–¼_2024í•˜ë°˜ê¸°")
            docs_directory (str): ë¬¸ì„œê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ

        Returns:
            str: íŒŒì¼ ë‚´ìš© ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€
        """
        if docs_directory is None:
            docs_directory = "/Users/jinwoo/Documents/project/2025_kt_intelligence/learnmate-ai/docs"

        # ìºì‹œ í™•ì¸
        if title in LearningPathPlannerAgent._document_cache:
            self.log_debug(f"ìºì‹œëœ ë¬¸ì„œ ì‚¬ìš©: '{title}'")
            return LearningPathPlannerAgent._document_cache[title]

        self.log_debug(f"ë¬¸ì„œ ì½˜í…ì¸  ì½ê¸° ì‹œë„: '{title}'")

        if not title:
            return ""

        # ì œëª©ì— í™•ì¥ìê°€ ì—†ìœ¼ë©´ .jsonì„ ì¶”ê°€
        if not title.endswith('.json'):
            filename = f"{title}.json"
        else:
            filename = title

        file_path = os.path.join(docs_directory, filename)

        try:
            # JSON íŒŒì¼ ì½ê¸°
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ìºì‹œì— ì €ì¥
            LearningPathPlannerAgent._document_cache[title] = content
            self.log_debug(f"íŒŒì¼ ì½ê¸° ì„±ê³µ! (í¬ê¸°: {len(content)} ë¬¸ì) - ìºì‹œì— ì €ì¥")
            return content

        except FileNotFoundError:
            # ì •í™•í•œ íŒŒì¼ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°, ìœ ì—°í•œ ê²€ìƒ‰
            try:
                def normalize_string(s):
                    """íŠ¹ìˆ˜ë¬¸ì, ê³µë°±, í™•ì¥ìë¥¼ ì œê±°í•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜"""
                    # í™•ì¥ì ì œê±°
                    if s.endswith('.json'):
                        s = s[:-5]
                    # íŠ¹ìˆ˜ë¬¸ìì™€ ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜
                    return re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', s).lower()

                available_files = os.listdir(docs_directory)
                normalized_title = normalize_string(title)

                # 1ë‹¨ê³„: ê³µë°± ì œê±°í•´ì„œ ì •í™• ë§¤ì¹­
                title_no_space = title.replace(' ', '')
                if not title_no_space.endswith('.json'):
                    title_no_space += '.json'

                exact_match_no_space = os.path.join(docs_directory, title_no_space)
                if os.path.exists(exact_match_no_space):
                    with open(exact_match_no_space, 'r', encoding='utf-8') as f:
                        content = f.read()
                    # ìºì‹œì— ì €ì¥
                    LearningPathPlannerAgent._document_cache[title] = content
                    self.log_debug(f"ê³µë°± ì œê±° ë§¤ì¹­ìœ¼ë¡œ íŒŒì¼ '{title_no_space}' ì½ê¸° ì„±ê³µ! - ìºì‹œì— ì €ì¥")
                    return content

                # 2ë‹¨ê³„: ìœ ì—°í•œ ë¬¸ìì—´ í¬í•¨ ê²€ìƒ‰
                matches = []
                for file in available_files:
                    if file.endswith('.json'):
                        normalized_filename = normalize_string(file)

                        # ì–‘ë°©í–¥ í¬í•¨ ê²€ìƒ‰
                        if normalized_title in normalized_filename or normalized_filename in normalized_title:
                            matches.append((file, 'exact_contain'))
                        # ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
                        elif len(normalized_title) > 3 and normalized_title[:4] in normalized_filename:
                            matches.append((file, 'partial_match'))

                # 3ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
                if not matches:
                    title_words = [word for word in re.findall(r'[ê°€-í£a-zA-Z0-9]+', title) if len(word) > 1]
                    for file in available_files:
                        if file.endswith('.json'):
                            normalized_filename = normalize_string(file)
                            # ì œëª©ì˜ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ íŒŒì¼ëª…ì— í¬í•¨ë˜ë©´ ë§¤ì¹­
                            if any(normalize_string(word) in normalized_filename for word in title_words):
                                matches.append((file, 'keyword_match'))

                if matches:
                    # ë§¤ì¹­ ìš°ì„ ìˆœìœ„
                    matches.sort(key=lambda x: {'exact_contain': 0, 'partial_match': 1, 'keyword_match': 2}[x[1]])

                    # ê°€ì¥ ì¢‹ì€ ë§¤ì¹˜ ì„ íƒ
                    best_match_file = matches[0][0]
                    similar_path = os.path.join(docs_directory, best_match_file)
                    with open(similar_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    # ìºì‹œì— ì €ì¥
                    LearningPathPlannerAgent._document_cache[title] = content
                    self.log_debug(f"ìœ ì‚¬í•œ íŒŒì¼ '{best_match_file}' ì½ê¸° ì„±ê³µ! - ìºì‹œì— ì €ì¥")
                    return content

                self.log_debug(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
                return ""

            except Exception as e:
                self.log_debug(f"ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                return ""

        except json.JSONDecodeError as e:
            self.log_debug(f"JSON íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜: {e}")
            return ""
        except Exception as e:
            self.log_debug(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            return ""
