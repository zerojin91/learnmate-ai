"""
LangGraph ê¸°ë°˜ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì„œë²„ (v2)
ê¸°ì¡´ generate_curriculum.pyë¥¼ LangGraph Agent ì‹œìŠ¤í…œìœ¼ë¡œ ì™„ì „íˆ ë¦¬íŒ©í† ë§
"""
from mcp.server.fastmcp import FastMCP
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
import os
import sys
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
from enum import Enum

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config

# ìƒˆë¡œìš´ Agent ì‹œìŠ¤í…œ import
from servers.curriculum_agents.workflow import create_curriculum_workflow
from servers.curriculum_agents.state import ProcessingPhase


# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í´ë˜ìŠ¤ë“¤ ìœ ì§€
class LevelEnum(str, Enum):
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"


class SessionParameters(BaseModel):
    level: LevelEnum = Field(default=LevelEnum.BEGINNER, description="í•™ìŠµ ìˆ˜ì¤€")
    duration_weeks: int = Field(default=4, description="í•™ìŠµ ê¸°ê°„ (ì£¼ ë‹¨ìœ„, 1-24 ì‚¬ì´)", ge=1, le=24)
    focus_areas: List[str] = Field(default=[], description="ì¤‘ì  í•™ìŠµ ì˜ì—­")
    weekly_hours: int = Field(default=10, description="ì£¼ë‹¹ í•™ìŠµ ê°€ëŠ¥ ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„, 1-40 ì‚¬ì´)", ge=1, le=40)


class ExtractionRequest(BaseModel):
    constraints: str = Field(description="í•™ìŠµ ì œì•½ ì¡°ê±´")
    goal: str = Field(description="í•™ìŠµ ëª©í‘œ")


# ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ (CurriculumDB, SessionLoader) ìœ ì§€í•˜ë˜ ê°„ì†Œí™”
class CurriculumDB:
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        os.makedirs(data_dir, exist_ok=True)
        self.db_file = os.path.join(data_dir, "curriculums.json")
        self.data = self._load_data()

    def _load_data(self):
        try:
            if os.path.exists(self.db_file):
                with open(self.db_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"DEBUG: Error loading curriculum DB: {e}", file=sys.stderr)
        return {}

    def _save_data(self):
        try:
            with open(self.db_file, 'w', encoding='utf-8') as f:
                json.dump(self.data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"DEBUG: Error saving curriculum DB: {e}", file=sys.stderr)

    def save_curriculum(self, user_id: str, curriculum: Dict):
        if user_id not in self.data:
            self.data[user_id] = []

        curriculum_id = len(self.data[user_id])
        curriculum["id"] = curriculum_id
        self.data[user_id].append(curriculum)
        self._save_data()
        return curriculum_id

    def get_curriculum(self, user_id: str, curriculum_id: int) -> Optional[Dict]:
        user_curriculums = self.data.get(user_id, [])
        if 0 <= curriculum_id < len(user_curriculums):
            return user_curriculums[curriculum_id]
        return None


class SessionLoader:
    def __init__(self, sessions_dir: str = "sessions"):
        self.sessions_dir = sessions_dir

    def get_completed_sessions(self) -> List[Dict[str, Any]]:
        sessions = []
        try:
            if os.path.exists(self.sessions_dir):
                for filename in os.listdir(self.sessions_dir):
                    if filename.endswith('.json'):
                        session_path = os.path.join(self.sessions_dir, filename)
                        with open(session_path, 'r', encoding='utf-8') as f:
                            session_data = json.load(f)
                            # status=='completed' ë˜ëŠ” completed==True ëª¨ë‘ ì§€ì›
                            if (session_data.get('status') == 'completed' or
                                session_data.get('completed') == True):
                                sessions.append(session_data)
        except Exception as e:
            print(f"DEBUG: Error loading sessions: {e}", file=sys.stderr)
        return sessions

    def update_session_with_curriculum(self, session_id: str, curriculum: Dict[str, Any]) -> bool:
        try:
            session_file = os.path.join(self.sessions_dir, f"{session_id}.json")
            if os.path.exists(session_file):
                with open(session_file, 'r', encoding='utf-8') as f:
                    session_data = json.load(f)

                session_data['curriculum'] = {
                    'id': curriculum.get('curriculum_id'),
                    'title': curriculum.get('title'),
                    'generated_at': curriculum.get('generated_at')
                }

                with open(session_file, 'w', encoding='utf-8') as f:
                    json.dump(session_data, f, ensure_ascii=False, indent=2)
                return True
        except Exception as e:
            print(f"DEBUG: Error updating session with curriculum: {e}", file=sys.stderr)
        return False


# MCP ì„œë²„ ì„¤ì •
mcp = FastMCP(
    "CurriculumGenerator",
    instructions="Generate personalized learning curriculums using LangGraph agents",
    host="0.0.0.0",
    port=8006,  # ê¸°ì¡´ í¬íŠ¸ ì‚¬ìš©
)

# LLM ë° ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
def initialize_system():
    try:
        llm = ChatOpenAI(
            base_url=Config.LLM_BASE_URL,
            api_key=Config.LLM_API_KEY,
            model=Config.LLM_MODEL,
            temperature=0.7,
            max_tokens=Config.LLM_MAX_TOKENS,
            model_kwargs={"max_completion_tokens": None}
        )

        workflow = create_curriculum_workflow(llm)
        return llm, workflow, True
    except Exception as e:
        print(f"ERROR: System initialization failed: {e}", file=sys.stderr)
        return None, None, False


llm, workflow, system_available = initialize_system()
db = CurriculumDB()
session_loader = SessionLoader()


def extract_duration_from_message(message: str) -> Optional[int]:
    """ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€"""
    import re
    if not message:
        return None

    duration_patterns = [
        r'(\d+)\s*ì£¼',
        r'(\d+)\s*week',
        r'(\d+)\s*ë‹¬',
        r'(\d+)\s*month'
    ]

    for pattern in duration_patterns:
        match = re.search(pattern, message.lower())
        if match:
            duration = int(match.group(1))
            if 'month' in pattern or 'ë‹¬' in pattern:
                duration *= 4

            if 1 <= duration <= 24:
                return duration
    return None


@mcp.tool()
async def list_session_topics() -> Dict[str, Any]:
    """List all completed sessions available for curriculum generation"""
    sessions = session_loader.get_completed_sessions()
    return {
        "message": f"Found {len(sessions)} completed sessions",
        "sessions": [
            {
                "session_id": s["session_id"],
                "topic": s["topic"],
                "goal": s["goal"],
                "constraints": s["constraints"]
            }
            for s in sessions
        ],
        "all_sessions": sessions
    }


@mcp.tool()
async def generate_curriculum_from_session(session_id: str, user_message: str = "") -> Dict[str, Any]:
    """Generate curriculum from a specific session using LangGraph agents"""

    if not system_available:
        return {"error": "LangGraph system not available"}

    sessions = session_loader.get_completed_sessions()
    session_data = None

    for session in sessions:
        if session["session_id"] == session_id:
            session_data = session
            break

    if not session_data:
        return {"error": f"Session {session_id} not found"}

    print(f"DEBUG: Starting LangGraph curriculum generation for {session_id}", file=sys.stderr)

    try:
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¡œ ì»¤ë¦¬í˜ëŸ¼ ìƒì„±
        curriculum = await workflow.generate_curriculum(
            session_id=session_id,
            topic=session_data["topic"],
            constraints=session_data["constraints"],
            goal=session_data["goal"],
            user_message=user_message
        )

        print(f"DEBUG: LangGraph workflow completed successfully", file=sys.stderr)

        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        curriculum_id = db.save_curriculum(session_id, curriculum)
        curriculum["curriculum_id"] = curriculum_id

        # ì„¸ì…˜ íŒŒì¼ ì—…ë°ì´íŠ¸
        session_loader.update_session_with_curriculum(session_id, curriculum)

        return curriculum

    except Exception as e:
        print(f"ERROR: LangGraph curriculum generation failed: {e}", file=sys.stderr)
        return {"error": f"Curriculum generation failed: {str(e)}"}


@mcp.tool()
async def generate_curriculums_from_all_sessions() -> Dict[str, Any]:
    """Generate curriculums for all completed sessions using LangGraph"""

    if not system_available:
        return {"error": "LangGraph system not available"}

    sessions = session_loader.get_completed_sessions()

    if not sessions:
        return {
            "message": "No completed sessions found",
            "sessions_processed": 0,
            "curriculums_generated": 0
        }

    successful = []
    failed = []

    for session in sessions:
        session_id = session["session_id"]

        try:
            # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            existing = db.get_curriculum(session_id, 0)
            if existing:
                continue

            result = await generate_curriculum_from_session(session_id)

            if "error" in result:
                failed.append({"session_id": session_id, "error": result["error"]})
            else:
                successful.append(session_id)

        except Exception as e:
            failed.append({"session_id": session_id, "error": str(e)})

    return {
        "message": f"Processed {len(sessions)} sessions",
        "sessions_processed": len(sessions),
        "curriculums_generated": len(successful),
        "successful": successful,
        "failed": failed
    }


@mcp.tool()
async def get_curriculum(user_id: str, curriculum_id: int = 0) -> Dict[str, Any]:
    """Get a specific curriculum"""
    curriculum = db.get_curriculum(user_id, curriculum_id)
    if curriculum:
        return curriculum
    else:
        return {"error": f"Curriculum not found for user {user_id}, id {curriculum_id}"}


@mcp.tool()
async def search_learning_resources(topic: str, num_results: int = 10) -> Dict[str, Any]:
    """Search for learning resources on a topic (legacy compatibility)"""
    try:
        # ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì—ì´ì „íŠ¸ ì§ì ‘ í˜¸ì¶œ
        from servers.curriculum_agents.resource_collector import ResourceCollectorAgent
        resource_agent = ResourceCollectorAgent(llm)

        resources = await resource_agent._search_basic_resources(topic, num_results)

        return {
            "topic": topic,
            "resources": resources,
            "count": len(resources)
        }
    except Exception as e:
        return {"error": f"Resource search failed: {str(e)}"}


@mcp.tool()
async def get_curriculum_progress(session_id: str) -> Dict[str, Any]:
    """Get real-time progress of curriculum generation"""
    try:
        progress_file = f"data/progress/{session_id}.json"

        if os.path.exists(progress_file):
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            return progress_data
        else:
            return {"error": "No progress data found", "session_id": session_id}

    except Exception as e:
        return {"error": f"Failed to get progress: {str(e)}"}


if __name__ == "__main__":
    print("ğŸš€ Starting LangGraph-based Curriculum Generator")
    print(f"ğŸ¤– System available: {system_available}")
    if system_available:
        print("ğŸ¯ All LangGraph agents loaded successfully")
    else:
        print("âŒ System initialization failed - running in fallback mode")

    mcp.run()