from mcp.server.fastmcp import FastMCP
import asyncio
import httpx
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
import re
from urllib.parse import quote
import os
import glob
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from pydantic import BaseModel, Field
from enum import Enum
import sys
import os
from bs4 import BeautifulSoup
import time
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config

# ì§„í–‰ ìƒíƒœ ê´€ë¦¬ í´ë˜ìŠ¤
class CurriculumProgress:
    """ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ê³¼ì •ì˜ ì§„í–‰ ìƒíƒœë¥¼ ì¶”ì í•˜ê³  ê³µìœ í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.progress_file = f"{os.getcwd()}/data/progress/{session_id}.json"
        self.current_phase = None
        self.phase_start_time = None
        
    async def update(self, phase: str, message: str, details: dict = None, thinking: str = None):
        """ì§„í–‰ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  íŒŒì¼ì— ì €ì¥"""
        try:
            # ìƒˆë¡œìš´ í˜ì´ì¦ˆ ì‹œì‘ ì‹œ ì‹œê°„ ê¸°ë¡
            if phase != self.current_phase:
                self.current_phase = phase
                self.phase_start_time = datetime.now()
            
            progress_data = {
                "session_id": self.session_id,
                "timestamp": datetime.now().isoformat(),
                "phase": phase,
                "message": message,
                "details": details or {},
                "thinking": thinking,  # LLMì˜ ì‚¬ê³  ê³¼ì •
                "phase_duration": (datetime.now() - self.phase_start_time).total_seconds() if self.phase_start_time else 0
            }
            
            # íŒŒì¼ì— ì €ì¥ (ë®ì–´ì“°ê¸°)
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, ensure_ascii=False, indent=2)
            
            # ë””ë²„ê¹…ìš© stderr ì¶œë ¥
            print(f"PROGRESS: [{phase}] {message}", file=sys.stderr, flush=True)
            if thinking:
                print(f"THINKING: {thinking[:100]}...", file=sys.stderr, flush=True)
                
        except Exception as e:
            print(f"DEBUG: Progress update failed: {e}", file=sys.stderr, flush=True)
    
    def cleanup(self):
        """ì™„ë£Œ í›„ ì§„í–‰ ìƒíƒœ íŒŒì¼ ì‚­ì œ"""
        try:
            if os.path.exists(self.progress_file):
                os.remove(self.progress_file)
        except Exception:
            pass

# MCP ì„œë²„ ì„¤ì •
mcp = FastMCP(
    "CurriculumGenerator",
    instructions="Generate personalized learning curriculums from session data",
    host="0.0.0.0",
    port=8006,
)

# LLM ì´ˆê¸°í™”
def initialize_llm():
    try:
        llm = ChatOpenAI(
            base_url=Config.LLM_BASE_URL,
            api_key=Config.LLM_API_KEY,
            model=Config.LLM_MODEL,
            temperature=0.7,
            max_tokens=Config.LLM_MAX_TOKENS,
            model_kwargs={"max_completion_tokens": None}  # Friendli.aiì—ì„œ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒë¼ë¯¸í„° ì œê±°
        )
        # print(f"ğŸ¤– LLM initialized: {Config.LLM_MODEL}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
        return llm, True
    except Exception as e:
        # print(f"âŒ LLM initialization failed: {e}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
        return None, False

llm, llm_available = initialize_llm()

# Pydantic ëª¨ë¸ ì •ì˜
class LevelEnum(str, Enum):
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"

class SessionParameters(BaseModel):
    """ì„¸ì…˜ íŒŒë¼ë¯¸í„° ì¶”ì¶œì„ ìœ„í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥"""
    level: LevelEnum = Field(description="í•™ìŠµìì˜ ë ˆë²¨ (beginner/intermediate/advanced)")
    duration_weeks: int = Field(description="í•™ìŠµ ê¸°ê°„ (ì£¼ ë‹¨ìœ„, 1-52 ì‚¬ì´)", ge=1, le=52)  # 1ë…„ê¹Œì§€ í™•ì¥
    focus_areas: List[str] = Field(description="í•™ìŠµ í¬ì»¤ìŠ¤ ì˜ì—­ë“¤")
    
class ExtractionRequest(BaseModel):
    """íŒŒë¼ë¯¸í„° ì¶”ì¶œ ìš”ì²­"""
    constraints: str = Field(description="í•™ìŠµ ì œì•½ ì¡°ê±´")
    goal: str = Field(description="í•™ìŠµ ëª©í‘œ")

# ë°ì´í„°ë² ì´ìŠ¤ í´ë˜ìŠ¤
class CurriculumDB:
    def __init__(self, data_dir: str = "data"):
        self.curriculums = {}
        self.data_dir = data_dir
        os.makedirs(data_dir, exist_ok=True)
        self._load_data()
    
    def _load_data(self):
        try:
            file_path = os.path.join(self.data_dir, "curriculums.json")
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    self.curriculums = json.load(f)
                # print(f"ğŸ“š Loaded {len(self.curriculums)} curriculums")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
        except Exception as e:
            # print(f"âŒ Error loading data: {e}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
            self.curriculums = {}
            pass
    
    def _save_data(self):
        try:
            file_path = os.path.join(self.data_dir, "curriculums.json")
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(self.curriculums, f, indent=2, ensure_ascii=False)
        except Exception as e:
            # print(f"âŒ Error saving data: {e}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
            pass
    
    def save_curriculum(self, user_id: str, curriculum: Dict):
        if user_id not in self.curriculums:
            self.curriculums[user_id] = []
        curriculum['id'] = len(self.curriculums[user_id])
        curriculum['created_at'] = datetime.now().isoformat()
        self.curriculums[user_id].append(curriculum)
        self._save_data()
        return curriculum['id']
    
    def get_curriculum(self, user_id: str, curriculum_id: int) -> Optional[Dict]:
        if user_id in self.curriculums and curriculum_id < len(self.curriculums[user_id]):
            return self.curriculums[user_id][curriculum_id]
        return None

db = CurriculumDB()

# ì„¸ì…˜ ë°ì´í„° ë¡œë”
class SessionLoader:
    def __init__(self, sessions_dir: str = "sessions"):
        self.sessions_dir = sessions_dir
    
    def get_completed_sessions(self) -> List[Dict[str, Any]]:
        completed_sessions = []
        session_files = glob.glob(os.path.join(self.sessions_dir, "*.json"))
        
        for session_file in session_files:
            try:
                with open(session_file, 'r', encoding='utf-8') as f:
                    session_data = json.load(f)
                
                if (session_data.get("completed") and 
                    session_data.get("topic") and 
                    session_data.get("constraints") and 
                    session_data.get("goal")):
                    
                    completed_sessions.append({
                        "session_id": session_data.get("session_id"),
                        "topic": session_data.get("topic"),
                        "constraints": session_data.get("constraints"),
                        "goal": session_data.get("goal")
                    })
            except Exception as e:
                # print(f"âš ï¸ Error loading {session_file}: {e}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
                continue
        
        return completed_sessions
    
    async def extract_parameters_with_llm(self, constraints: str, goal: str, max_retries: int = 3) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì„¸ì…˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤ (ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í¬í•¨)"""
        if not llm_available:
            # print("âš ï¸ LLM not available, using fallback method")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
            return self.parse_constraints_fallback(constraints, goal)
        
        for attempt in range(max_retries):
            try:
                prompt = f"""ë‹¤ìŒ í•œêµ­ì–´ í•™ìŠµ ì œì•½ì¡°ê±´ê³¼ ëª©í‘œì—ì„œ í•™ìŠµ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

ì œì•½ì¡°ê±´: "{constraints}"
ëª©í‘œ: "{goal}"

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ë ˆë²¨ (level):
   - "ì´ˆë³´", "ì²˜ìŒ", "ì‹œì‘", "beginner" â†’ "beginner"
   - "ì¤‘ê¸‰", "ì–´ëŠì •ë„", "ì¤‘ê°„", "intermediate" â†’ "intermediate"  
   - "ê³ ê¸‰", "ì „ë¬¸", "ìˆ™ë ¨", "advanced" â†’ "advanced"

2. ê¸°ê°„ (duration_weeks):
   - "1ì£¼", "ì¼ì£¼ì¼", "1week" â†’ 1
   - "2ì£¼", "2week", "2ì¼" â†’ 2
   - "1ë‹¬", "í•œë‹¬", "1month", "4ì£¼" â†’ 4
   - "2ë‹¬", "ë‘ë‹¬", "2month", "8ì£¼" â†’ 8
   - "3ë‹¬", "ì„¸ë‹¬", "3month", "12ì£¼" â†’ 12
   - "4ê°œì›”", "4month", "16ì£¼" â†’ 16
   - "5ê°œì›”", "5month", "20ì£¼" â†’ 20
   - "6ê°œì›”", "ë°˜ë…„", "6month", "24ì£¼" â†’ 24
   - "9ê°œì›”", "9month" â†’ 36
   - "1ë…„", "12ê°œì›”", "1year", "52ì£¼" â†’ 52
   - ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ â†’ 4

3. í¬ì»¤ìŠ¤ ì˜ì—­ (focus_areas):
   - "ì›¹", "web" â†’ ["web development"]
   - "ë°ì´í„°", "data" â†’ ["data analysis"]
   - "ë¨¸ì‹ ëŸ¬ë‹", "AI", "ì¸ê³µì§€ëŠ¥" â†’ ["machine learning"]
   - "ì•±", "ëª¨ë°”ì¼", "app" â†’ ["mobile development"]
   - "ê°œì¸ í”„ë¡œì íŠ¸", "í† ì´ í”„ë¡œì íŠ¸" â†’ ["personal projects"]
   - "ì·¨ì—…", "ë©´ì ‘", "job" â†’ ["job preparation"]
   - ê¸°íƒ€ ê´€ë ¨ í‚¤ì›Œë“œë“¤ì„ í¬í•¨

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""
                
                # Pydanticì„ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥
                structured_llm = llm.with_structured_output(SessionParameters)
                
                messages = [
                    SystemMessage(content="ë‹¹ì‹ ì€ í•œêµ­ì–´ í•™ìŠµ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
                    HumanMessage(content=prompt)
                ]
                
                # print(f"ğŸ¤– LLM parameter extraction attempt {attempt + 1}/{max_retries}...")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
                result = await structured_llm.ainvoke(messages)
                
                # ì„±ê³µí•˜ë©´ ê²°ê³¼ ë°˜í™˜
                extracted_params = {
                    "level": result.level.value,
                    "duration_weeks": result.duration_weeks,
                    "focus_areas": result.focus_areas
                }
                # print(f"âœ… LLM extraction successful on attempt {attempt + 1}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
                return extracted_params
            
            except Exception as e:
                # print(f"âš ï¸ LLM extraction attempt {attempt + 1} failed: {e}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
                
                # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ê³„ì† ì¬ì‹œë„
                if attempt < max_retries - 1:
                    # print(f"ğŸ”„ Retrying... ({max_retries - attempt - 1} attempts remaining)")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
                    continue
                else:
                    # print(f"âŒ All {max_retries} LLM attempts failed, falling back to rule-based parsing")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
                    break
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ì‹œ fallback ì‚¬ìš©
        return self.parse_constraints_fallback(constraints, goal)
    
    def parse_constraints_fallback(self, constraints: str, goal: str) -> Dict[str, Any]:
        """LLM ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ê·œì¹™ ê¸°ë°˜ íŒŒì‹± (fallback)"""
        constraints_lower = constraints.lower()
        goal_lower = goal.lower()
        
        # ë ˆë²¨ íŒŒì‹±
        level = "beginner"
        if any(word in constraints_lower for word in ["ì¤‘ê¸‰", "ì–´ëŠì •ë„", "intermediate"]):
            level = "intermediate"
        elif any(word in constraints_lower for word in ["ê³ ê¸‰", "ì „ë¬¸", "advanced"]):
            level = "advanced"
        
        # ê¸°ê°„ íŒŒì‹± (ì£¼ ë‹¨ìœ„) - í™•ì¥ëœ ë²„ì „
        duration_weeks = 4  # ê¸°ë³¸ê°’
        if any(word in constraints_lower for word in ["1ì£¼", "1week"]):
            duration_weeks = 1
        elif any(word in constraints_lower for word in ["2ì£¼", "2week", "2ì¼"]):
            duration_weeks = 2
        elif any(word in constraints_lower for word in ["1ë‹¬", "1month", "4ì£¼"]):
            duration_weeks = 4
        elif any(word in constraints_lower for word in ["2ë‹¬", "2month", "8ì£¼"]):
            duration_weeks = 8
        elif any(word in constraints_lower for word in ["3ë‹¬", "3month", "12ì£¼"]):
            duration_weeks = 12
        elif any(word in constraints_lower for word in ["4ê°œì›”", "4month", "16ì£¼"]):
            duration_weeks = 16
        elif any(word in constraints_lower for word in ["5ê°œì›”", "5month", "20ì£¼"]):
            duration_weeks = 20
        elif any(word in constraints_lower for word in ["6ê°œì›”", "ë°˜ë…„", "6month", "24ì£¼"]):
            duration_weeks = 24
        elif any(word in constraints_lower for word in ["9ê°œì›”", "9month"]):
            duration_weeks = 36
        elif any(word in constraints_lower for word in ["1ë…„", "12ê°œì›”", "1year", "52ì£¼"]):
            duration_weeks = 52
        
        # í¬ì»¤ìŠ¤ ì˜ì—­ ì¶”ì¶œ
        focus_areas = []
        mappings = {
            "ì›¹": ["web development"],
            "ë°ì´í„°": ["data analysis"],
            "ë¨¸ì‹ ëŸ¬ë‹": ["machine learning"],
            "ì•±": ["mobile development"],
            "ê°œì¸ í”„ë¡œì íŠ¸": ["personal projects"],
            "ì·¨ì—…": ["job preparation"]
        }
        
        for keyword, areas in mappings.items():
            if keyword in goal_lower:
                focus_areas.extend(areas)
        
        return {
            "level": level, 
            "duration_weeks": duration_weeks,
            "focus_areas": list(set(focus_areas))
        }
    
    def update_session_with_curriculum(self, session_id: str, curriculum: Dict[str, Any]) -> bool:
        """ì„¸ì…˜ JSON íŒŒì¼ì— ì»¤ë¦¬í˜ëŸ¼ ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤"""
        try:
            session_file_path = os.path.join(self.sessions_dir, f"{session_id}.json")
            
            if not os.path.exists(session_file_path):
                # print(f"âš ï¸ Session file not found: {session_file_path}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
                return False
            
            # ê¸°ì¡´ ì„¸ì…˜ ë°ì´í„° ë¡œë“œ
            with open(session_file_path, 'r', encoding='utf-8') as f:
                session_data = json.load(f)
            
            # ëª¨ë“ˆ ë°ì´í„° ì •ê·œí™” (LLM ì˜¤ë¥˜ ìˆ˜ì •)
            modules = curriculum.get("modules", [])
            cleaned_modules = []
            
            for module in modules:
                cleaned_module = {}
                for key, value in module.items():
                    # í‚¤ ì •ê·œí™”: í•œêµ­ì–´ í‚¤ë¥¼ ì˜ì–´ë¡œ ë§¤í•‘
                    cleaned_key = key.replace("_ ", "_").replace(" _", "_").strip()
                    
                    # í•œêµ­ì–´ í‚¤ ë§¤í•‘
                    key_mapping = {
                        "key_ê°œë…ë“¤": "key_concepts",
                        "key_ê°œë…": "key_concepts",
                        "estimated_ì‹œê°„": "estimated_hours",
                        "estimated_ì‹œê°„": "estimated_hours",
                        "í•™ìŠµëª©í‘œ": "objectives",
                        "ì œëª©": "title",
                        "ì„¤ëª…": "description",
                        "ì£¼ì°¨": "week"
                    }
                    
                    if cleaned_key in key_mapping:
                        cleaned_key = key_mapping[cleaned_key]
                    
                    cleaned_module[cleaned_key] = value
                cleaned_modules.append(cleaned_module)
            
            # ì„¸ë¶€ ì»¤ë¦¬í˜ëŸ¼ ì •ë³´ ì¶”ê°€ (ì „ì²´ ë‚´ìš© í¬í•¨)
            curriculum_full = {
                "curriculum_generated": True,
                "curriculum_id": curriculum.get("curriculum_id"),
                "title": curriculum.get("title"),
                "level": curriculum.get("level"),
                "duration_weeks": curriculum.get("duration_weeks"),
                "overall_goal": curriculum.get("overall_goal"),
                "generated_at": curriculum.get("generated_at"),
                "original_constraints": curriculum.get("original_constraints"),
                "original_goal": curriculum.get("original_goal"),
                
                # ì •ê·œí™”ëœ ëª¨ë“ˆ ì •ë³´ í¬í•¨
                "modules": cleaned_modules,
                "modules_count": len(cleaned_modules),
                
                # í•™ìŠµ ìë£Œ ì •ë³´ í¬í•¨
                "resources": curriculum.get("resources", []),
                "resources_count": len(curriculum.get("resources", [])),
                
                # í†µê³„ ì •ë³´ ê³„ì‚°
                "total_estimated_hours": sum(
                    module.get("estimated_hours", module.get("estimated_ hours", 0)) 
                    for module in cleaned_modules
                ),
                "average_hours_per_week": 0  # ì„ì‹œë¡œ 0ìœ¼ë¡œ ì„¤ì •
            }
            
            # í‰ê·  ì‹œê°„ ì¬ê³„ì‚°
            total_hours = curriculum_full["total_estimated_hours"]
            duration = curriculum.get("duration_weeks", 1)
            curriculum_full["average_hours_per_week"] = (
                total_hours / duration
            ) if duration > 0 else 0
            
            session_data["curriculum"] = curriculum_full
            
            # íŒŒì¼ì— ë‹¤ì‹œ ì €ì¥
            with open(session_file_path, 'w', encoding='utf-8') as f:
                json.dump(session_data, f, indent=2, ensure_ascii=False)
            
            # print(f"âœ… Session {session_id} updated with curriculum info")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
            return True
            
        except Exception as e:
            # print(f"âŒ Failed to update session {session_id}: {e}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
            return False

session_loader = SessionLoader()

# ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ê¸°ê°„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def extract_duration_from_message(message: str) -> int:
    """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ê¸°ê°„ì„ ì¶”ì¶œí•˜ì—¬ ì£¼ ë‹¨ìœ„ë¡œ ë°˜í™˜"""
    message_lower = message.lower()
    
    # ê¸°ê°„ í‚¤ì›Œë“œ ë§¤í•‘ (ì£¼ ë‹¨ìœ„)
    duration_patterns = {
        "1ì£¼": 1, "1week": 1, "ì¼ì£¼ì¼": 1,
        "2ì£¼": 2, "2week": 2, "ì´ì£¼": 2,
        "1ê°œì›”": 4, "1month": 4, "í•œë‹¬": 4, "4ì£¼": 4,
        "2ê°œì›”": 8, "2month": 8, "ë‘ë‹¬": 8, "8ì£¼": 8,
        "3ê°œì›”": 12, "3month": 12, "ì„¸ë‹¬": 12, "12ì£¼": 12,
        "4ê°œì›”": 16, "4month": 16, "16ì£¼": 16,
        "5ê°œì›”": 20, "5month": 20, "20ì£¼": 20,
        "6ê°œì›”": 24, "6month": 24, "ë°˜ë…„": 24, "24ì£¼": 24,
        "9ê°œì›”": 36, "9month": 36,
        "1ë…„": 52, "12ê°œì›”": 52, "1year": 52, "52ì£¼": 52
    }
    
    # ë©”ì‹œì§€ì—ì„œ ê¸°ê°„ í‚¤ì›Œë“œ ì°¾ê¸°
    for keyword, weeks in duration_patterns.items():
        if keyword in message_lower:
            return weeks
    
    return None  # ê¸°ê°„ ì •ë³´ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜

# K-MOOC Summary íŒŒì‹± í—¬í¼ í•¨ìˆ˜
def parse_kmooc_summary(summary: str) -> Dict[str, str]:
    """K-MOOC summaryì—ì„œ ê°•ì¢Œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤"""
    try:
        if not summary:
            return {}
        
        parsed_info = {}
        
        # ê°•ì¢Œ ëª©í‘œ ì¶”ì¶œ
        goal_match = re.search(r'\*\*ê°•ì¢Œ ëª©í‘œ:\*\*\s*([^\n*]+)', summary)
        if goal_match:
            parsed_info["course_goal"] = goal_match.group(1).strip()
            # ê°•ì¢Œ ëª©í‘œì—ì„œ ì²« ë²ˆì§¸ ë¬¸ì¥ì„ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
            goal_text = goal_match.group(1).strip()
            # ì²« ë²ˆì§¸ ë¬¸ì¥ì´ë‚˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì œëª©ìœ¼ë¡œ ì¶”ì¶œ
            if "," in goal_text:
                parsed_info["title"] = goal_text.split(",")[0].strip()
            else:
                parsed_info["title"] = goal_text[:50] + "..." if len(goal_text) > 50 else goal_text
        
        # ì£¼ìš” ë‚´ìš© ì¶”ì¶œ
        content_match = re.search(r'\*\*ì£¼ìš” ë‚´ìš©:\*\*\s*([^\n*]+)', summary)
        if content_match:
            content = content_match.group(1).strip()
            parsed_info["main_content"] = content
            # ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ ì„¤ëª…ìœ¼ë¡œ ì‚¬ìš©
            if len(content) > 100:
                parsed_info["description"] = content[:97] + "..."
            else:
                parsed_info["description"] = content
        
        # ê°•ì¢Œ ê¸°ê°„ ì¶”ì¶œ
        duration_match = re.search(r'\*\*ê°•ì¢Œ ê¸°ê°„:\*\*[^()]*\((\d+ì£¼)\)', summary)
        if duration_match:
            parsed_info["duration"] = duration_match.group(1)
        
        # ë‚œì´ë„ ì¶”ì¶œ
        difficulty_match = re.search(r'\*\*ë‚œì´ë„:\*\*\s*([^\n*]+)', summary)
        if difficulty_match:
            parsed_info["difficulty"] = difficulty_match.group(1).strip()
        
        # ìˆ˜ì—… ì‹œê°„ ì¶”ì¶œ
        time_match = re.search(r'\*\*ìˆ˜ì—… ì‹œê°„:\*\*[^()]*ì•½\s*([^\n*()]+)', summary)
        if time_match:
            parsed_info["class_time"] = time_match.group(1).strip()
        
        print(f"DEBUG: Parsed summary - title: {parsed_info.get('title', 'N/A')}, description: {parsed_info.get('description', 'N/A')[:50]}...", file=sys.stderr, flush=True)
        
        return parsed_info
        
    except Exception as e:
        print(f"DEBUG: Summary parsing failed: {e}", file=sys.stderr, flush=True)
        return {}

# K-MOOC DB ê²€ìƒ‰ (Pinecone API ì—°ë™)
async def search_kmooc_resources(topic: str, week_title: str = None, top_k: int = 5) -> List[Dict[str, Any]]:
    """K-MOOC DBì—ì„œ ê´€ë ¨ ì˜ìƒì„ ê²€ìƒ‰í•©ë‹ˆë‹¤"""
    try:
        # Pinecone ê²€ìƒ‰ API í˜¸ì¶œ
        search_query = f"{topic}"
        if week_title:
            search_query += f" {week_title}"
            
        search_payload = {
            "query": search_query,
            "top_k": top_k,
            "namespace": "kmooc_engineering",
            "filter": {"institution": {"$ne": ""}},
            "rerank": True,
            "include_metadata": True
        }
        
        # pinecone_use.py ì„œë²„ê°€ localhost:8000ì—ì„œ ì‹¤í–‰ ì¤‘ì´ë¼ê³  ê°€ì •
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:8090/search",
                json=search_payload,
                timeout=10.0
            )
            
        if response.status_code == 200:
            result = response.json()
            kmooc_videos = []
            
            for item in result.get("results", []):
                metadata = item.get("metadata", {})
                if metadata:
                    # Summary íŒŒì‹±í•˜ì—¬ ê°•ì¢Œ ì •ë³´ ì¶”ì¶œ
                    summary = metadata.get("summary", "")
                    parsed_info = parse_kmooc_summary(summary)
                    
                    # ì œëª© ê²°ì •: íŒŒì‹±ëœ ì œëª© > ê¸°ë³¸ "K-MOOC ê°•ì¢Œ"
                    course_title = parsed_info.get("title") or "K-MOOC ê°•ì¢Œ"
                    
                    # ì„¤ëª… ê²°ì •: íŒŒì‹±ëœ ì„¤ëª… > ì£¼ìš” ë‚´ìš© > ê°•ì¢Œ ëª©í‘œ > ê¸°ë³¸ ë©”ì‹œì§€
                    description = (
                        parsed_info.get("description") or 
                        parsed_info.get("main_content") or 
                        parsed_info.get("course_goal") or 
                        "K-MOOC ì˜¨ë¼ì¸ ê°•ì¢Œ"
                    )
                    
                    video_info = {
                        "title": course_title,
                        "description": description,
                        "url": metadata.get("url", ""),
                        "institution": metadata.get("institution", "").replace(" ìš´ì˜ê¸°ê´€ ë°”ë¡œê°€ê¸°ìƒˆì°½ì—´ë¦¼", ""),
                        "course_goal": parsed_info.get("course_goal", ""),
                        "duration": parsed_info.get("duration", ""),
                        "difficulty": parsed_info.get("difficulty", ""),
                        "class_time": parsed_info.get("class_time", ""),
                        "score": item.get("score", 0.0),
                        "source": "K-MOOC"
                    }
                    kmooc_videos.append(video_info)
            
            return kmooc_videos
            
    except Exception as e:
        print(f"DEBUG: K-MOOC search failed: {e}", file=sys.stderr, flush=True)
        pass
    
    return []

# í•™ìŠµ ìë£Œ ê²€ìƒ‰ (ì›¹ ê²€ìƒ‰)
async def search_resources(topic: str, num_results: int = 10) -> List[Dict[str, str]]:
    try:
        encoded_query = quote(f"{topic} tutorial")
        url = f"https://lite.duckduckgo.com/lite/?q={encoded_query}"
        
        async with httpx.AsyncClient() as client:
            response = await client.get(url, timeout=10.0)
            
            if response.status_code == 200:
                content = response.text
                results = []
                
                link_pattern = r'<a[^>]*class="result-link"[^>]*href="([^"]*)"[^>]*>(.*?)</a>'
                matches = re.finditer(link_pattern, content)
                
                for i, match in enumerate(matches):
                    if len(results) >= num_results:
                        break
                    results.append({
                        "title": re.sub(r'<[^>]+>', '', match.group(2)).strip(),
                        "url": match.group(1),
                        "source": "Web Search"
                    })
                
                return results
    except Exception as e:
        # print(f"âŒ Search failed: {e}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
        pass
    
    return []

# ë¦¬ì†ŒìŠ¤ ì½˜í…ì¸  ì¶”ì¶œ í•¨ìˆ˜
async def fetch_resource_content(resource: Dict[str, str]) -> Dict[str, Any]:
    """ì›¹ ë¦¬ì†ŒìŠ¤ì˜ ì‹¤ì œ ì½˜í…ì¸ ë¥¼ ê°€ì ¸ì™€ì„œ íŒŒì‹±í•©ë‹ˆë‹¤"""
    try:
        url = resource.get('url', '')
        if not url or not url.startswith(('http://', 'https://')):
            return {
                "success": False,
                "error": "Invalid URL",
                "raw_content": "",
                "summary": "",
                "key_points": [],
                "code_examples": []
            }
        
        # ì›¹ í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        async with httpx.AsyncClient(timeout=10.0) as client:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = await client.get(url, headers=headers)
            
            if response.status_code != 200:
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}",
                    "raw_content": "",
                    "summary": "",
                    "key_points": [],
                    "code_examples": []
                }
            
            # HTML íŒŒì‹±
            soup = BeautifulSoup(response.text, 'lxml')
            
            # ë©”íƒ€ íƒœê·¸ ì œê±°
            for script in soup(["script", "style", "nav", "header", "footer", "aside"]):
                script.decompose()
            
            # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            main_content = soup.find('main') or soup.find('article') or soup.find('div', class_='content') or soup.body
            if main_content:
                text_content = main_content.get_text(separator=' ', strip=True)
            else:
                text_content = soup.get_text(separator=' ', strip=True)
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬ (ê³¼ë„í•œ ê³µë°± ì œê±°)
            cleaned_text = ' '.join(text_content.split())
            
            # ì½”ë“œ ì˜ˆì œ ì¶”ì¶œ
            code_examples = []
            code_blocks = soup.find_all(['code', 'pre'])
            for block in code_blocks:
                code_text = block.get_text(strip=True)
                if len(code_text) > 10:  # ë„ˆë¬´ ì§§ì€ ì½”ë“œëŠ” ì œì™¸
                    code_examples.append(code_text)
            
            # í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ (ì œëª© íƒœê·¸ ê¸°ë°˜)
            key_points = []
            headers = soup.find_all(['h1', 'h2', 'h3', 'h4'])
            for header in headers:
                header_text = header.get_text(strip=True)
                if len(header_text) > 5 and len(header_text) < 100:
                    key_points.append(header_text)
            
            # ìš”ì•½ ìƒì„± (ì²« 500ì)
            summary = cleaned_text[:500] + "..." if len(cleaned_text) > 500 else cleaned_text
            
            return {
                "success": True,
                "raw_content": cleaned_text[:2000],  # ìµœëŒ€ 2000ìë¡œ ì œí•œ
                "summary": summary,
                "key_points": key_points[:10],  # ìµœëŒ€ 10ê°œ
                "code_examples": code_examples[:5],  # ìµœëŒ€ 5ê°œ
                "content_length": len(cleaned_text),
                "url": url,
                "title": resource.get('title', soup.title.string if soup.title else 'No title')
            }
            
    except httpx.TimeoutException:
        return {
            "success": False,
            "error": "Request timeout",
            "raw_content": "",
            "summary": "",
            "key_points": [],
            "code_examples": []
        }
    except Exception as e:
        print(f"DEBUG: fetch_resource_content failed for {resource.get('url', 'unknown')}: {e}", file=sys.stderr, flush=True)
        return {
            "success": False,
            "error": str(e),
            "raw_content": "",
            "summary": "",
            "key_points": [],
            "code_examples": []
        }

# LLMì„ ì‚¬ìš©í•œ ë‹¨ê³„ë³„ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ë²„ì „)
async def generate_with_llm_streaming(topic: str, level: str, duration_weeks: int, focus_areas: List[str], resources: List[Dict[str, str]] = None, session_id: str = None) -> Dict[str, Any]:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ê³„ë³„ë¡œ ì»¤ë¦¬í˜ëŸ¼ì„ ìƒì„±í•˜ë©° ì§„í–‰ ìƒíƒœë¥¼ ê³µìœ """
    if not llm_available:
        return create_basic_curriculum(topic, level, duration_weeks)
    
    # ì§„í–‰ ìƒíƒœ ì¶”ì ê¸° ì´ˆê¸°í™”
    progress = CurriculumProgress(session_id) if session_id else None
    
    try:
        focus_text = ', '.join(focus_areas) if focus_areas else 'General coverage'
        
        # Phase 1: í•™ìŠµ ê²½ë¡œ ë¶„ì„
        if progress:
            await progress.update("analysis", "ğŸ§  í•™ìŠµ ê²½ë¡œë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘...")
        
        analysis_prompt = f"""ë‹¤ìŒ í•™ìŠµ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ì²´ê³„ì ì¸ í•™ìŠµ ê³„íšì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”:

í•™ìŠµ ì£¼ì œ: {topic}
í•™ìŠµ ë ˆë²¨: {level}
í•™ìŠµ ê¸°ê°„: {duration_weeks}ì£¼
í¬ì»¤ìŠ¤ ì˜ì—­: {focus_text}

ë¨¼ì € ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì´ ì£¼ì œì˜ í•µì‹¬ í•™ìŠµ ì˜ì—­ì€ ë¬´ì—‡ì¸ê°€?
2. {level} ìˆ˜ì¤€ì—ì„œ ì‹œì‘í•˜ì—¬ ì–´ë–¤ ìˆœì„œë¡œ í•™ìŠµí•´ì•¼ í•˜ëŠ”ê°€?
3. {focus_areas}ë¥¼ ê³ ë ¤í•  ë•Œ ì¤‘ì ì„ ë‘¬ì•¼ í•  ë¶€ë¶„ì€?
4. {duration_weeks}ì£¼ ë™ì•ˆ í˜„ì‹¤ì ìœ¼ë¡œ ë‹¬ì„± ê°€ëŠ¥í•œ ëª©í‘œëŠ”?

ë¶„ì„ ê²°ê³¼ë¥¼ ìì„¸íˆ ì„¤ëª…í•˜ê³ , ì „ì²´ í•™ìŠµ ë¡œë“œë§µì„ ì œì‹œí•´ì£¼ì„¸ìš”."""
        
        analysis_messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ ì„¤ê³„ìì…ë‹ˆë‹¤. í•™ìŠµìì˜ ìš”êµ¬ì— ë§ëŠ” ìµœì ì˜ í•™ìŠµ ê²½ë¡œë¥¼ ë¶„ì„í•˜ê³  ì„¤ê³„í•´ì£¼ì„¸ìš”."),
            HumanMessage(content=analysis_prompt)
        ]
        
        print(f"DEBUG: Starting Phase 1 - Learning Path Analysis", file=sys.stderr, flush=True)
        analysis_response = await llm.agenerate([analysis_messages])
        analysis_text = analysis_response.generations[0][0].text if analysis_response.generations else ""
        
        if progress:
            await progress.update("analysis", "ğŸ’¡ ë¶„ì„ ì™„ë£Œ", thinking=analysis_text[:500])
        
        # Phase 2: ì „ì²´ ëª¨ë“ˆ êµ¬ì¡° ì„¤ê³„
        if progress:
            await progress.update("structure_design", "ğŸ“‹ ì „ì²´ ëª¨ë“ˆ êµ¬ì¡°ë¥¼ ì„¤ê³„í•˜ëŠ” ì¤‘...")
        
        structure_prompt = f"""ì•ì„  ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ {duration_weeks}ì£¼ ì»¤ë¦¬í˜ëŸ¼ì˜ ì „ì²´ êµ¬ì¡°ë¥¼ ì„¤ê³„í•´ì£¼ì„¸ìš”.

ì´ì „ ë¶„ì„ ê²°ê³¼:
{analysis_text}

ê° ì£¼ì°¨ë³„ë¡œ ë‹¤ìŒ ì •ë³´ë§Œ í¬í•¨í•˜ì—¬ JSON í˜•íƒœë¡œ ìƒì„±í•´ì£¼ì„¸ìš”:
- week: ì£¼ì°¨ ë²ˆí˜¸
- title: ì£¼ì°¨ ì œëª© (í•œêµ­ì–´)
- main_topic: ì£¼ìš” í•™ìŠµ ì£¼ì œ (í•œêµ­ì–´)
- learning_goals: ì´ë²ˆ ì£¼ì°¨ì˜ í•µì‹¬ ëª©í‘œ 2-3ê°œ (í•œêµ­ì–´ ë¦¬ìŠ¤íŠ¸)
- difficulty_level: ë‚œì´ë„ (1-10)

JSON í˜•ì‹:
{{
    "modules": [
        {{
            "week": 1,
            "title": "ì£¼ì°¨ ì œëª©",
            "main_topic": "ì£¼ìš” í•™ìŠµ ì£¼ì œ", 
            "learning_goals": ["ëª©í‘œ1", "ëª©í‘œ2"],
            "difficulty_level": 3
        }}
    ],
    "overall_goal": "ì „ì²´ í•™ìŠµ ëª©í‘œ"
}}"""
        
        structure_messages = [
            SystemMessage(content="ì „ì²´ ì»¤ë¦¬í˜ëŸ¼ êµ¬ì¡°ë¥¼ ì„¤ê³„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ í•™ìŠµ íë¦„ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”."),
            HumanMessage(content=structure_prompt)
        ]
        
        print(f"DEBUG: Starting Phase 2 - Structure Design", file=sys.stderr, flush=True)
        structure_response = await llm.agenerate([structure_messages])
        structure_text = structure_response.generations[0][0].text if structure_response.generations else ""
        
        # JSON íŒŒì‹±
        json_match = re.search(r'\{[\s\S]*\}', structure_text)
        if not json_match:
            if progress:
                await progress.update("structure_design", "âŒ êµ¬ì¡° ì„¤ê³„ ì‹¤íŒ¨", details={"error": "JSON íŒŒì‹± ì‹¤íŒ¨"})
            return create_basic_curriculum(topic, level, duration_weeks)
        
        structure_data = json.loads(json_match.group())
        modules = structure_data.get("modules", [])
        
        if progress:
            # f-string ì¤‘ì²© ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ ë¶„ë¦¬
            module_titles = [m.get('title', f"{m.get('week')}ì£¼ì°¨") for m in modules[:5]]
            flow_text = ' â†’ '.join(module_titles)
            await progress.update("structure_design", f"âœ… {len(modules)}ê°œ ëª¨ë“ˆ êµ¬ì¡° ì„¤ê³„ ì™„ë£Œ", 
                                thinking=f"ì „ì²´ í•™ìŠµ íë¦„: {flow_text}...")
        
        # Phase 3: ê° ëª¨ë“ˆ ìƒì„¸ ë‚´ìš© ìƒì„±
        detailed_modules = []
        for i, module in enumerate(modules):
            if progress:
                # f-string ì¤‘ì²© ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ ë¶„ë¦¬
                module_title = module.get('title', f"{module.get('week')}ì£¼ì°¨")
                await progress.update("detail_generation", 
                                    f"ğŸ“ {module_title} ìƒì„¸ ë‚´ìš© ìƒì„± ì¤‘...",
                                    details={"current": i + 1, "total": len(modules)})
            
            detail_prompt = f"""ë‹¤ìŒ ëª¨ë“ˆì˜ ìƒì„¸ ë‚´ìš©ì„ ìƒì„±í•´ì£¼ì„¸ìš”:

ëª¨ë“ˆ ì •ë³´:
- ì£¼ì°¨: {module.get('week')}ì£¼ì°¨
- ì œëª©: {module.get('title')}
- ì£¼ìš” ì£¼ì œ: {module.get('main_topic')}
- í•™ìŠµ ëª©í‘œ: {module.get('learning_goals')}

ì´ì „ ëª¨ë“ˆë“¤: {[m.get('title') for m in detailed_modules[-2:]] if detailed_modules else 'ì—†ìŒ'}

ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•œ ìƒì„¸ ëª¨ë“ˆì„ JSONìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”:
{{
    "week": {module.get('week')},
    "title": "{module.get('title')}",
    "description": "ëª¨ë“ˆì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª… (í•œêµ­ì–´)",
    "objectives": ["êµ¬ì²´ì ì¸ í•™ìŠµëª©í‘œ1", "í•™ìŠµëª©í‘œ2", "í•™ìŠµëª©í‘œ3"],
    "learning_outcomes": ["ë‚´ê°€ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê²ƒ1", "ë‚´ê°€ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê²ƒ2"],
    "key_concepts": ["í•µì‹¬ê°œë…1", "í•µì‹¬ê°œë…2", "í•µì‹¬ê°œë…3"],
    "estimated_hours": ì˜ˆìƒí•™ìŠµì‹œê°„(ìˆ«ì)
}}"""
            
            detail_messages = [
                SystemMessage(content="ê° ëª¨ë“ˆì˜ ìƒì„¸ ë‚´ìš©ì„ ì„¤ê³„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ í•™ìŠµ ë‚´ìš©ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”."),
                HumanMessage(content=detail_prompt)
            ]
            
            detail_response = await llm.agenerate([detail_messages])
            detail_text = detail_response.generations[0][0].text if detail_response.generations else ""
            
            # JSON íŒŒì‹±
            detail_json_match = re.search(r'\{[\s\S]*\}', detail_text)
            if detail_json_match:
                try:
                    detailed_module = json.loads(detail_json_match.group())
                    detailed_modules.append(detailed_module)
                    
                    if progress:
                        await progress.update("detail_generation", 
                                            f"âœ… {module.get('title')} ì™„ë£Œ",
                                            thinking=f"í•µì‹¬ ê°œë…: {', '.join(detailed_module.get('key_concepts', [])[:2])}")
                except json.JSONDecodeError:
                    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ì‚¬ìš©
                    detailed_modules.append(module)
            else:
                detailed_modules.append(module)
        
        if progress:
            await progress.update("completion", "âœ… ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì™„ë£Œ!")
        
        return {
            "modules": detailed_modules,
            "overall_goal": structure_data.get("overall_goal", f"Master {topic}")
        }
        
    except Exception as e:
        print(f"DEBUG: Streaming curriculum generation failed: {e}", file=sys.stderr, flush=True)
        if progress:
            await progress.update("error", f"âŒ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return create_basic_curriculum(topic, level, duration_weeks)

# LLMì„ ì‚¬ìš©í•œ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± (ê¸°ì¡´ ë²„ì „)
async def generate_with_llm(topic: str, level: str, duration_weeks: int, focus_areas: List[str], resources: List[Dict[str, str]] = None) -> Dict[str, Any]:
    if not llm_available:
        return create_basic_curriculum(topic, level, duration_weeks)
    
    try:
        print(f"DEBUG: generate_with_llm called - topic:{topic}, level:{level}, duration:{duration_weeks}", file=sys.stderr, flush=True)
        
        focus_text = ', '.join(focus_areas) if focus_areas else 'General coverage'
        print(f"DEBUG: Focus areas processed: {focus_text}", file=sys.stderr, flush=True)
        
        # í•™ìŠµ ìë£Œê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        resources_text = ""
        if resources and len(resources) > 0:
            print(f"DEBUG: Processing {len(resources)} resources for prompt", file=sys.stderr, flush=True)
            resources_text = "\n\nAvailable learning resources:\n"
            for i, resource in enumerate(resources[:5], 1):
                resources_text += f"{i}. {resource.get('title', 'No title')} - {resource.get('url', 'No URL')}\n"
            resources_text += "\nConsider these resources when designing the curriculum modules.\n"
        else:
            print(f"DEBUG: No resources found, using fallback text", file=sys.stderr, flush=True)
            resources_text = "\n\nNote: No specific learning resources were found, but design a comprehensive curriculum anyway.\n"
        
        prompt = f"""ë‹¤ìŒ ì¡°ê±´ì— ë§ëŠ” {duration_weeks}ì£¼ ì»¤ë¦¬í˜ëŸ¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”:

í•™ìŠµ ì£¼ì œ: {topic}
í•™ìŠµ ë ˆë²¨: {level}
í¬ì»¤ìŠ¤ ì˜ì—­: {focus_text}{resources_text}
ì¤‘ìš”: JSON í‚¤ëŠ” ì˜ì–´ë¡œ, ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”!

ê° ëª¨ë“ˆì€ ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
- ëª…í™•í•œ ì œëª©ê³¼ ì„¤ëª… (í•œêµ­ì–´)
- 3-4ê°œì˜ í•™ìŠµ ëª©í‘œ (í•œêµ­ì–´)
- í•™ìŠµ ì„±ê³¼ ("ë‚´ê°€ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê²ƒ") (í•œêµ­ì–´)
- ì˜ˆìƒ í•™ìŠµ ì‹œê°„
- í•µì‹¬ ê°œë…ë“¤ (í•œêµ­ì–´)

JSON í˜•ì‹ (í‚¤ëŠ” ì˜ì–´, ê°’ì€ í•œêµ­ì–´):
{{
    "modules": [
        {{
            "week": 1,
            "title": "ëª¨ë“ˆ ì œëª© (í•œêµ­ì–´)",
            "description": "ëª¨ë“ˆì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª… (í•œêµ­ì–´)",
            "objectives": ["í•™ìŠµëª©í‘œ1 (í•œêµ­ì–´)", "í•™ìŠµëª©í‘œ2 (í•œêµ­ì–´)", "í•™ìŠµëª©í‘œ3 (í•œêµ­ì–´)"],
            "learning_outcomes": ["ë‚´ê°€ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê²ƒ1 (í•œêµ­ì–´)", "ë‚´ê°€ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê²ƒ2 (í•œêµ­ì–´)"],
            "key_concepts": ["í•µì‹¬ê°œë… 1 (í•œêµ­ì–´)", "í•µì‹¬ê°œë… 2 (í•œêµ­ì–´)"],
            "estimated_hours": 10
        }}
    ],
    "overall_goal": "ì „ì²´ í•™ìŠµ ëª©í‘œ (í•œêµ­ì–´)"
}}"""
        
        print(f"DEBUG: Prompt constructed. Length: {len(prompt)} chars", file=sys.stderr, flush=True)
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì „ë¬¸ ì»¤ë¦¬í˜ëŸ¼ ì„¤ê³„ìì…ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í‚¤ëŠ” ì˜ì–´ë¡œ, ëª¨ë“  ê°’(ë‚´ìš©)ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ì˜ˆì‹œ: 'key_concepts', 'estimated_hours' ê°™ì€ í‚¤ëŠ” ì˜ì–´ë¥¼ ìœ ì§€í•˜ê³ , ê·¸ ê°’ë“¤ë§Œ í•œêµ­ì–´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤."),
            HumanMessage(content=prompt)
        ]
        
        print(f"DEBUG: Calling LLM.agenerate() - this may take a while for {duration_weeks} weeks...", file=sys.stderr, flush=True)
        import time
        start_time = time.time()
        
        # print("ğŸ¤– Generating curriculum with LLM...")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
        response = await llm.agenerate([messages])
        
        end_time = time.time()
        print(f"DEBUG: LLM.agenerate() completed in {end_time - start_time:.2f} seconds", file=sys.stderr, flush=True)
        
        if response.generations and response.generations[0]:
            response_text = response.generations[0][0].text
            print(f"DEBUG: LLM response received. Length: {len(response_text)} chars", file=sys.stderr, flush=True)
            
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                print(f"DEBUG: JSON found in response. Parsing...", file=sys.stderr, flush=True)
                parsed_json = json.loads(json_match.group())
                print(f"DEBUG: JSON parsed successfully. Modules count: {len(parsed_json.get('modules', []))}", file=sys.stderr, flush=True)
                return parsed_json
            else:
                print(f"DEBUG: No valid JSON found in LLM response", file=sys.stderr, flush=True)
        else:
            print(f"DEBUG: No generations found in LLM response", file=sys.stderr, flush=True)
    
    except Exception as e:
        print(f"DEBUG: Exception in generate_with_llm: {type(e).__name__}: {e}", file=sys.stderr, flush=True)
        # print(f"âŒ LLM generation failed: {e}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
        pass
    
    return create_basic_curriculum(topic, level, duration_weeks)

# ëª¨ë“ˆë³„ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ (ì½˜í…ì¸  í¬í•¨)
async def collect_module_resources(topic: str, module_info: Dict[str, Any]) -> Dict[str, List[Dict[str, Any]]]:
    """ì£¼ì°¨ë³„ ëª¨ë“ˆì— ëŒ€í•œ K-MOOC ì˜ìƒê³¼ ì›¹ ë¦¬ì†ŒìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ì‹¤ì œ ì½˜í…ì¸ ë„ ê°€ì ¸ì˜µë‹ˆë‹¤"""
    try:
        # K-MOOC ê²€ìƒ‰ê³¼ ì›¹ ê²€ìƒ‰ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
        import asyncio
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± - ë” êµ¬ì²´ì ì´ê³  ê´€ë ¨ì„± ë†’ì€ í‚¤ì›Œë“œ
        week_title = module_info.get('title', '')
        key_concepts = module_info.get('key_concepts', [])
        
        # ê¸°ë³¸ ì£¼ì œì—ì„œ í•µì‹¬ ìš©ì–´ ì¶”ì¶œ
        core_topic = topic.split()[0] if topic else ""  # ì²« ë²ˆì§¸ ë‹¨ì–´ë§Œ ì‚¬ìš©
        
        # ì£¼ì°¨ ì œëª©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        week_keywords = []
        if "ê¸°ì´ˆ" in week_title:
            week_keywords.append("ê¸°ì´ˆ")
        if "íšŒë¡œ" in week_title:
            week_keywords.append("íšŒë¡œ")
        if "ë¶„ì„" in week_title:
            week_keywords.append("ë¶„ì„")
        if "ì„¤ê³„" in week_title:
            week_keywords.append("ì„¤ê³„")
        
        # í•µì‹¬ ê°œë…ì—ì„œ êµ¬ì²´ì  í‚¤ì›Œë“œ ì„ íƒ (ìµœëŒ€ 2ê°œ)
        concept_keywords = []
        for concept in key_concepts[:2]:
            if "ì˜´ì˜ ë²•ì¹™" in concept:
                concept_keywords.append("ì˜´ì˜ë²•ì¹™")
            elif "í‚¤ë¥´íˆí˜¸í”„" in concept:
                concept_keywords.append("í‚¤ë¥´íˆí˜¸í”„")
            elif "ì €í•­" in concept:
                concept_keywords.append("ì €í•­")
            elif "ì „ë¥˜" in concept:
                concept_keywords.append("ì „ë¥˜")
            elif "ì „ì••" in concept:
                concept_keywords.append("ì „ì••")
        
        # ê²€ìƒ‰ í‚¤ì›Œë“œ ì¡°í•©
        search_parts = [core_topic]
        search_parts.extend(week_keywords[:1])  # ì£¼ì°¨ í‚¤ì›Œë“œ 1ê°œ
        search_parts.extend(concept_keywords[:1])  # ê°œë… í‚¤ì›Œë“œ 1ê°œ
        
        search_keywords = " ".join(filter(None, search_parts))
        
        print(f"DEBUG: Enhanced search keywords: {search_keywords} (from topic: {topic}, week: {week_title})", file=sys.stderr, flush=True)
        
        # ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰
        kmooc_task = search_kmooc_resources(topic, week_title, top_k=3)
        web_task = search_resources(search_keywords, num_results=5)  # ë” ë§ì€ ì›¹ ê²°ê³¼ ìˆ˜ì§‘
        
        kmooc_results, web_results = await asyncio.gather(
            kmooc_task, web_task, return_exceptions=True
        )
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        if isinstance(kmooc_results, Exception):
            print(f"DEBUG: K-MOOC search exception: {kmooc_results}", file=sys.stderr, flush=True)
            kmooc_results = []
        if isinstance(web_results, Exception):
            print(f"DEBUG: Web search exception: {web_results}", file=sys.stderr, flush=True)
            web_results = []
        
        # ì›¹ ë¦¬ì†ŒìŠ¤ì˜ ì‹¤ì œ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°
        enhanced_web_links = []
        if web_results and len(web_results) > 0:
            print(f"DEBUG: Fetching content for {len(web_results)} web resources", file=sys.stderr, flush=True)
            
            # ê° ì›¹ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•´ ì½˜í…ì¸  ìˆ˜ì§‘ (ìµœëŒ€ 3ê°œ)
            content_tasks = []
            for resource in web_results[:3]:  # Rate limit ê³ ë ¤í•˜ì—¬ ìµœëŒ€ 3ê°œë¡œ ì œí•œ
                content_tasks.append(fetch_resource_content(resource))
            
            if content_tasks:
                # ì½˜í…ì¸  ìˆ˜ì§‘ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
                content_results = await asyncio.gather(*content_tasks, return_exceptions=True)
                
                # ì„±ê³µí•œ ì½˜í…ì¸ ë§Œ ì¶”ê°€
                for i, content in enumerate(content_results):
                    if not isinstance(content, Exception) and content.get('success', False):
                        enhanced_resource = {
                            **web_results[i],  # ê¸°ì¡´ ì •ë³´ ìœ ì§€
                            "content": content,  # ìƒˆë¡œìš´ ì½˜í…ì¸  ì •ë³´ ì¶”ê°€
                            "has_content": True
                        }
                        enhanced_web_links.append(enhanced_resource)
                        print(f"DEBUG: Successfully fetched content for: {content.get('title', 'Unknown')[:50]}...", file=sys.stderr, flush=True)
                    else:
                        # ì½˜í…ì¸  ìˆ˜ì§‘ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì •ë³´ë§Œ ìœ ì§€
                        enhanced_resource = {
                            **web_results[i],
                            "has_content": False,
                            "content_error": str(content) if isinstance(content, Exception) else content.get('error', 'Unknown error')
                        }
                        enhanced_web_links.append(enhanced_resource)
                        print(f"DEBUG: Failed to fetch content for: {web_results[i].get('title', 'Unknown')}", file=sys.stderr, flush=True)
                
                # Rate limitingì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                await asyncio.sleep(0.5)
        
        # K-MOOC ë¦¬ì†ŒìŠ¤ë„ ì½˜í…ì¸  ì •ë³´ í™•ì¥ (summary ê¸°ë°˜)
        enhanced_kmooc_videos = []
        for video in kmooc_results:
            enhanced_video = {
                **video,
                "has_content": True,  # K-MOOCëŠ” summaryê°€ ìˆìœ¼ë¯€ë¡œ True
                "content": {
                    "success": True,
                    "summary": video.get('description', ''),
                    "key_points": [video.get('course_goal', '')] if video.get('course_goal') else [],
                    "raw_content": video.get('description', '') + ' ' + video.get('course_goal', ''),
                    "code_examples": [],
                    "title": video.get('title', ''),
                    "url": video.get('url', '')
                }
            }
            enhanced_kmooc_videos.append(enhanced_video)
        
        total_resources = len(enhanced_web_links) + len(enhanced_kmooc_videos)
        resources_with_content = len([r for r in enhanced_web_links if r.get('has_content', False)]) + len(enhanced_kmooc_videos)
        
        print(f"DEBUG: Collected {total_resources} resources, {resources_with_content} with content", file=sys.stderr, flush=True)
        
        return {
            "videos": enhanced_kmooc_videos,
            "web_links": enhanced_web_links,
            "documents": [],  # í–¥í›„ êµ¬í˜„ ì˜ˆì •
            "total_resources": total_resources,
            "resources_with_content": resources_with_content,
            "content_coverage": resources_with_content / max(total_resources, 1)
        }
        
    except Exception as e:
        print(f"DEBUG: collect_module_resources failed: {e}", file=sys.stderr, flush=True)
        return {
            "videos": [],
            "web_links": [],
            "documents": [],
            "total_resources": 0,
            "resources_with_content": 0,
            "content_coverage": 0.0
        }

# ë¦¬ì†ŒìŠ¤ ê¸°ë°˜ ê°•ì˜ ì½˜í…ì¸  ìƒì„± í•¨ìˆ˜
async def generate_lecture_content(module: Dict[str, Any], resources: Dict[str, Any]) -> Dict[str, str]:
    """ìˆ˜ì§‘ëœ ë¦¬ì†ŒìŠ¤ ì½˜í…ì¸ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°•ì˜ ë‚´ìš©ì„ ìƒì„±í•©ë‹ˆë‹¤"""
    if not llm_available:
        return {
            "introduction": f"{module.get('title', 'Module')} í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.",
            "main_content": "ë‚´ë¶€ ìë£Œ ë¶€ì¡±ìœ¼ë¡œ ê¸°ë³¸ í•™ìŠµ ì•ˆë‚´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
            "examples": [],
            "exercises": [],
            "summary": f"{module.get('title', 'Module')} í•™ìŠµì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.",
            "content_sources": [],
            "coverage_note": "ì¶”ê°€ í•™ìŠµ ìë£Œê°€ í•„ìš”í•©ë‹ˆë‹¤."
        }
    
    try:
        # ë¦¬ì†ŒìŠ¤ì—ì„œ ì½˜í…ì¸  ì¶”ì¶œ
        all_content = []
        source_references = []
        
        # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ì„¸íŠ¸
        seen_urls = set()
        seen_titles = set()
        
        # ì›¹ ë¦¬ì†ŒìŠ¤ ì½˜í…ì¸  ìˆ˜ì§‘
        web_links = resources.get("web_links", [])
        for link in web_links:
            if link.get("has_content", False) and link.get("content", {}).get("success", False):
                content_info = link["content"]
                url = link.get("url", "")
                title = content_info.get("title", link.get("title", "Unknown"))
                
                # ì¤‘ë³µ ì²´í¬ (URL ë˜ëŠ” ì œëª©)
                if url in seen_urls or title in seen_titles:
                    print(f"DEBUG: ì¤‘ë³µ ì›¹ ë§í¬ ì œì™¸: {title}", file=sys.stderr, flush=True)
                    continue
                    
                seen_urls.add(url)
                seen_titles.add(title)
                
                all_content.append({
                    "source": "web",
                    "title": title,
                    "summary": content_info.get("summary", ""),
                    "raw_content": content_info.get("raw_content", "")[:3000],
                    "key_points": content_info.get("key_points", []),
                    "code_examples": content_info.get("code_examples", []),
                    "url": url
                })
                source_references.append({
                    "title": title,
                    "url": url,
                    "type": "web"
                })
        
        # K-MOOC ë¹„ë””ì˜¤ ì½˜í…ì¸  ìˆ˜ì§‘
        videos = resources.get("videos", [])
        for video in videos:
            if video.get("has_content", False) and video.get("content", {}).get("success", False):
                content_info = video["content"]
                url = video.get("url", "")
                title = content_info.get("title", video.get("title", "Unknown"))
                
                # ì¤‘ë³µ ì²´í¬ (URL ë˜ëŠ” ì œëª©)
                if url in seen_urls or title in seen_titles:
                    print(f"DEBUG: ì¤‘ë³µ ë¹„ë””ì˜¤ ì œì™¸: {title}", file=sys.stderr, flush=True)
                    continue
                    
                seen_urls.add(url)
                seen_titles.add(title)
                
                all_content.append({
                    "source": "kmooc",
                    "title": title,
                    "summary": content_info.get("summary", ""),
                    "raw_content": content_info.get("raw_content", "")[:3000],
                    "key_points": content_info.get("key_points", []),
                    "course_goal": video.get("course_goal", ""),
                    "institution": video.get("institution", ""),
                    "url": url
                })
                source_references.append({
                    "title": title,
                    "url": url,
                    "institution": video.get("institution", ""),
                    "type": "kmooc"
                })
        
        content_coverage = resources.get("content_coverage", 0.0)
        
        # ì½˜í…ì¸ ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ê²½ìš°
        if len(all_content) == 0:
            return {
                "introduction": f"{module.get('title', 'Module')} í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.",
                "main_content": "í˜„ì¬ ë‚´ë¶€ DBì—ì„œ ê´€ë ¨ í•™ìŠµ ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¶”ê°€ ìë£Œ ìˆ˜ì§‘ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "examples": [],
                "exercises": [],
                "summary": "í•™ìŠµ ìë£Œ ë¶€ì¡±ìœ¼ë¡œ ê¸°ë³¸ ì•ˆë‚´ë§Œ ì œê³µë©ë‹ˆë‹¤.",
                "content_sources": [],
                "coverage_note": "ê´€ë ¨ í•™ìŠµ ìë£Œë¥¼ ì¶”ê°€ë¡œ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”."
            }
        
        # LLMì—ê²Œ ê°•ì˜ ë‚´ìš© ìƒì„± ìš”ì²­
        combined_content = ""
        for content in all_content:
            combined_content += f"\n=== {content['title']} ({content['source']}) ===\n"
            combined_content += f"ìš”ì•½: {content['summary']}\n"
            combined_content += f"ë‚´ìš©: {content['raw_content']}\n"
            if content.get('key_points'):
                combined_content += f"í•µì‹¬ í¬ì¸íŠ¸: {', '.join(content['key_points'][:3])}\n"
            if content.get('code_examples'):
                combined_content += f"ì½”ë“œ ì˜ˆì œ: {content['code_examples'][0][:200]}...\n"
        
        lecture_prompt = f"""ë‹¤ìŒ ë‚´ë¶€ DBì—ì„œ ìˆ˜ì§‘í•œ ìë£Œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶©ì‹¤í•œ ê°•ì˜ ë‚´ìš©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì£¼ì°¨: {module.get('title', 'Module')}
í•™ìŠµ ëª©í‘œ: {', '.join(module.get('objectives', []))}
í•µì‹¬ ê°œë…: {', '.join(module.get('key_concepts', []))}

=== ìˆ˜ì§‘ëœ ë‚´ë¶€ ìë£Œ ===
{combined_content}

**ê°•ì˜ ì‘ì„± ì§€ì¹¨:**
- ìµœì†Œ 1000ì ì´ìƒì˜ ì¶©ì‹¤í•œ ê°•ì˜ ë‚´ìš©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”
- ì œê³µëœ ë‚´ë¶€ ìë£Œì˜ ë‚´ìš©ë§Œì„ í™œìš©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ êµ¬ì„±
- ê° ì„¹ì…˜ë§ˆë‹¤ êµ¬ì²´ì ì´ê³  ì‹¤ì§ˆì ì¸ ë‚´ìš© í¬í•¨

**ì¤‘ìš”: ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì€ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:**

{{
  "introduction": "í…ìŠ¤íŠ¸ ë‚´ìš© (ë”°ì˜´í‘œ ì•ˆì— í…ìŠ¤íŠ¸ë§Œ, JSON ê°ì²´ ì ˆëŒ€ ê¸ˆì§€)",
  "main_content": "í…ìŠ¤íŠ¸ ë‚´ìš© (ë”°ì˜´í‘œ ì•ˆì— í…ìŠ¤íŠ¸ë§Œ, JSON ê°ì²´ ì ˆëŒ€ ê¸ˆì§€)",
  "examples": ["í…ìŠ¤íŠ¸1", "í…ìŠ¤íŠ¸2", "í…ìŠ¤íŠ¸3"],
  "exercises": ["í…ìŠ¤íŠ¸1", "í…ìŠ¤íŠ¸2", "í…ìŠ¤íŠ¸3"], 
  "summary": "í…ìŠ¤íŠ¸ ë‚´ìš© (ë”°ì˜´í‘œ ì•ˆì— í…ìŠ¤íŠ¸ë§Œ, JSON ê°ì²´ ì ˆëŒ€ ê¸ˆì§€)"
}}

**ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­:**
- JSON ì•ˆì— ë˜ ë‹¤ë¥¸ JSON ê°ì²´ë¥¼ ë„£ì§€ ë§ˆì„¸ìš”
- ì¤‘ê´„í˜¸ {{}} ë‚˜ ë”°ì˜´í‘œë¥¼ í…ìŠ¤íŠ¸ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- ê° í•„ë“œëŠ” ìˆœìˆ˜í•œ í…ìŠ¤íŠ¸ë‚˜ í…ìŠ¤íŠ¸ ë°°ì—´ë§Œ í¬í•¨í•˜ì„¸ìš”

**ë‚´ìš© ìš”êµ¬ì‚¬í•­:**
- introduction: ìµœì†Œ 100ì ì´ìƒì˜ ì¸ì‚¬ë§ê³¼ ëª©í‘œ ì†Œê°œ
- main_content: ìµœì†Œ 600ì ì´ìƒì˜ í•™ìŠµ ë‚´ìš© (ì¶œì²˜ í‘œê¸° í¬í•¨)
- examples: 3ê°œì˜ êµ¬ì²´ì  ì‹¤ìŠµ ì˜ˆì œ
- exercises: 3ê°œì˜ ì—°ìŠµ ë¬¸ì œ
- summary: ìµœì†Œ 150ì ì´ìƒì˜ í•µì‹¬ ë‚´ìš© ì •ë¦¬

ì˜¤ì§ ìœ„ JSON í˜•ì‹ë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ ì¼ì ˆ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""

        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì‚¬ë‚´ êµìœ¡ ê°•ì‚¬ì…ë‹ˆë‹¤. ì œê³µëœ ë‚´ë¶€ DB ìë£Œë§Œì„ í™œìš©í•˜ì—¬ ì •í™•í•˜ê³  ì²´ê³„ì ì¸ ê°•ì˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."),
            HumanMessage(content=lecture_prompt)
        ]
        
        print(f"DEBUG: Generating lecture content with {len(all_content)} resources", file=sys.stderr, flush=True)
        response = await llm.agenerate([messages])
        
        if response.generations and response.generations[0]:
            response_text = response.generations[0][0].text
            print(f"DEBUG: LLM ì‘ë‹µ ê¸¸ì´: {len(response_text)} ë¬¸ì", file=sys.stderr, flush=True)
            print(f"DEBUG: LLM ì‘ë‹µ ì²« 500ë¬¸ì: {response_text[:500]}", file=sys.stderr, flush=True)
            
            # JSON íŒŒì‹± ì‹œë„ - ë” ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­
            # ì „ì²´ ì‘ë‹µì´ JSONì¸ì§€ ë¨¼ì € í™•ì¸
            response_text = response_text.strip()
            if response_text.startswith('{') and response_text.endswith('}'):
                json_text = response_text
            else:
                # JSON íŒ¨í„´ ì°¾ê¸°
                json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', response_text)
                if json_match:
                    json_text = json_match.group()
                else:
                    json_text = None
            
            if json_text:
                try:
                    lecture_data = json.loads(json_text)
                    print(f"DEBUG: JSON íŒŒì‹± ì„±ê³µ! í‚¤ë“¤: {list(lecture_data.keys())}", file=sys.stderr, flush=True)
                    
                    # ê¸°ë³¸ êµ¬ì¡° í™•ì¸ ë° ë³´ì™„
                    lecture_content = {
                        "introduction": lecture_data.get("introduction", f"{module.get('title', 'Module')} í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤."),
                        "main_content": lecture_data.get("main_content", "ê°•ì˜ ë‚´ìš©ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤."),
                        "examples": lecture_data.get("examples", []),
                        "exercises": lecture_data.get("exercises", []),
                        "summary": lecture_data.get("summary", "í•™ìŠµì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."),
                        "content_sources": source_references,
                        "coverage_note": f"DB ì»¤ë²„ë¦¬ì§€: {content_coverage:.0%}, {len(all_content)}ê°œ ìë£Œ í™œìš©"
                    }
                    
                    print(f"DEBUG: ìµœì¢… ê°•ì˜ ë‚´ìš© - introduction: {len(lecture_content['introduction'])}ì, main_content: {len(lecture_content['main_content'])}ì", file=sys.stderr, flush=True)
                    return lecture_content
                    
                except json.JSONDecodeError as e:
                    print(f"DEBUG: JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}", file=sys.stderr, flush=True)
                    print(f"DEBUG: JSON ë§¤ì¹˜ëœ í…ìŠ¤íŠ¸: {json_match.group()[:300]}", file=sys.stderr, flush=True)
            else:
                print("DEBUG: JSON íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ", file=sys.stderr, flush=True)
        
        # íŒŒì‹± ì‹¤íŒ¨ì‹œ response_textì—ì„œ ì•ˆì „í•˜ê²Œ ë‚´ìš© ì¶”ì¶œ
        fallback_content = f"ìˆ˜ì§‘ëœ {len(all_content)}ê°œ ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ ë‚´ìš©ì„ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤."
        
        # ì‘ë‹µì—ì„œ JSONì´ ì•„ë‹Œ ìœ ìš©í•œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ ì‹œë„
        if response_text and len(response_text) > 100:
            # JSON êµ¬ì¡° ë¬¸ìì—´ì´ í¬í•¨ëœ ê²½ìš° ì œê±°
            if '{' in response_text and '}' in response_text:
                print("DEBUG: JSON íŒŒì‹± ì‹¤íŒ¨, JSON êµ¬ì¡° ì œê±° í›„ í…ìŠ¤íŠ¸ ì¶”ì¶œ", file=sys.stderr, flush=True)
                # JSON ë¶€ë¶„ì„ ì œê±°í•˜ê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                lines = response_text.split('\n')
                clean_lines = []
                skip_json = False
                
                for line in lines:
                    line = line.strip()
                    if line.startswith('{') or '"' in line[:10]:  # JSON ì‹œì‘ìœ¼ë¡œ ë³´ì´ëŠ” ë¼ì¸
                        skip_json = True
                        continue
                    elif skip_json and line.endswith('}'):  # JSON ë
                        skip_json = False
                        continue
                    elif not skip_json and len(line) > 20 and not line.startswith('"'):
                        clean_lines.append(line)
                
                if clean_lines:
                    fallback_content = ' '.join(clean_lines[:3])[:800]  # ì²˜ìŒ 3ì¤„, ìµœëŒ€ 800ì
                    print(f"DEBUG: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ, ê¸¸ì´: {len(fallback_content)}", file=sys.stderr, flush=True)
            else:
                print("DEBUG: ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì‘ë‹µìœ¼ë¡œ ë³´ì„, ì¼ë¶€ ì‚¬ìš©", file=sys.stderr, flush=True)
                fallback_content = response_text[:800] + "..."
        
        # ìˆ˜ì§‘ëœ ìë£Œ ì •ë³´ë¥¼ í¬í•¨í•œ ë” í’ë¶€í•œ ê¸°ë³¸ ì½˜í…ì¸  ìƒì„±
        resource_summary = ""
        if all_content:
            resource_summary = f"\n\nğŸ“š ìˆ˜ì§‘ëœ í•™ìŠµ ìë£Œ:\n"
            for i, content in enumerate(all_content[:3], 1):  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                resource_summary += f"{i}. {content['title']} ({content['source']})\n"
                if content.get('summary'):
                    resource_summary += f"   ìš”ì•½: {content['summary'][:100]}...\n"
        
        return {
            "introduction": f"ì•ˆë…•í•˜ì„¸ìš”! {module.get('title', 'Module')} í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤. ì´ë²ˆ ì£¼ì°¨ì—ì„œëŠ” {', '.join(module.get('key_concepts', ['í•µì‹¬ ê°œë…ë“¤'])[:2])} ë“±ì„ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤.",
            "main_content": fallback_content + resource_summary,
            "examples": ["ìˆ˜ì§‘ëœ ìë£Œì˜ ì‹¤ìŠµ ì˜ˆì œë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.", "ê° ìë£Œì˜ ì˜ˆì‹œ ì½”ë“œë¥¼ ì§ì ‘ ì‹¤í–‰í•´ë³´ì„¸ìš”."],
            "exercises": [
                f"{module.get('title', 'Module')}ì˜ í•µì‹¬ ê°œë…ì„ ì„¤ëª…í•´ë³´ì„¸ìš”.",
                "í•™ìŠµí•œ ë‚´ìš©ì„ ì‹¤ì œ ìƒí™©ì— ì–´ë–»ê²Œ ì ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ìƒê°í•´ë³´ì„¸ìš”.", 
                "ì°¸ê³  ìë£Œì˜ ì˜ˆì œë¥¼ ì‘ìš©í•œ ìƒˆë¡œìš´ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”."
            ],
            "summary": f"{module.get('title', 'Module')} í•™ìŠµì„ í†µí•´ {', '.join(module.get('objectives', ['í•™ìŠµ ëª©í‘œ'])[:2])} ë“±ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì œê³µëœ {len(all_content)}ê°œ ìë£Œë¥¼ í†µí•´ ì‹¬í™” í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”.",
            "content_sources": source_references,
            "coverage_note": f"DB ì»¤ë²„ë¦¬ì§€: {content_coverage:.0%}, {len(all_content)}ê°œ ìë£Œ í™œìš© (JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ fallback ì‚¬ìš©)"
        }
        
    except Exception as e:
        print(f"DEBUG: generate_lecture_content failed: {e}", file=sys.stderr, flush=True)
        return {
            "introduction": f"{module.get('title', 'Module')} í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.",
            "main_content": "ê°•ì˜ ë‚´ìš© ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "examples": [],
            "exercises": [],
            "summary": "ì˜¤ë¥˜ë¡œ ì¸í•´ ê¸°ë³¸ ì•ˆë‚´ë§Œ ì œê³µë©ë‹ˆë‹¤.",
            "content_sources": [],
            "coverage_note": "ê°•ì˜ ìƒì„± ì‹¤íŒ¨"
        }

# ê¸°ë³¸ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± (LLM ì‹¤íŒ¨ì‹œ fallback)
def create_basic_curriculum(topic: str, level: str, duration_weeks: int) -> Dict[str, Any]:
    modules = []
    
    for i in range(1, duration_weeks + 1):
        modules.append({
            "week": i,
            "title": f"{topic} - {i}ì£¼ì°¨",
            "description": f"{i}ì£¼ì°¨ í•™ìŠµ ë‚´ìš©",
            "objectives": [f"{i}ì£¼ì°¨ í•µì‹¬ ê°œë… í•™ìŠµ", "ì‹¤ìŠµ ê³¼ì œ ì™„ë£Œ", "ì´ë¡  ì´í•´ ë° ì ìš©"],
            "learning_outcomes": [f"{topic} ê¸°ë³¸ ê°œë… ì´í•´", f"{i}ì£¼ì°¨ ì‹¤ë¬´ ì§€ì‹ ìŠµë“"],
            "key_concepts": [f"{i}ì£¼ì°¨ ê¸°ì´ˆ ê°œë…", "ì‹¤ìŠµ ì˜ˆì œ"],
            "estimated_hours": 8 + i * 2
        })
    
    return {
        "modules": modules,
        "overall_goal": f"{duration_weeks}ì£¼ ë™ì•ˆ {topic} ê¸°ì´ˆë¥¼ ë§ˆìŠ¤í„°í•˜ê¸°"
    }

# === MCP Tools ===

@mcp.tool()
async def list_session_topics() -> Dict[str, Any]:
    """List all completed sessions available for curriculum generation"""
    sessions = session_loader.get_completed_sessions()
    
    if not sessions:
        return {"message": "No completed sessions found", "sessions": []}
    
    topics_count = {}
    for session in sessions:
        topic = session["topic"]
        topics_count[topic] = topics_count.get(topic, 0) + 1
    
    return {
        "total_sessions": len(sessions),
        "unique_topics": len(topics_count),
        "topics": topics_count,
        "all_sessions": sessions
    }

@mcp.tool()
async def generate_curriculum_from_session(session_id: str, user_message: str = "") -> Dict[str, Any]:
    """Generate curriculum from a specific session with optional user message for duration override"""
    sessions = session_loader.get_completed_sessions()
    session_data = None
    
    for session in sessions:
        if session["session_id"] == session_id:
            session_data = session
            break
    
    if not session_data:
        return {"error": f"Session {session_id} not found"}
    
    # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    topic = session_data["topic"]
    constraints = session_data["constraints"]
    goal = session_data["goal"]
    
    params = await session_loader.extract_parameters_with_llm(constraints, goal)
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ê¸°ê°„ ì •ë³´ ì¶”ì¶œ ë° ì˜¤ë²„ë¼ì´ë“œ
    if user_message:
        message_duration = extract_duration_from_message(user_message)
        print(f"DEBUG: user_message='{user_message}'", file=sys.stderr, flush=True)
        print(f"DEBUG: extracted duration={message_duration}", file=sys.stderr, flush=True)
        print(f"DEBUG: original params duration={params.get('duration_weeks')}", file=sys.stderr, flush=True)
        
        if message_duration is not None:
            params["duration_weeks"] = message_duration
            print(f"DEBUG: overridden to {message_duration} weeks", file=sys.stderr, flush=True)
        else:
            print(f"DEBUG: no duration found in message", file=sys.stderr, flush=True)
    
    # print(f"ğŸ“š Generating curriculum for {session_id}:")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
    # print(f"  Topic: {topic}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
    # print(f"  Level: {params['level']}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
    # print(f"  Duration: {params['duration_weeks']} weeks")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
    
    # ê¸°ë³¸ í•™ìŠµ ìë£Œ ê²€ìƒ‰ (í”„ë¡¬í”„íŠ¸ìš©)
    print(f"DEBUG: Starting basic resource search for topic: {topic}", file=sys.stderr, flush=True)
    basic_resources = await search_resources(topic)
    print(f"DEBUG: Basic resource search completed. Found {len(basic_resources)} resources", file=sys.stderr, flush=True)
    
    # ì»¤ë¦¬í˜ëŸ¼ ìƒì„± (ê¸°ë³¸ êµ¬ì¡°)
    print(f"DEBUG: Starting LLM curriculum generation...", file=sys.stderr, flush=True)
    print(f"DEBUG: LLM parameters - topic:{topic}, level:{params['level']}, duration:{params['duration_weeks']}, focus_areas:{params['focus_areas']}", file=sys.stderr, flush=True)
    print(f"DEBUG: llm_available status: {llm_available}", file=sys.stderr, flush=True)
    
    try:
        # ìŠ¤íŠ¸ë¦¬ë° ë²„ì „ì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒíƒœ ê³µìœ 
        curriculum_data = await generate_with_llm_streaming(
            topic=topic,
            level=params["level"],
            duration_weeks=params["duration_weeks"],
            focus_areas=params["focus_areas"],
            resources=basic_resources,
            session_id=session_id
        )
        print(f"DEBUG: LLM curriculum generation completed successfully", file=sys.stderr, flush=True)
        print(f"DEBUG: Generated {len(curriculum_data.get('modules', []))} modules", file=sys.stderr, flush=True)
    except Exception as e:
        print(f"DEBUG: LLM curriculum generation failed with error: {type(e).__name__}: {e}", file=sys.stderr, flush=True)
        raise
    
    # ê° ëª¨ë“ˆì— ëŒ€í•´ êµ¬ì¡°í™”ëœ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘
    modules = curriculum_data.get("modules", [])
    print(f"DEBUG: Processing {len(modules)} modules for resource collection", file=sys.stderr, flush=True)
    
    for module in modules:
        module_topic = f"{topic} {module.get('title', '')}"
        week_title = module.get('title', '')
        
        print(f"DEBUG: Collecting resources for module: {week_title}", file=sys.stderr, flush=True)
        
        # ë³‘ë ¬ë¡œ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ (K-MOOC + ì›¹ ê²€ìƒ‰)
        module_resources = await collect_module_resources(module_topic, module)
        
        # ëª¨ë“ˆì— ë¦¬ì†ŒìŠ¤ ì¶”ê°€ (ëª¨ë“  ì½˜í…ì¸  ì •ë³´ í¬í•¨)
        module["resources"] = module_resources  # ì „ì²´ ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ í¬í•¨
        
        # ìˆ˜ì§‘ëœ ë¦¬ì†ŒìŠ¤ê°€ ìˆìœ¼ë©´ ê°•ì˜ ì½˜í…ì¸  ìƒì„±
        if module_resources.get('resources_with_content', 0) > 0:
            print(f"DEBUG: Generating lecture content for module: {week_title}", file=sys.stderr, flush=True)
            try:
                lecture_content = await generate_lecture_content(module, module_resources)
                module["lecture_content"] = lecture_content
                print(f"DEBUG: Successfully generated lecture content with {len(lecture_content.get('sections', []))} sections", file=sys.stderr, flush=True)
            except Exception as e:
                print(f"DEBUG: Failed to generate lecture content: {e}", file=sys.stderr, flush=True)
                # ê°•ì˜ ìƒì„± ì‹¤íŒ¨ì‹œì—ë„ ì»¤ë¦¬í˜ëŸ¼ì€ ê³„ì† ì§„í–‰
        else:
            print(f"DEBUG: No content available for lecture generation in module: {week_title}", file=sys.stderr, flush=True)
        
        print(f"DEBUG: Added {len(module_resources.get('videos', []))} videos and {len(module_resources.get('web_links', []))} web links", file=sys.stderr, flush=True)
        print(f"DEBUG: Content coverage: {module_resources.get('content_coverage', 0.0):.2f}", file=sys.stderr, flush=True)
    
    # ìµœì¢… ì»¤ë¦¬í˜ëŸ¼ êµ¬ì„±
    curriculum = {
        "title": f"{topic} Learning Path",
        "level": params["level"],
        "duration_weeks": params["duration_weeks"],
        "modules": modules,  # ë¦¬ì†ŒìŠ¤ê°€ í¬í•¨ëœ ëª¨ë“ˆë“¤
        "overall_goal": curriculum_data.get("overall_goal", f"Master {topic}"),
        "resources": basic_resources[:5] if basic_resources else [],  # ì „ì²´ ì°¸ê³  ìë£Œ
        "session_id": session_id,
        "original_constraints": constraints,
        "original_goal": goal,
        "generated_at": datetime.now().isoformat()
    }
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    curriculum_id = db.save_curriculum(session_id, curriculum)
    curriculum["curriculum_id"] = curriculum_id
    
    # ì„¸ì…˜ íŒŒì¼ì—ë„ ì»¤ë¦¬í˜ëŸ¼ ì •ë³´ ì—…ë°ì´íŠ¸
    session_loader.update_session_with_curriculum(session_id, curriculum)
    
    return curriculum

@mcp.tool()
async def generate_curriculums_from_all_sessions() -> Dict[str, Any]:
    """Generate curriculums for all completed sessions"""
    sessions = session_loader.get_completed_sessions()
    
    if not sessions:
        return {
            "message": "No completed sessions found",
            "sessions_processed": 0,
            "curriculums_generated": 0
        }
    
    successful = []
    failed = []
    
    for session in sessions:
        session_id = session["session_id"]
        
        try:
            # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            existing = db.get_curriculum(session_id, 0)
            if existing:
                # print(f"âš ï¸ Curriculum already exists for {session_id}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
                continue
            
            result = await generate_curriculum_from_session(session_id)
            
            if "error" in result:
                failed.append({"session_id": session_id, "error": result["error"]})
            else:
                successful.append({
                    "session_id": session_id,
                    "topic": session["topic"],
                    "curriculum_id": result.get("curriculum_id")
                })
                # print(f"âœ… Generated curriculum for {session_id}")  # MCP í†µì‹  ë°©í•´ ë°©ì§€
                
        except Exception as e:
            failed.append({"session_id": session_id, "error": str(e)})
    
    return {
        "sessions_processed": len(sessions),
        "curriculums_generated": len(successful),
        "successful_generations": successful,
        "failed_generations": failed,
        "success_rate": f"{(len(successful) / len(sessions)) * 100:.1f}%" if sessions else "0%"
    }

@mcp.tool()
async def get_curriculum(user_id: str, curriculum_id: int = 0) -> Dict[str, Any]:
    """Get a specific curriculum"""
    curriculum = db.get_curriculum(user_id, curriculum_id)
    
    if not curriculum:
        return {"error": "Curriculum not found"}
    
    return curriculum

@mcp.tool()
async def search_learning_resources(topic: str, num_results: int = 10) -> Dict[str, Any]:
    """Search for learning resources on a topic"""
    resources = await search_resources(topic, num_results)
    
    return {
        "topic": topic,
        "total_resources": len(resources),
        "resources": resources
    }

if __name__ == "__main__":
    mcp.run(transport="stdio")