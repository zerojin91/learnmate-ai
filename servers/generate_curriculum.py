"""
LangGraph ê¸°ë°˜ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì„œë²„ (v2)
ê¸°ì¡´ generate_curriculum.pyë¥¼ LangGraph Agent ì‹œìŠ¤í…œìœ¼ë¡œ ì™„ì „íˆ ë¦¬íŒ©í† ë§
"""
from mcp.server.fastmcp import FastMCP
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
import os
import sys
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
from enum import Enum
import time
from functools import lru_cache

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config

# ìƒˆë¡œìš´ Agent ì‹œìŠ¤í…œ import
from servers.curriculum_agents.workflow import create_curriculum_workflow
from servers.curriculum_agents.state import ProcessingPhase


# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í´ë˜ìŠ¤ë“¤ ìœ ì§€
class LevelEnum(str, Enum):
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"


class SessionParameters(BaseModel):
    level: LevelEnum = Field(default=LevelEnum.BEGINNER, description="í•™ìŠµ ìˆ˜ì¤€")
    duration_weeks: int = Field(default=4, description="í•™ìŠµ ê¸°ê°„ (ì£¼ ë‹¨ìœ„, 1-24 ì‚¬ì´)", ge=1, le=24)
    focus_areas: List[str] = Field(default=[], description="ì¤‘ì  í•™ìŠµ ì˜ì—­")
    weekly_hours: int = Field(default=10, description="ì£¼ë‹¹ í•™ìŠµ ê°€ëŠ¥ ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„, 1-40 ì‚¬ì´)", ge=1, le=40)


class ExtractionRequest(BaseModel):
    constraints: str = Field(description="í•™ìŠµ ì œì•½ ì¡°ê±´")
    goal: str = Field(description="í•™ìŠµ ëª©í‘œ")


# ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ (CurriculumDB, SessionLoader) ìœ ì§€í•˜ë˜ ê°„ì†Œí™”
class CurriculumDB:
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        os.makedirs(data_dir, exist_ok=True)
        self.db_file = os.path.join(data_dir, "curriculums.json")
        self.data = self._load_data()

    def _load_data(self):
        try:
            if os.path.exists(self.db_file):
                with open(self.db_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"DEBUG: Error loading curriculum DB: {e}", file=sys.stderr)
        return {}

    def _save_data(self):
        try:
            with open(self.db_file, 'w', encoding='utf-8') as f:
                json.dump(self.data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"DEBUG: Error saving curriculum DB: {e}", file=sys.stderr)

    def save_curriculum(self, user_id: str, curriculum: Dict):
        if user_id not in self.data:
            self.data[user_id] = []

        curriculum_id = len(self.data[user_id])
        curriculum["id"] = curriculum_id
        self.data[user_id].append(curriculum)
        self._save_data()
        return curriculum_id

    def get_curriculum(self, user_id: str, curriculum_id: int) -> Optional[Dict]:
        user_curriculums = self.data.get(user_id, [])
        if 0 <= curriculum_id < len(user_curriculums):
            return user_curriculums[curriculum_id]
        return None


class SessionLoader:
    def __init__(self, sessions_dir: str = "sessions"):
        self.sessions_dir = sessions_dir

    def get_session_by_id(self, session_id: str) -> Optional[Dict[str, Any]]:
        try:
            # Search for the file in the directory and subdirectories
            for root, _, files in os.walk(self.sessions_dir):
                for filename in files:
                    if filename == f"{session_id}.json":
                        session_path = os.path.join(root, filename)
                        with open(session_path, 'r', encoding='utf-8') as f:
                            return json.load(f)
        except Exception as e:
            print(f"DEBUG: Error loading session {session_id}: {e}", file=sys.stderr)
        return None

    def get_completed_sessions(self) -> List[Dict[str, Any]]:
        sessions = []
        try:
            if os.path.exists(self.sessions_dir):
                for root, _, files in os.walk(self.sessions_dir):
                    for filename in files:
                        if filename.endswith('.json'):
                            session_path = os.path.join(root, filename)
                            with open(session_path, 'r', encoding='utf-8') as f:
                                session_data = json.load(f)
                                # status=='completed' ë˜ëŠ” completed==True ëª¨ë‘ ì§€ì›
                                if (session_data.get('status') == 'completed' or
                                    session_data.get('completed') == True):
                                    sessions.append(session_data)
        except Exception as e:
            print(f"DEBUG: Error loading sessions: {e}", file=sys.stderr)
        return sessions

    def update_session_with_curriculum(self, session_id: str, curriculum: Dict[str, Any]) -> bool:
        try:
            session_file = os.path.join(self.sessions_dir, f"{session_id}.json")
            if os.path.exists(session_file):
                with open(session_file, 'r', encoding='utf-8') as f:
                    session_data = json.load(f)

                session_data['curriculum'] = {
                    'id': curriculum.get('curriculum_id'),
                    'title': curriculum.get('title'),
                    'generated_at': curriculum.get('generated_at')
                }

                with open(session_file, 'w', encoding='utf-8') as f:
                    json.dump(session_data, f, ensure_ascii=False, indent=2)
                return True
        except Exception as e:
            print(f"DEBUG: Error updating session with curriculum: {e}", file=sys.stderr)
        return False


# MCP ì„œë²„ ì„¤ì •
mcp = FastMCP(
    "CurriculumGenerator",
    instructions="Generate personalized learning curriculums using LangGraph agents",
    host="0.0.0.0",
    port=8006,  # ê¸°ì¡´ í¬íŠ¸ ì‚¬ìš©
)

# ì „ì—­ ìºì‹œ ë° ì„±ëŠ¥ ìµœì í™” ë³€ìˆ˜
_content_cache = {}
_semaphore = None

# LLM ë° ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
def initialize_system():
    global _semaphore
    try:
        llm = ChatOpenAI(
            base_url=Config.LLM_BASE_URL,
            api_key=Config.LLM_API_KEY,
            model=Config.LLM_MODEL,
            temperature=0.7,
            max_tokens=Config.LLM_MAX_TOKENS,
            model_kwargs={"max_completion_tokens": None}
        )

        workflow = create_curriculum_workflow(llm)
        # ë™ì‹œ LLM í˜¸ì¶œ ì œí•œ (ìµœëŒ€ 12ê°œ)
        _semaphore = asyncio.Semaphore(12)
        return llm, workflow, True
    except Exception as e:
        print(f"ERROR: System initialization failed: {e}", file=sys.stderr)
        return None, None, False


llm, workflow, system_available = initialize_system()
db = CurriculumDB()
session_loader = SessionLoader()


def extract_duration_from_message(message: str) -> Optional[int]:
    """ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€"""
    import re
    if not message:
        return None

    duration_patterns = [
        r'(\d+)\s*ì£¼',
        r'(\d+)\s*week',
        r'(\d+)\s*ë‹¬',
        r'(\d+)\s*month'
    ]

    for pattern in duration_patterns:
        match = re.search(pattern, message.lower())
        if match:
            duration = int(match.group(1))
            if 'month' in pattern or 'ë‹¬' in pattern:
                duration *= 4

            if 1 <= duration <= 24:
                return duration
    return None


@mcp.tool()
async def list_session_topics() -> Dict[str, Any]:
    """List all completed sessions available for curriculum generation"""
    sessions = session_loader.get_completed_sessions()
    return {
        "message": f"Found {len(sessions)} completed sessions",
        "sessions": [
            {
                "session_id": s["session_id"],
                "topic": s["topic"],
                "goal": s["goal"],
                "constraints": s["constraints"]
            }
            for s in sessions
        ],
        "all_sessions": sessions
    }


@mcp.tool()
async def generate_curriculum_from_session(session_id: str, user_message: str = "") -> Dict[str, Any]:
    """Generate curriculum from a specific session using LangGraph agents"""

    if not system_available:
        return {"error": "LangGraph system not available"}

    session_data = session_loader.get_session_by_id(session_id)

    if not session_data:
        return {"error": f"Session {session_id} not found"}

    print(f"DEBUG: Starting LangGraph curriculum generation for {session_id}", file=sys.stderr)
    print(f"DEBUG: Session data - topic: {session_data.get('topic')}, constraints: {session_data.get('constraints')}, goal: {session_data.get('goal')}", file=sys.stderr)

    try:
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¡œ ì»¤ë¦¬í˜ëŸ¼ ìƒì„±
        curriculum = await workflow.generate_curriculum(
            session_id=session_id,
            topic=session_data["topic"],
            constraints=session_data["constraints"],
            goal=session_data["goal"],
            user_message=user_message
        )

        print(f"DEBUG: LangGraph workflow completed", file=sys.stderr)
        print(f"DEBUG: Generated curriculum type: {type(curriculum)}", file=sys.stderr)

        # fallback ì»¤ë¦¬í˜ëŸ¼ì¸ì§€ í™•ì¸
        if curriculum.get("fallback"):
            print(f"WARNING: Fallback curriculum was generated", file=sys.stderr)
        else:
            print(f"SUCCESS: Complete curriculum generated with graph_curriculum: {'graph_curriculum' in curriculum}", file=sys.stderr)

        # ê°•ì˜ìë£Œ ìƒì„±ì€ ì´ì œ ì›Œí¬í”Œë¡œìš° ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë¨
        lecture_generation_success = curriculum.get("lecture_notes_complete", False)
        print(f"DEBUG: Lecture notes generation status from workflow: {lecture_generation_success}", file=sys.stderr)

        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        curriculum_id = db.save_curriculum(session_id, curriculum)
        curriculum["curriculum_id"] = curriculum_id

        # ì„¸ì…˜ íŒŒì¼ ì—…ë°ì´íŠ¸
        session_loader.update_session_with_curriculum(session_id, curriculum)

        # ê°•ì˜ìë£Œ ìƒì„± ìƒíƒœë¥¼ í¬í•¨í•œ ê²°ê³¼ ë°˜í™˜
        result = curriculum.copy()
        result["generation_status"] = {
            "curriculum_complete": True,
            "lecture_notes_complete": curriculum.get("lecture_notes_complete", False),
            "overall_success": lecture_generation_success and not curriculum.get("fallback", False)
        }

        return result

    except Exception as e:
        print(f"ERROR: LangGraph curriculum generation failed: {e}", file=sys.stderr)
        import traceback
        print(f"ERROR: Stacktrace: {traceback.format_exc()}", file=sys.stderr)
        return {"error": f"Curriculum generation failed: {str(e)}"}


@mcp.tool()
async def generate_curriculums_from_all_sessions() -> Dict[str, Any]:
    """Generate curriculums for all completed sessions using LangGraph"""

    if not system_available:
        return {"error": "LangGraph system not available"}

    sessions = session_loader.get_completed_sessions()

    if not sessions:
        return {
            "message": "No completed sessions found",
            "sessions_processed": 0,
            "curriculums_generated": 0
        }

    successful = []
    failed = []

    for session in sessions:
        session_id = session["session_id"]

        try:
            # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            existing = db.get_curriculum(session_id, 0)
            if existing:
                continue

            result = await generate_curriculum_from_session(session_id)

            if "error" in result:
                failed.append({"session_id": session_id, "error": result["error"]})
            else:
                successful.append(session_id)

        except Exception as e:
            failed.append({"session_id": session_id, "error": str(e)})

    return {
        "message": f"Processed {len(sessions)} sessions",
        "sessions_processed": len(sessions),
        "curriculums_generated": len(successful),
        "successful": successful,
        "failed": failed
    }


@mcp.tool()
async def get_curriculum(user_id: str, curriculum_id: int = 0) -> Dict[str, Any]:
    """Get a specific curriculum"""
    curriculum = db.get_curriculum(user_id, curriculum_id)
    if curriculum:
        return curriculum
    else:
        return {"error": f"Curriculum not found for user {user_id}, id {curriculum_id}"}


@mcp.tool()
async def search_learning_resources(topic: str, num_results: int = 10) -> Dict[str, Any]:
    """Search for learning resources on a topic (legacy compatibility)"""
    try:
        # ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì—ì´ì „íŠ¸ ì§ì ‘ í˜¸ì¶œ
        from servers.curriculum_agents.resource_collector import ResourceCollectorAgent
        resource_agent = ResourceCollectorAgent(llm)

        resources = await resource_agent._search_basic_resources(topic, num_results)

        return {
            "topic": topic,
            "resources": resources,
            "count": len(resources)
        }
    except Exception as e:
        return {"error": f"Resource search failed: {str(e)}"}


@mcp.tool()
async def get_curriculum_progress(session_id: str) -> Dict[str, Any]:
    """Get real-time progress of curriculum generation"""
    try:
        progress_file = f"data/progress/{session_id}.json"

        if os.path.exists(progress_file):
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            return progress_data
        else:
            return {"error": "No progress data found", "session_id": session_id}

    except Exception as e:
        return {"error": f"Failed to get progress: {str(e)}"}


@mcp.tool()
async def generate_lecture_notes(user_id: str, curriculum_id: int = 0, week: Optional[int] = None) -> Dict[str, Any]:
    """Generate lecture notes for a specific week using graph_curriculum content"""
    
    if not system_available:
        return {"error": "LangGraph system not available"}

    # ì»¤ë¦¬í˜ëŸ¼ ê°€ì ¸ì˜¤ê¸°
    curriculum = db.get_curriculum(user_id, curriculum_id)
    if not curriculum:
        return {"error": f"Curriculum not found for user {user_id}, id {curriculum_id}"}

    # graph_curriculumì´ ì—†ìœ¼ë©´ ì—ëŸ¬
    if "graph_curriculum" not in curriculum:
        return {"error": "Graph curriculum not found. Please generate curriculum with LangGraph first."}

    graph_curriculum = curriculum["graph_curriculum"]
    modules = curriculum.get("modules", [])

    try:
        # íŠ¹ì • ì£¼ì°¨ê°€ ì§€ì •ëœ ê²½ìš°
        if week is not None:
            target_module = next((m for m in modules if m["week"] == week), None)
            if not target_module:
                return {"error": f"Week {week} not found in curriculum"}
            
            lecture_note = await _generate_single_lecture_note(target_module, graph_curriculum, llm)
            
            # ì»¤ë¦¬í˜ëŸ¼ì— ê°•ì˜ìë£Œ ì¶”ê°€
            for module in curriculum["modules"]:
                if module["week"] == week:
                    module["lecture_note"] = lecture_note
                    break
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
            db.save_curriculum(user_id, curriculum)
            
            return {
                "message": f"Generated lecture note for week {week}",
                "week": week,
                "lecture_note": lecture_note
            }
        
        # ëª¨ë“  ì£¼ì°¨ì— ëŒ€í•´ ê°•ì˜ìë£Œ ìƒì„±
        else:
            generated_count = 0
            
            for module in curriculum["modules"]:
                # ì´ë¯¸ ê°•ì˜ìë£Œê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
                if "lecture_note" in module:
                    continue
                
                lecture_note = await _generate_single_lecture_note(module, graph_curriculum, llm)
                module["lecture_note"] = lecture_note
                generated_count += 1
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
            db.save_curriculum(user_id, curriculum)
            
            return {
                "message": f"Generated lecture notes for {generated_count} weeks",
                "total_weeks": len(modules),
                "generated_count": generated_count
            }

    except Exception as e:
        print(f"ERROR: Lecture note generation failed: {e}", file=sys.stderr)
        import traceback
        print(f"ERROR: Stacktrace: {traceback.format_exc()}", file=sys.stderr)
        return {"error": f"Lecture note generation failed: {str(e)}"}


def _extract_relevant_content_cached(graph_curriculum: Dict) -> Dict[str, List[Dict]]:
    """Extract and index content from graph_curriculum with caching"""
    global _content_cache

    # ìºì‹œ í‚¤ ìƒì„± (graph_curriculumì˜ í•´ì‹œ)
    cache_key = hash(str(sorted(graph_curriculum.items())))

    if cache_key in _content_cache:
        print(f"DEBUG: Using cached content index", file=sys.stderr)
        return _content_cache[cache_key]

    print(f"DEBUG: Building new content index", file=sys.stderr)
    start_time = time.time()

    content_index = {}

    for _, step_data in graph_curriculum.items():
        step_title = step_data.get("title", "").lower()
        skills = step_data.get("skills", {})

        for skill_name, skill_data in skills.items():
            documents = skill_data.get("documents", {})
            for _, doc_data in documents.items():
                content = doc_data.get("content", "")
                if content:
                    # í‚¤ì›Œë“œë¡œ ì¸ë±ì‹± (ìµœì í™”ë¨)
                    keywords = [step_title, skill_name.lower()]
                    keywords.extend(step_title.split())

                    for keyword in set(keywords):  # ì¤‘ë³µ ì œê±°
                        if keyword and len(keyword) > 2:  # ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ
                            if keyword not in content_index:
                                content_index[keyword] = []
                            content_index[keyword].append({
                                "source": f"{step_data.get('title', '')} - {skill_name}",
                                "content": content[:800]  # ë” ì§§ê²Œ ì œí•œ
                            })

    # ìºì‹œì— ì €ì¥ (ë©”ëª¨ë¦¬ ì œí•œì„ ìœ„í•´ ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ)
    if len(_content_cache) >= 5:
        # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
        oldest_key = next(iter(_content_cache))
        del _content_cache[oldest_key]

    _content_cache[cache_key] = content_index

    build_time = time.time() - start_time
    print(f"DEBUG: Content index built in {build_time:.2f}s with {len(content_index)} keywords", file=sys.stderr)

    return content_index

def _extract_relevant_content(graph_curriculum: Dict) -> Dict[str, List[Dict]]:
    """Legacy wrapper for compatibility"""
    return _extract_relevant_content_cached(graph_curriculum)


async def _generate_lecture_notes_concurrent(modules: List[Dict], graph_curriculum: Dict, llm) -> List[str]:
    """Generate lecture notes for multiple modules concurrently with semaphore control"""
    global _semaphore

    start_time = time.time()
    print(f"DEBUG: Starting concurrent lecture note generation for {len(modules)} modules", file=sys.stderr)

    # ì½˜í…ì¸  ì¸ë±ì‹± (í•œ ë²ˆë§Œ ìˆ˜í–‰, ìºì‹œë¨)
    content_index = _extract_relevant_content_cached(graph_curriculum)

    # Semaphoreë¡œ ì œì–´ë˜ëŠ” ë³‘ë ¬ ê°•ì˜ìë£Œ ìƒì„±
    tasks = [
        _generate_single_lecture_note_with_semaphore(module, content_index, llm)
        for module in modules
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    # ì˜ˆì™¸ ì²˜ë¦¬
    lecture_notes = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            print(f"ERROR: Failed to generate lecture note for module {i+1}: {result}", file=sys.stderr)
            lecture_notes.append(f"# {modules[i].get('title', f'Week {i+1}')}\\n\\nê°•ì˜ìë£Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(result)}")
        else:
            lecture_notes.append(result)

    total_time = time.time() - start_time
    print(f"DEBUG: Concurrent lecture note generation completed in {total_time:.2f}s", file=sys.stderr)

    return lecture_notes


async def _generate_single_lecture_note_with_semaphore(module: Dict, content_index: Dict, llm) -> str:
    """Generate lecture note with semaphore control for better resource management"""
    global _semaphore

    async with _semaphore:
        return await _generate_single_lecture_note_optimized(module, content_index, llm)

async def _generate_single_lecture_note_optimized(module: Dict, content_index: Dict, llm) -> str:
    """Generate lecture note for a single module using pre-indexed content"""

    week = module["week"]
    title = module["title"]
    description = module.get("description", "")
    objectives = module.get("objectives", [])
    key_concepts = module.get("key_concepts", [])

    start_time = time.time()

    # ê´€ë ¨ ì½˜í…ì¸ ë¥¼ ì¸ë±ìŠ¤ì—ì„œ ë¹ ë¥´ê²Œ ê²€ìƒ‰ (ë” íš¨ìœ¨ì )
    relevant_contents = []
    searched_keywords = set()

    for concept in key_concepts[:3]:  # ìµœëŒ€ 3ê°œ ê°œë…ë§Œ ì²˜ë¦¬
        concept_lower = concept.lower()
        keywords = [concept_lower] + [kw for kw in concept_lower.split() if len(kw) > 2]

        for keyword in keywords:
            if keyword not in searched_keywords and keyword in content_index:
                relevant_contents.extend(content_index[keyword][:1])  # ê° í‚¤ì›Œë“œë‹¹ 1ê°œë§Œ
                searched_keywords.add(keyword)

    # ì¤‘ë³µ ì œê±° ë° ì œí•œ (ë” ì—„ê²©)
    unique_contents = []
    seen_sources = set()
    for content in relevant_contents[:2]:  # ìµœëŒ€ 2ê°œë¡œ ë” ì œí•œ
        if content["source"] not in seen_sources:
            unique_contents.append(content)
            seen_sources.add(content["source"])

    # ë” ê°„ì†Œí™”ëœ ì°¸ê³ ìë£Œ
    reference_text = "\n\n".join([f"**{content['source']}**\n{content['content'][:500]}"
                                  for content in unique_contents[:1]])  # 1ê°œë§Œ ì‚¬ìš©

    prompt = f"""ì£¼ì°¨: {week}ì£¼ì°¨ - {title}

í•™ìŠµëª©í‘œ: {', '.join(objectives[:2])}
í•µì‹¬ê°œë…: {', '.join(key_concepts[:3])}

ì°¸ê³ ìë£Œ:
{reference_text}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ê°„ë‹¨ëª…ë£Œí•œ ê°•ì˜ìë£Œë¥¼ ì‘ì„±í•˜ì„¸ìš”:

# {week}ì£¼ì°¨: {title}

## í•™ìŠµ ê°œìš”
{description[:100]}...ì˜ ëª©ì ê³¼ ì¤‘ìš”ì„±

## í•µì‹¬ ê°œë…
- ê°œë… 1: ì„¤ëª…
- ê°œë… 2: ì„¤ëª…

## ì‹¤ìŠµ ì˜ˆì œ
êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì˜ˆì œ 1ê°œ

## ì •ë¦¬
í•µì‹¬ ë‚´ìš© ìš”ì•½ (3ì¤„ ì´ë‚´)

ì´ˆë³´ìë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

    try:
        llm_start = time.time()
        response = await llm.ainvoke(prompt)
        llm_time = time.time() - llm_start

        total_time = time.time() - start_time
        print(f"DEBUG: Week {week} lecture note generated in {total_time:.2f}s (LLM: {llm_time:.2f}s)", file=sys.stderr)

        return response.content
    except Exception as e:
        print(f"ERROR: Week {week} lecture note generation failed: {e}", file=sys.stderr)
        return f"# {week}ì£¼ì°¨: {title}\n\nê°•ì˜ìë£Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


async def _generate_single_lecture_note(module: Dict, graph_curriculum: Dict, llm) -> str:
    """Generate lecture note for a single module using graph_curriculum content (legacy)"""
    content_index = _extract_relevant_content_cached(graph_curriculum)
    return await _generate_single_lecture_note_with_semaphore(module, content_index, llm)


if __name__ == "__main__":
    print("ğŸš€ Starting LangGraph-based Curriculum Generator")
    print(f"ğŸ¤– System available: {system_available}")
    if system_available:
        print("ğŸ¯ All LangGraph agents loaded successfully")
    else:
        print("âŒ System initialization failed - running in fallback mode")

    mcp.run()