"""
LangGraph ê¸°ë°˜ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì„œë²„ (v2)
ê¸°ì¡´ generate_curriculum.pyë¥¼ LangGraph Agent ì‹œìŠ¤í…œìœ¼ë¡œ ì™„ì „íˆ ë¦¬íŒ©í† ë§
"""
from mcp.server.fastmcp import FastMCP
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
import os
import sys
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
from enum import Enum

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config

# ìƒˆë¡œìš´ Agent ì‹œìŠ¤í…œ import
from servers.curriculum_agents.workflow import create_curriculum_workflow
from servers.curriculum_agents.state import ProcessingPhase


# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í´ë˜ìŠ¤ë“¤ ìœ ì§€
class LevelEnum(str, Enum):
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"


class SessionParameters(BaseModel):
    level: LevelEnum = Field(default=LevelEnum.BEGINNER, description="í•™ìŠµ ìˆ˜ì¤€")
    duration_weeks: int = Field(default=4, description="í•™ìŠµ ê¸°ê°„ (ì£¼ ë‹¨ìœ„, 1-24 ì‚¬ì´)", ge=1, le=24)
    focus_areas: List[str] = Field(default=[], description="ì¤‘ì  í•™ìŠµ ì˜ì—­")
    weekly_hours: int = Field(default=10, description="ì£¼ë‹¹ í•™ìŠµ ê°€ëŠ¥ ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„, 1-40 ì‚¬ì´)", ge=1, le=40)


class ExtractionRequest(BaseModel):
    constraints: str = Field(description="í•™ìŠµ ì œì•½ ì¡°ê±´")
    goal: str = Field(description="í•™ìŠµ ëª©í‘œ")


# ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ (CurriculumDB, SessionLoader) ìœ ì§€í•˜ë˜ ê°„ì†Œí™”
class CurriculumDB:
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        os.makedirs(data_dir, exist_ok=True)
        self.db_file = os.path.join(data_dir, "curriculums.json")
        self.data = self._load_data()

    def _load_data(self):
        try:
            if os.path.exists(self.db_file):
                with open(self.db_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"DEBUG: Error loading curriculum DB: {e}", file=sys.stderr)
        return {}

    def _save_data(self):
        try:
            with open(self.db_file, 'w', encoding='utf-8') as f:
                json.dump(self.data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"DEBUG: Error saving curriculum DB: {e}", file=sys.stderr)

    def save_curriculum(self, user_id: str, curriculum: Dict):
        if user_id not in self.data:
            self.data[user_id] = []

        curriculum_id = len(self.data[user_id])
        curriculum["id"] = curriculum_id
        self.data[user_id].append(curriculum)
        self._save_data()
        return curriculum_id

    def get_curriculum(self, user_id: str, curriculum_id: int) -> Optional[Dict]:
        user_curriculums = self.data.get(user_id, [])
        if 0 <= curriculum_id < len(user_curriculums):
            return user_curriculums[curriculum_id]
        return None


class SessionLoader:
    def __init__(self, sessions_dir: str = "sessions"):
        self.sessions_dir = sessions_dir

    def get_session_by_id(self, session_id: str) -> Optional[Dict[str, Any]]:
        try:
            # Search for the file in the directory and subdirectories
            for root, _, files in os.walk(self.sessions_dir):
                for filename in files:
                    if filename == f"{session_id}.json":
                        session_path = os.path.join(root, filename)
                        with open(session_path, 'r', encoding='utf-8') as f:
                            return json.load(f)
        except Exception as e:
            print(f"DEBUG: Error loading session {session_id}: {e}", file=sys.stderr)
        return None

    def get_completed_sessions(self) -> List[Dict[str, Any]]:
        sessions = []
        try:
            if os.path.exists(self.sessions_dir):
                for root, _, files in os.walk(self.sessions_dir):
                    for filename in files:
                        if filename.endswith('.json'):
                            session_path = os.path.join(root, filename)
                            with open(session_path, 'r', encoding='utf-8') as f:
                                session_data = json.load(f)
                                # status=='completed' ë˜ëŠ” completed==True ëª¨ë‘ ì§€ì›
                                if (session_data.get('status') == 'completed' or
                                    session_data.get('completed') == True):
                                    sessions.append(session_data)
        except Exception as e:
            print(f"DEBUG: Error loading sessions: {e}", file=sys.stderr)
        return sessions

    def update_session_with_curriculum(self, session_id: str, curriculum: Dict[str, Any]) -> bool:
        try:
            session_file = os.path.join(self.sessions_dir, f"{session_id}.json")
            if os.path.exists(session_file):
                with open(session_file, 'r', encoding='utf-8') as f:
                    session_data = json.load(f)

                session_data['curriculum'] = {
                    'id': curriculum.get('curriculum_id'),
                    'title': curriculum.get('title'),
                    'generated_at': curriculum.get('generated_at')
                }

                with open(session_file, 'w', encoding='utf-8') as f:
                    json.dump(session_data, f, ensure_ascii=False, indent=2)
                return True
        except Exception as e:
            print(f"DEBUG: Error updating session with curriculum: {e}", file=sys.stderr)
        return False


# MCP ì„œë²„ ì„¤ì •
mcp = FastMCP(
    "CurriculumGenerator",
    instructions="Generate personalized learning curriculums using LangGraph agents",
    host="0.0.0.0",
    port=8006,  # ê¸°ì¡´ í¬íŠ¸ ì‚¬ìš©
)

# LLM ë° ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
def initialize_system():
    try:
        llm = ChatOpenAI(
            base_url=Config.LLM_BASE_URL,
            api_key=Config.LLM_API_KEY,
            model=Config.LLM_MODEL,
            temperature=0.7,
            max_tokens=Config.LLM_MAX_TOKENS,
            model_kwargs={"max_completion_tokens": None}
        )

        workflow = create_curriculum_workflow(llm)
        return llm, workflow, True
    except Exception as e:
        print(f"ERROR: System initialization failed: {e}", file=sys.stderr)
        return None, None, False


llm, workflow, system_available = initialize_system()
db = CurriculumDB()
session_loader = SessionLoader()


def extract_duration_from_message(message: str) -> Optional[int]:
    """ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€"""
    import re
    if not message:
        return None

    duration_patterns = [
        r'(\d+)\s*ì£¼',
        r'(\d+)\s*week',
        r'(\d+)\s*ë‹¬',
        r'(\d+)\s*month'
    ]

    for pattern in duration_patterns:
        match = re.search(pattern, message.lower())
        if match:
            duration = int(match.group(1))
            if 'month' in pattern or 'ë‹¬' in pattern:
                duration *= 4

            if 1 <= duration <= 24:
                return duration
    return None


@mcp.tool()
async def list_session_topics() -> Dict[str, Any]:
    """List all completed sessions available for curriculum generation"""
    sessions = session_loader.get_completed_sessions()
    return {
        "message": f"Found {len(sessions)} completed sessions",
        "sessions": [
            {
                "session_id": s["session_id"],
                "topic": s["topic"],
                "goal": s["goal"],
                "constraints": s["constraints"]
            }
            for s in sessions
        ],
        "all_sessions": sessions
    }


@mcp.tool()
async def generate_curriculum_from_session(session_id: str, user_message: str = "") -> Dict[str, Any]:
    """Generate curriculum from a specific session using LangGraph agents"""

    if not system_available:
        return {"error": "LangGraph system not available"}

    session_data = session_loader.get_session_by_id(session_id)

    if not session_data:
        return {"error": f"Session {session_id} not found"}

    print(f"DEBUG: Starting LangGraph curriculum generation for {session_id}", file=sys.stderr)
    print(f"DEBUG: Session data - topic: {session_data.get('topic')}, constraints: {session_data.get('constraints')}, goal: {session_data.get('goal')}", file=sys.stderr)

    try:
        # LangGraph ì›Œí¬í”Œë¡œìš°ë¡œ ì»¤ë¦¬í˜ëŸ¼ ìƒì„±
        curriculum = await workflow.generate_curriculum(
            session_id=session_id,
            topic=session_data["topic"],
            constraints=session_data["constraints"],
            goal=session_data["goal"],
            user_message=user_message
        )

        print(f"DEBUG: LangGraph workflow completed", file=sys.stderr)
        print(f"DEBUG: Generated curriculum type: {type(curriculum)}", file=sys.stderr)

        # fallback ì»¤ë¦¬í˜ëŸ¼ì¸ì§€ í™•ì¸
        if curriculum.get("fallback"):
            print(f"WARNING: Fallback curriculum was generated", file=sys.stderr)
        else:
            print(f"SUCCESS: Complete curriculum generated with graph_curriculum: {'graph_curriculum' in curriculum}", file=sys.stderr)

        # ê°•ì˜ìë£Œ ìë™ ìƒì„± (graph_curriculumì´ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        lecture_generation_success = True
        if "graph_curriculum" in curriculum and "modules" in curriculum and not curriculum.get("fallback"):
            print(f"DEBUG: Generating lecture notes for {session_id}", file=sys.stderr)
            try:
                # ë³‘ë ¬ë¡œ ëª¨ë“  ëª¨ë“ˆì˜ ê°•ì˜ìë£Œ ìƒì„±
                lecture_notes = await _generate_lecture_notes_concurrent(curriculum["modules"], curriculum["graph_curriculum"], llm)
                
                # ìƒì„±ëœ ê°•ì˜ìë£Œ ê²€ì¦
                successful_notes = 0
                for i, module in enumerate(curriculum["modules"]):
                    if i < len(lecture_notes) and lecture_notes[i] and not ("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤" in lecture_notes[i]):
                        # ìœ íš¨í•œ ê°•ì˜ìë£Œì¸ì§€ ê²€ì¦ (ìµœì†Œ ê¸¸ì´ í™•ì¸)
                        if len(lecture_notes[i].strip()) > 50:
                            module["lecture_note"] = lecture_notes[i]
                            successful_notes += 1
                        else:
                            print(f"WARNING: Generated lecture note too short for week {module.get('week', i+1)}", file=sys.stderr)
                            lecture_generation_success = False
                    else:
                        print(f"WARNING: Failed to generate lecture note for week {module.get('week', i+1)}", file=sys.stderr)
                        lecture_generation_success = False
                
                if successful_notes == len(curriculum["modules"]):
                    print(f"SUCCESS: All {successful_notes} lecture notes generated successfully", file=sys.stderr)
                    curriculum["lecture_notes_complete"] = True
                else:
                    print(f"WARNING: Only {successful_notes}/{len(curriculum['modules'])} lecture notes generated", file=sys.stderr)
                    curriculum["lecture_notes_complete"] = False
                    lecture_generation_success = False
                    
            except Exception as e:
                print(f"ERROR: Lecture note generation failed: {e}", file=sys.stderr)
                import traceback
                print(f"ERROR: Lecture note stacktrace: {traceback.format_exc()}", file=sys.stderr)
                curriculum["lecture_notes_complete"] = False
                lecture_generation_success = False

        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        curriculum_id = db.save_curriculum(session_id, curriculum)
        curriculum["curriculum_id"] = curriculum_id

        # ì„¸ì…˜ íŒŒì¼ ì—…ë°ì´íŠ¸
        session_loader.update_session_with_curriculum(session_id, curriculum)

        # ê°•ì˜ìë£Œ ìƒì„± ìƒíƒœë¥¼ í¬í•¨í•œ ê²°ê³¼ ë°˜í™˜
        result = curriculum.copy()
        result["generation_status"] = {
            "curriculum_complete": True,
            "lecture_notes_complete": curriculum.get("lecture_notes_complete", False),
            "overall_success": lecture_generation_success and not curriculum.get("fallback", False)
        }

        return result

    except Exception as e:
        print(f"ERROR: LangGraph curriculum generation failed: {e}", file=sys.stderr)
        import traceback
        print(f"ERROR: Stacktrace: {traceback.format_exc()}", file=sys.stderr)
        return {"error": f"Curriculum generation failed: {str(e)}"}


@mcp.tool()
async def generate_curriculums_from_all_sessions() -> Dict[str, Any]:
    """Generate curriculums for all completed sessions using LangGraph"""

    if not system_available:
        return {"error": "LangGraph system not available"}

    sessions = session_loader.get_completed_sessions()

    if not sessions:
        return {
            "message": "No completed sessions found",
            "sessions_processed": 0,
            "curriculums_generated": 0
        }

    successful = []
    failed = []

    for session in sessions:
        session_id = session["session_id"]

        try:
            # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            existing = db.get_curriculum(session_id, 0)
            if existing:
                continue

            result = await generate_curriculum_from_session(session_id)

            if "error" in result:
                failed.append({"session_id": session_id, "error": result["error"]})
            else:
                successful.append(session_id)

        except Exception as e:
            failed.append({"session_id": session_id, "error": str(e)})

    return {
        "message": f"Processed {len(sessions)} sessions",
        "sessions_processed": len(sessions),
        "curriculums_generated": len(successful),
        "successful": successful,
        "failed": failed
    }


@mcp.tool()
async def get_curriculum(user_id: str, curriculum_id: int = 0) -> Dict[str, Any]:
    """Get a specific curriculum"""
    curriculum = db.get_curriculum(user_id, curriculum_id)
    if curriculum:
        return curriculum
    else:
        return {"error": f"Curriculum not found for user {user_id}, id {curriculum_id}"}


@mcp.tool()
async def search_learning_resources(topic: str, num_results: int = 10) -> Dict[str, Any]:
    """Search for learning resources on a topic (legacy compatibility)"""
    try:
        # ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘ ì—ì´ì „íŠ¸ ì§ì ‘ í˜¸ì¶œ
        from servers.curriculum_agents.resource_collector import ResourceCollectorAgent
        resource_agent = ResourceCollectorAgent(llm)

        resources = await resource_agent._search_basic_resources(topic, num_results)

        return {
            "topic": topic,
            "resources": resources,
            "count": len(resources)
        }
    except Exception as e:
        return {"error": f"Resource search failed: {str(e)}"}


@mcp.tool()
async def get_curriculum_progress(session_id: str) -> Dict[str, Any]:
    """Get real-time progress of curriculum generation"""
    try:
        progress_file = f"data/progress/{session_id}.json"

        if os.path.exists(progress_file):
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            return progress_data
        else:
            return {"error": "No progress data found", "session_id": session_id}

    except Exception as e:
        return {"error": f"Failed to get progress: {str(e)}"}


@mcp.tool()
async def generate_lecture_notes(user_id: str, curriculum_id: int = 0, week: Optional[int] = None) -> Dict[str, Any]:
    """Generate lecture notes for a specific week using graph_curriculum content"""
    
    if not system_available:
        return {"error": "LangGraph system not available"}

    # ì»¤ë¦¬í˜ëŸ¼ ê°€ì ¸ì˜¤ê¸°
    curriculum = db.get_curriculum(user_id, curriculum_id)
    if not curriculum:
        return {"error": f"Curriculum not found for user {user_id}, id {curriculum_id}"}

    # graph_curriculumì´ ì—†ìœ¼ë©´ ì—ëŸ¬
    if "graph_curriculum" not in curriculum:
        return {"error": "Graph curriculum not found. Please generate curriculum with LangGraph first."}

    graph_curriculum = curriculum["graph_curriculum"]
    modules = curriculum.get("modules", [])

    try:
        # íŠ¹ì • ì£¼ì°¨ê°€ ì§€ì •ëœ ê²½ìš°
        if week is not None:
            target_module = next((m for m in modules if m["week"] == week), None)
            if not target_module:
                return {"error": f"Week {week} not found in curriculum"}
            
            lecture_note = await _generate_single_lecture_note(target_module, graph_curriculum, llm)
            
            # ì»¤ë¦¬í˜ëŸ¼ì— ê°•ì˜ìë£Œ ì¶”ê°€
            for module in curriculum["modules"]:
                if module["week"] == week:
                    module["lecture_note"] = lecture_note
                    break
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
            db.save_curriculum(user_id, curriculum)
            
            return {
                "message": f"Generated lecture note for week {week}",
                "week": week,
                "lecture_note": lecture_note
            }
        
        # ëª¨ë“  ì£¼ì°¨ì— ëŒ€í•´ ê°•ì˜ìë£Œ ìƒì„±
        else:
            generated_count = 0
            
            for module in curriculum["modules"]:
                # ì´ë¯¸ ê°•ì˜ìë£Œê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
                if "lecture_note" in module:
                    continue
                
                lecture_note = await _generate_single_lecture_note(module, graph_curriculum, llm)
                module["lecture_note"] = lecture_note
                generated_count += 1
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
            db.save_curriculum(user_id, curriculum)
            
            return {
                "message": f"Generated lecture notes for {generated_count} weeks",
                "total_weeks": len(modules),
                "generated_count": generated_count
            }

    except Exception as e:
        print(f"ERROR: Lecture note generation failed: {e}", file=sys.stderr)
        import traceback
        print(f"ERROR: Stacktrace: {traceback.format_exc()}", file=sys.stderr)
        return {"error": f"Lecture note generation failed: {str(e)}"}


def _extract_relevant_content(graph_curriculum: Dict) -> Dict[str, List[Dict]]:
    """Extract and index content from graph_curriculum for faster lookup"""
    content_index = {}
    
    for _, step_data in graph_curriculum.items():
        step_title = step_data.get("title", "").lower()
        skills = step_data.get("skills", {})
        
        for skill_name, skill_data in skills.items():
            documents = skill_data.get("documents", {})
            for _, doc_data in documents.items():
                content = doc_data.get("content", "")
                if content:
                    # í‚¤ì›Œë“œë¡œ ì¸ë±ì‹±
                    keywords = [step_title, skill_name.lower()] + step_title.split()
                    for keyword in keywords:
                        if keyword not in content_index:
                            content_index[keyword] = []
                        content_index[keyword].append({
                            "source": f"{step_data.get('title', '')} - {skill_name}",
                            "content": content[:1500]  # ê¸¸ì´ ì œí•œìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìµœì í™”
                        })
    
    return content_index


async def _generate_lecture_notes_concurrent(modules: List[Dict], graph_curriculum: Dict, llm) -> List[str]:
    """Generate lecture notes for multiple modules concurrently"""
    import asyncio
    
    # ì½˜í…ì¸  ì¸ë±ì‹± (í•œ ë²ˆë§Œ ìˆ˜í–‰)
    content_index = _extract_relevant_content(graph_curriculum)
    
    # ë³‘ë ¬ë¡œ ê°•ì˜ìë£Œ ìƒì„±
    tasks = [
        _generate_single_lecture_note_optimized(module, content_index, llm)
        for module in modules
    ]
    
    return await asyncio.gather(*tasks)


async def _generate_single_lecture_note_optimized(module: Dict, content_index: Dict, llm) -> str:
    """Generate lecture note for a single module using pre-indexed content"""
    
    week = module["week"]
    title = module["title"]
    description = module.get("description", "")
    objectives = module.get("objectives", [])
    key_concepts = module.get("key_concepts", [])
    
    # ê´€ë ¨ ì½˜í…ì¸ ë¥¼ ì¸ë±ìŠ¤ì—ì„œ ë¹ ë¥´ê²Œ ê²€ìƒ‰
    relevant_contents = []
    for concept in key_concepts:
        concept_lower = concept.lower()
        for keyword in [concept_lower] + concept_lower.split():
            if keyword in content_index:
                relevant_contents.extend(content_index[keyword][:2])  # ê° í‚¤ì›Œë“œë‹¹ ìµœëŒ€ 2ê°œ
                
    # ì¤‘ë³µ ì œê±° ë° ì œí•œ
    unique_contents = []
    seen_sources = set()
    for content in relevant_contents[:4]:  # ìµœëŒ€ 4ê°œë¡œ ì œí•œ
        if content["source"] not in seen_sources:
            unique_contents.append(content)
            seen_sources.add(content["source"])
    
    # ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì„±ëŠ¥ í–¥ìƒ
    reference_text = "\n\n".join([f"**{content['source']}**\n{content['content'][:800]}" 
                                  for content in unique_contents[:2]])
    
    prompt = f"""ì£¼ì°¨: {week}ì£¼ì°¨ - {title}

í•™ìŠµëª©í‘œ: {', '.join(objectives[:2])}
í•µì‹¬ê°œë…: {', '.join(key_concepts[:3])}

ì°¸ê³ ìë£Œ:
{reference_text}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ê°„ë‹¨ëª…ë£Œí•œ ê°•ì˜ìë£Œë¥¼ ì‘ì„±í•˜ì„¸ìš”:

# {week}ì£¼ì°¨: {title}

## í•™ìŠµ ê°œìš”
{description[:100]}...ì˜ ëª©ì ê³¼ ì¤‘ìš”ì„±

## í•µì‹¬ ê°œë…
- ê°œë… 1: ì„¤ëª…
- ê°œë… 2: ì„¤ëª…

## ì‹¤ìŠµ ì˜ˆì œ
êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì˜ˆì œ 1ê°œ

## ì •ë¦¬
í•µì‹¬ ë‚´ìš© ìš”ì•½ (3ì¤„ ì´ë‚´)

ì´ˆë³´ìë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

    try:
        response = await llm.ainvoke(prompt)
        return response.content
    except Exception as e:
        return f"# {week}ì£¼ì°¨: {title}\n\nê°•ì˜ìë£Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


async def _generate_single_lecture_note(module: Dict, graph_curriculum: Dict, llm) -> str:
    """Generate lecture note for a single module using graph_curriculum content (legacy)"""
    content_index = _extract_relevant_content(graph_curriculum)
    return await _generate_single_lecture_note_optimized(module, content_index, llm)


if __name__ == "__main__":
    print("ğŸš€ Starting LangGraph-based Curriculum Generator")
    print(f"ğŸ¤– System available: {system_available}")
    if system_available:
        print("ğŸ¯ All LangGraph agents loaded successfully")
    else:
        print("âŒ System initialization failed - running in fallback mode")

    mcp.run()