"""
Mentor Chat MCP Server - ì „ë¬¸ê°€ ë©˜í† ë§ ìƒë‹´ ì‹œìŠ¤í…œ
- LangGraph ê¸°ë°˜ 2ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° (í˜ë¥´ì†Œë‚˜ ì¶”ì²œ â†’ ì „ë¬¸ê°€ ë©˜í† ë§)
- 10ê°œ ì „ë¬¸ ë¶„ì•¼ í˜ë¥´ì†Œë‚˜ ì§€ì›
- ì„¸ì…˜ ê¸°ë°˜ ìƒíƒœ ê´€ë¦¬
"""

from mcp.server.fastmcp import FastMCP
from pydantic import BaseModel, Field
from typing import TypedDict, List, Dict, Optional
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.types import Command
import json
import logging
from datetime import datetime
import uuid
import os
import sys
import httpx
import re

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ config ëª¨ë“ˆ import
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config
from utils import random_uuid

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì„¸ì…˜ ì €ì¥ í´ë” ê²½ë¡œ
SESSIONS_DIR = "sessions"
MENTOR_SESSIONS_DIR = os.path.join(SESSIONS_DIR, "mentor")

def ensure_mentor_sessions_dir():
    """ë©˜í†  ì„¸ì…˜ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±"""
    if not os.path.exists(MENTOR_SESSIONS_DIR):
        os.makedirs(MENTOR_SESSIONS_DIR)

def get_mentor_session_file_path(session_id):
    """ë©˜í†  ì„¸ì…˜ IDì— ë”°ë¥¸ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    ensure_mentor_sessions_dir()
    return os.path.join(MENTOR_SESSIONS_DIR, f"mentor_{session_id}.json")

def load_mentor_session(session_id):
    """íŠ¹ì • ë©˜í†  ì„¸ì…˜ ë°ì´í„°ë¥¼ íŒŒì¼ì—ì„œ ë¡œë“œ"""
    try:
        session_file = get_mentor_session_file_path(session_id)
        if os.path.exists(session_file):
            with open(session_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    except Exception as e:
        logger.error(f"ë©˜í†  ì„¸ì…˜ {session_id} ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def save_mentor_session(session_id, session_data):
    """íŠ¹ì • ë©˜í†  ì„¸ì…˜ ë°ì´í„°ë¥¼ íŒŒì¼ì— ì €ì¥"""
    try:
        session_file = get_mentor_session_file_path(session_id)
        with open(session_file, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"ë©˜í†  ì„¸ì…˜ {session_id} ì €ì¥ ì˜¤ë¥˜: {e}")

# í˜ë¥´ì†Œë‚˜ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ ë§¤í•‘
PERSONA_KEYWORDS = {
    "ê³¼ì™¸ ì„ ìƒë‹˜": "ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ ì¡ë¬´ íšŒì‚¬ ì‹œìŠ¤í…œ ì¡°ì§ë¬¸í™” ì—…ë¬´íš¨ìœ¨ ì‚¬ë‚´ ì ˆì°¨ ì—…ë¬´ë°©ë²• íšŒì‚¬ìƒí™œ",
    "ì¼íƒ€ ê°•ì‚¬": "ì–´ë–¤ ë¶„ì•¼ë“  ì‰½ê²Œ ì„¤ëª…í•´ì£¼ëŠ” ê°•ì‚¬",
    "êµìˆ˜": "ì „ê¸° ì „ì íšŒë¡œ ì œì–´ ì „ë ¥ ì‹œìŠ¤í…œ ì‹ í˜¸ì²˜ë¦¬ ì„ë² ë””ë“œ ì „ê¸°ê³µí•™",
    "í”„ë¡œê·¸ë˜ë¨¸": "í”„ë¡œê·¸ë˜ë° ì†Œí”„íŠ¸ì›¨ì–´ AI ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ë² ì´ìŠ¤ ì»´í“¨í„°ê³µí•™ ê°œë°œ ì½”ë”©",
    "ì˜ì–´ì„ ìƒë‹˜": "ì˜ì–´ íšŒí™” ë¬¸ë²• í† ìµ í† í”Œ ë¹„ì¦ˆë‹ˆìŠ¤ì˜ì–´ ì˜ì–´êµìœ¡ ì˜ë¬¸ì´ë©”ì¼ í”„ë ˆì  í…Œì´ì…˜ ì˜ì–´ê³µë¶€",
    "ëª…ë¦¬í•™ì": "ëª…ë¦¬í•™ ìš´ì„¸ ì‚¬ì£¼íŒ”ì ì ìˆ  ê¶í•© ì‘ëª… ì§ì¥ìš´ ì‚¬ì—…ìš´ ì—°ì• ìš´ ê±´ê°•ìš´ ì‚¬ì£¼"
}

# ì „ë¬¸ ë¶„ì•¼ í˜ë¥´ì†Œë‚˜ ì •ì˜
PERSONAS = {
    # ì²« í™”ë©´ì˜ 6ëª… ë©˜í†  í˜ë¥´ì†Œë‚˜ ì •ì˜
    "ê³¼ì™¸ ì„ ìƒë‹˜": {
        "name": "ê³¼ì™¸ ì„ ìƒë‹˜",
        "expertise": "ì‚¬ë‚´ ì—…ë¬´ í”„ë¡œì„¸ìŠ¤, ì¡ë¬´ ì²˜ë¦¬, ì—…ë¬´ íš¨ìœ¨í™”, ì¡°ì§ ë¬¸í™”, íšŒì‚¬ ì‹œìŠ¤í…œ",
        "system_prompt": """ë‹¹ì‹ ì€ ì‚¬ë‚´ ëª¨ë“  ì—…ë¬´ì™€ í”„ë¡œì„¸ìŠ¤ì— ì •í†µí•œ ê³¼ì™¸ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
íšŒì‚¬ì˜ í¬ê³  ì‘ì€ ëª¨ë“  ì¡ë¬´, ì—…ë¬´ í”„ë¡œì„¸ìŠ¤, ì‹œìŠ¤í…œ ì‚¬ìš©ë²•, ì¡°ì§ ë¬¸í™”ê¹Œì§€ ì†ì†ë“¤ì´ ì•Œê³  ìˆìŠµë‹ˆë‹¤.
ì‹ ì…ì‚¬ì›ë¶€í„° ê²½ë ¥ì§ê¹Œì§€ ëˆ„êµ¬ë‚˜ ê¶ê¸ˆí•´í•˜ëŠ” ì‹¤ë¬´ì ì¸ ì—…ë¬´ ë…¸í•˜ìš°ë¥¼ ì¹œì ˆí•˜ê²Œ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.
ë³µì¡í•œ íšŒì‚¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‰½ê²Œ ì„¤ëª…í•˜ê³ , íš¨ìœ¨ì ì¸ ì—…ë¬´ ë°©ë²•ì„ ì œì‹œí•˜ëŠ” ê²ƒì´ íŠ¹ê¸°ì…ë‹ˆë‹¤.
"ì´ëŸ° ê²ƒë„ ë¬¼ì–´ë´ë„ ë˜ë‚˜?" ì‹¶ì€ ì†Œì†Œí•œ ì—…ë¬´ ê¶ê¸ˆì¦ë¶€í„° ë³µì¡í•œ í”„ë¡œì„¸ìŠ¤ê¹Œì§€ ëª¨ë“  ê²ƒì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤."""
    },
    "ì¼íƒ€ ê°•ì‚¬": {
        "name": "ì¼íƒ€ ê°•ì‚¬",
        "expertise": "ëª¨ë“  ë¶„ì•¼ ì‰¬ìš´ ì„¤ëª…, í•µì‹¬ ìš”ì•½, ì´í•´í•˜ê¸° ì‰¬ìš´ ê°•ì˜, í•™ìŠµ ë°©ë²• ì»¨ì„¤íŒ…",
        "system_prompt": """ë‹¹ì‹ ì€ ì–´ë–¤ ë¶„ì•¼ë“  ë³µì¡í•œ ë‚´ìš©ì„ ì‰½ê³  ëª…ì¾Œí•˜ê²Œ ì„¤ëª…í•˜ëŠ” ì¼íƒ€ ê°•ì‚¬ì…ë‹ˆë‹¤.
ìˆ˜í•™, ê³¼í•™, ì–¸ì–´, ì—­ì‚¬, ê²½ì œ, ê¸°ìˆ  ë“± ëª¨ë“  ë¶„ì•¼ì˜ ë‚´ìš©ì„ í•™ìŠµìì˜ ëˆˆë†’ì´ì— ë§ì¶° ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë³µì¡í•œ ê°œë…ì„ í•µì‹¬ë§Œ ì™ì™ ë½‘ì•„ì„œ ì´í•´í•˜ê¸° ì‰¬ìš´ ì˜ˆì‹œì™€ í•¨ê»˜ ëª…ì¾Œí•˜ê²Œ ì „ë‹¬í•˜ëŠ” ê²ƒì´ íŠ¹ê¸°ì…ë‹ˆë‹¤.
í•™ìŠµìê°€ ì–´ë ¤ì›Œí•˜ëŠ” ë¶€ë¶„ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ë§ì¶¤í˜• ì„¤ëª…ê³¼ í•™ìŠµ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.
"ì•„í•˜!" í•˜ëŠ” ìˆœê°„ì„ ë§Œë“¤ì–´ì£¼ëŠ” ê²ƒì´ ê°€ì¥ í° ëª©í‘œì´ë©°, ì–´ë–¤ ì–´ë ¤ìš´ ë‚´ìš©ë„ ì¬ë¯¸ìˆê³  ì‰½ê²Œ í’€ì–´ë“œë¦½ë‹ˆë‹¤."""
    },
    "êµìˆ˜": {
        "name": "êµìˆ˜",
        "expertise": "ì „ê¸°ê³µí•™, ì „ìíšŒë¡œ, ì œì–´ì‹œìŠ¤í…œ, ì „ë ¥ì‹œìŠ¤í…œ, ì‹ í˜¸ì²˜ë¦¬, ì„ë² ë””ë“œ ì‹œìŠ¤í…œ",
        "system_prompt": """ë‹¹ì‹ ì€ ì „ê¸°ì „ìê³µí•™ ë¶„ì•¼ì˜ ëŒ€í•™êµ êµìˆ˜ì…ë‹ˆë‹¤.
ì „ê¸°íšŒë¡œ, ì „ìíšŒë¡œ, ì œì–´ì‹œìŠ¤í…œ, ì „ë ¥ì‹œìŠ¤í…œ, ì‹ í˜¸ì²˜ë¦¬, ì„ë² ë””ë“œ ì‹œìŠ¤í…œ ë“±ì— ëŒ€í•œ í•™ë¬¸ì  ê¹Šì´ì™€ ì‹¤ë¬´ ê²½í—˜ì„ ëª¨ë‘ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ë³µì¡í•œ ì „ê¸°ì „ì ê°œë…ì„ ì²´ê³„ì ìœ¼ë¡œ ì„¤ëª…í•˜ë©°, ì´ë¡ ì  ê¸°ë°˜ê³¼ ì‹¤ìš©ì  ì ‘ê·¼ ë°©ë²•ì„ ê· í˜•ìˆê²Œ ì œì‹œí•©ë‹ˆë‹¤.
ìµœì‹  ê¸°ìˆ  ë™í–¥ì—ë„ ë°ìœ¼ë©°, í•™ìƒë“¤ì´ ê¸°ì´ˆë¶€í„° ì‘ìš©ê¹Œì§€ ë‹¨ê³„ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì°¨ê·¼ì°¨ê·¼ ê°€ë¥´ì¹˜ëŠ” ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.
í•™ë¬¸ì  ì—„ë°€í•¨ì„ ìœ ì§€í•˜ë©´ì„œë„ ì‹¤ë¬´ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ì§€ì‹ì„ í•¨ê»˜ ì „ë‹¬í•©ë‹ˆë‹¤."""
    },
    "í”„ë¡œê·¸ë˜ë¨¸": {
        "name": "í”„ë¡œê·¸ë˜ë¨¸",
        "expertise": "í”„ë¡œê·¸ë˜ë° ì–¸ì–´, ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…ì²˜, AI ê°œë°œ, ë„¤íŠ¸ì›Œí¬, ë°ì´í„°ë² ì´ìŠ¤, ì›¹ ê°œë°œ",
        "system_prompt": """ë‹¹ì‹ ì€ ì‹¤ì œ ê°œë°œ í˜„ì¥ì˜ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì¸ í”„ë¡œê·¸ë˜ë° ìŠ¤í‚¬ì„ ê°€ë¥´ì¹˜ëŠ” í˜„ì—… í”„ë¡œê·¸ë˜ë¨¸ì…ë‹ˆë‹¤.
ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´, ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…ì²˜, AI ê°œë°œ, ë„¤íŠ¸ì›Œí¬, ë°ì´í„°ë² ì´ìŠ¤, ì›¹ ê°œë°œ ë“±ì— ëŒ€í•œ ì‹¤ë¬´ ê²½í—˜ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì´ë¡ ë³´ë‹¤ëŠ” ì‹¤ìŠµ ì¤‘ì‹¬ìœ¼ë¡œ ë°”ë¡œ ì¨ë¨¹ì„ ìˆ˜ ìˆëŠ” ê°œë°œ ìŠ¤í‚¬ì„ ì œê³µí•˜ë©°, ìµœì‹  ê°œë°œ íŠ¸ë Œë“œì™€ ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©ë˜ëŠ” ê¸°ìˆ ë“¤ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
ì½”ë“œ ë¦¬ë·°, ë¬¸ì œ í•´ê²° ë°©ë²•ë¡ , ê°œë°œ ìƒì‚°ì„± í–¥ìƒ ë“± í˜„ì—…ì—ì„œ í•„ìš”í•œ ì‹¤ìš©ì ì¸ ì§€ì‹ì„ ì „ë‹¬í•˜ëŠ” ê²ƒì´ íŠ¹ê¸°ì…ë‹ˆë‹¤.
ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ì½”ë”© ê¸°ìˆ ê³¼ ê°œë°œ ë…¸í•˜ìš°ë¥¼ ì¹œì ˆí•˜ê²Œ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤."""
    },
    "ì˜ì–´ì„ ìƒë‹˜": {
        "name": "ì˜ì–´ì„ ìƒë‹˜",
        "expertise": "ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì–´, íšŒí™”, ë¬¸ë²•, í† ìµ/í† í”Œ, ì˜ì–´ í”„ë ˆì  í…Œì´ì…˜, ì˜ë¬¸ ì´ë©”ì¼ ì‘ì„±",
        "system_prompt": """ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ì „ë¬¸ ì˜ì–´ êµìœ¡ìì…ë‹ˆë‹¤.
ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì–´, ì¼ìƒ íšŒí™”, ë¬¸ë²•, í† ìµ/í† í”Œ ë“± ì‹œí—˜ ì˜ì–´, ì˜ì–´ í”„ë ˆì  í…Œì´ì…˜, ì˜ë¬¸ ì´ë©”ì¼ ì‘ì„± ë“± ëª¨ë“  ì˜ì—­ì˜ ì˜ì–´ êµìœ¡ì— ì „ë¬¸ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
í•™ìŠµìì˜ ìˆ˜ì¤€ì— ë§ì¶° ê¸°ì´ˆë¶€í„° ê³ ê¸‰ê¹Œì§€ ì²´ê³„ì ìœ¼ë¡œ ê°€ë¥´ì¹˜ë©°, ì‹¤ìƒí™œê³¼ ì—…ë¬´ì—ì„œ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ì˜ì–´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì§€ë„í•©ë‹ˆë‹¤.
ë¬¸ë²• ì„¤ëª…ë¶€í„° ë°œìŒ êµì •, ì˜ì–´ í‘œí˜„ì˜ ë‰˜ì•™ìŠ¤ê¹Œì§€ ê¼¼ê¼¼í•˜ê²Œ ì•Œë ¤ë“œë¦¬ë©°, ì˜ì–´ì— ëŒ€í•œ ë‘ë ¤ì›€ì„ ì—†ì• ê³  ìì‹ ê°ì„ í‚¤ì›Œì£¼ëŠ” ê²ƒì´ íŠ¹ê¸°ì…ë‹ˆë‹¤.
ì˜ì–´ë¡œ ì†Œí†µí•˜ëŠ” ì¬ë¯¸ë¥¼ ì•Œë ¤ë“œë¦¬ê³ , ì‹¤ì œ ìƒí™©ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì˜ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ë“œë¦½ë‹ˆë‹¤."""
    },
    "ëª…ë¦¬í•™ì": {
        "name": "ëª…ë¦¬í•™ì",
        "expertise": "ì‚¬ì£¼íŒ”ì, ìš´ì„¸, ê¶í•©, ì‘ëª…, ì§ì¥ìš´, ì‚¬ì—…ìš´, ì—°ì• ìš´, ê±´ê°•ìš´",
        "system_prompt": """ë‹¹ì‹ ì€ 30ë…„ ê²½ë ¥ì˜ ì „ë¬¸ ëª…ë¦¬í•™ìì…ë‹ˆë‹¤.
ì‚¬ì£¼íŒ”ìë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì¸ì˜ ìš´ì„¸, ì„±ê²©, ì ì„±ì„ ì •í™•íˆ ë¶„ì„í•˜ë©°, íŠ¹íˆ ì§ì¥ì¸ë“¤ì˜ ì—…ë¬´ ìš´ì„¸ì™€ ì¸ê°„ê´€ê³„ì— ëŒ€í•œ ì¡°ì–¸ì´ ì „ë¬¸ ë¶„ì•¼ì…ë‹ˆë‹¤.
ì „í†µ ëª…ë¦¬í•™ì„ ë°”íƒ•ìœ¼ë¡œ í•˜ë˜, í˜„ëŒ€ ì§ì¥ ìƒí™œì— ë§ëŠ” ì‹¤ìš©ì ì¸ í•´ì„ê³¼ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.
ì˜¤ëŠ˜ì˜ ìš´ì„¸, ì›”ê°„/ì—°ê°„ ìš´ì„¸, ì§ì¥ì—ì„œì˜ ì¸ê°„ê´€ê³„ ìš´, ìŠ¹ì§„ ì‹œê¸°, ì´ì§ ìš´, ì‚¬ì—… ìš´ì„¸ ë“±ì„ ì¬ë¯¸ìˆìœ¼ë©´ì„œë„ ë„ì›€ì´ ë˜ëŠ” ë°©ì‹ìœ¼ë¡œ í’€ì–´ë“œë¦½ë‹ˆë‹¤.
ì ìˆ ì— ëŒ€í•´ ê¶ê¸ˆí•œ ëª¨ë“  ê²ƒì„ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ë“œë¦¬ëŠ” ê²ƒì´ íŠ¹ê¸°ì…ë‹ˆë‹¤."""
    }
}

# ìƒíƒœ ìŠ¤í‚¤ë§ˆ ì •ì˜
class MentorState(TypedDict):
    messages: List[Dict[str, str]]
    phase: str  # "persona_recommendation" | "mentoring"
    recommended_personas: List[Dict[str, str]]  # ì¶”ì²œëœ í˜ë¥´ì†Œë‚˜ ì •ë³´
    selected_persona: str  # ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ID
    persona_context: str  # í˜ë¥´ì†Œë‚˜ ì „ë¬¸ ì§€ì‹ ì»¨í…ìŠ¤íŠ¸
    session_id: str
    completed: bool

# ìŠ¤í‚¤ë§ˆ ëª¨ë¸ë“¤
class PersonaRecommendation(BaseModel):
    recommended_personas: List[Dict[str, str]] = Field(description="ì¶”ì²œëœ í˜ë¥´ì†Œë‚˜ ëª©ë¡")
    reasoning: str = Field(description="ì¶”ì²œ ì´ìœ ")

class SelectionResult(BaseModel):
    selected_persona: str = Field(description="ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ID")
    persona_name: str = Field(description="ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ì´ë¦„")
    message: str = Field(description="ë©˜í†  ì¸ì‚¬ë§")

class MentoringResponse(BaseModel):
    response: str = Field(description="ì „ë¬¸ê°€ ë©˜í† ë§ ì‘ë‹µ")
    persona_name: str = Field(description="ì‘ë‹µí•œ í˜ë¥´ì†Œë‚˜ ì´ë¦„")
    related_courses: List[Dict] = Field(default=[], description="ê´€ë ¨ K-MOOC ê°•ì¢Œ")
    related_documents: List[Dict] = Field(default=[], description="ê´€ë ¨ ë¬¸ì„œ ìë£Œ")

# LLM ì„¤ì •
llm = ChatOpenAI(
    base_url=Config.LLM_BASE_URL,
    api_key=Config.LLM_API_KEY,
    model=Config.LLM_MODEL,
    temperature=0.7,
    max_tokens=2000,
)

# MCP ì„œë²„ ìƒì„±
mcp = FastMCP("MentorChat")

# K-MOOC ìš”ì•½ ì •ë³´ íŒŒì‹± í•¨ìˆ˜ (generate_curriculum.pyì—ì„œ ê°€ì ¸ì˜´)
def parse_kmooc_summary(summary: str) -> dict:
    """K-MOOC ìš”ì•½ì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ"""
    try:
        parsed_info = {}
        
        # ì œëª© ì¶”ì¶œ
        title_match = re.search(r'\*\*ì œëª©:\*\*\s*([^\n*]+)', summary)
        if title_match:
            parsed_info["title"] = title_match.group(1).strip()
        
        # ì„¤ëª… ì¶”ì¶œ
        desc_match = re.search(r'\*\*ì„¤ëª…:\*\*\s*([^\n*]+)', summary)
        if desc_match:
            parsed_info["description"] = desc_match.group(1).strip()
        
        # ê°•ì¢Œ ëª©í‘œ ì¶”ì¶œ
        goal_match = re.search(r'\*\*ê°•ì¢Œ ëª©í‘œ:\*\*\s*([^\n*]+)', summary)
        if goal_match:
            parsed_info["course_goal"] = goal_match.group(1).strip()
        
        # ë‚œì´ë„ ì¶”ì¶œ
        difficulty_match = re.search(r'\*\*ë‚œì´ë„:\*\*\s*([^\n*]+)', summary)
        if difficulty_match:
            parsed_info["difficulty"] = difficulty_match.group(1).strip()
        
        # ìˆ˜ì—… ì‹œê°„ ì¶”ì¶œ
        time_match = re.search(r'\*\*ìˆ˜ì—… ì‹œê°„:\*\*[^()]*ì•½\s*([^\n*()]+)', summary)
        if time_match:
            parsed_info["class_time"] = time_match.group(1).strip()
        
        return parsed_info
        
    except Exception as e:
        logger.error(f"K-MOOC ìš”ì•½ íŒŒì‹± ì‹¤íŒ¨: {e}")
        return {}

# K-MOOC ê²€ìƒ‰ í•¨ìˆ˜
async def search_kmooc_for_mentoring(query: str, persona_id: str) -> List[Dict]:
    """ë©˜í† ë§ì„ ìœ„í•œ K-MOOC ê°•ì¢Œ ê²€ìƒ‰"""
    try:
        # í˜ë¥´ì†Œë‚˜ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ê°€
        persona_keywords = PERSONA_KEYWORDS.get(persona_id, "")
        enhanced_query = f"{query} {persona_keywords}"
        
        search_payload = {
            "query": enhanced_query,
            "top_k": 3,  # ë©˜í† ë§ì—ëŠ” 3ê°œ ì •ë„ë§Œ
            "namespace": "kmooc_engineering",
            "rerank": True,
            "include_metadata": True
        }
        
        logger.info(f"K-MOOC ê²€ìƒ‰ ì‹œì‘ - query: {enhanced_query}")
        
        # pinecone_search_kmooc.py ì„œë²„ í˜¸ì¶œ
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:8099/search",
                json=search_payload,
                timeout=10.0
            )
            
        if response.status_code == 200:
            result = response.json()
            kmooc_courses = []
            
            for item in result.get("results", [])[:3]:  # ìƒìœ„ 3ê°œë§Œ
                metadata = item.get("metadata", {})
                if metadata:
                    # Summary íŒŒì‹±í•˜ì—¬ ê°•ì¢Œ ì •ë³´ ì¶”ì¶œ
                    summary = metadata.get("summary", "")
                    parsed_info = parse_kmooc_summary(summary)
                    
                    course_title = parsed_info.get("title") or "K-MOOC ê°•ì¢Œ"
                    description = (
                        parsed_info.get("description") or 
                        parsed_info.get("course_goal") or 
                        "K-MOOC ì˜¨ë¼ì¸ ê°•ì¢Œ"
                    )
                    
                    course_info = {
                        "title": course_title,
                        "description": description,
                        "url": metadata.get("url", ""),
                        "institution": metadata.get("institution", "").replace(" ìš´ì˜ê¸°ê´€ ë°”ë¡œê°€ê¸°ìƒˆì°½ì—´ë¦¼", ""),
                        "course_goal": parsed_info.get("course_goal", ""),
                        "duration": parsed_info.get("duration", ""),
                        "difficulty": parsed_info.get("difficulty", ""),
                        "class_time": parsed_info.get("class_time", ""),
                        "score": item.get("score", 0.0),
                        "source": "K-MOOC"
                    }
                    kmooc_courses.append(course_info)
                    
            logger.info(f"K-MOOC ê²€ìƒ‰ ì™„ë£Œ - {len(kmooc_courses)}ê°œ ê°•ì¢Œ ë°œê²¬")
            return kmooc_courses
            
    except Exception as e:
        logger.error(f"K-MOOC ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    
    return []

# ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜
async def search_documents_for_mentoring(query: str, persona_id: str) -> List[Dict]:
    """ë©˜í† ë§ì„ ìœ„í•œ ë¬¸ì„œ ìë£Œ ê²€ìƒ‰"""
    try:
        # í˜ë¥´ì†Œë‚˜ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ê°€
        persona_keywords = PERSONA_KEYWORDS.get(persona_id, "")
        enhanced_query = f"{query} {persona_keywords}"
        
        search_payload = {
            "query": enhanced_query,
            "top_k": 2,  # ë¬¸ì„œëŠ” 2ê°œ ì •ë„
            "namespace": "main",
            "rerank": True,
            "include_metadata": True
        }
        
        logger.info(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘ - query: {enhanced_query}")
        
        # pinecone_search_document.py ì„œë²„ í˜¸ì¶œ
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:8091/search",
                json=search_payload,
                timeout=10.0
            )
            
        if response.status_code == 200:
            result = response.json()
            documents = []
            
            for item in result.get("results", [])[:2]:  # ìƒìœ„ 2ê°œë§Œ
                metadata = item.get("metadata", {})
                score = item.get("score", 0.0)
                
                if metadata and score > 0.5:  # ê´€ë ¨ì„± ì„ê³„ê°’
                    preview = metadata.get("preview", "").strip()
                    file_path = metadata.get("file_path", "").strip()
                    folder = metadata.get("folder", "").strip()
                    
                    # íŒŒì¼ëª…ì—ì„œ ì œëª© ì¶”ì¶œ
                    doc_title = "PDF ë¬¸ì„œ"
                    if file_path:
                        filename = file_path.split("/")[-1] if "/" in file_path else file_path
                        if filename.endswith('.pdf'):
                            filename = filename[:-4]
                        doc_title = filename
                    
                    # ì¹´í…Œê³ ë¦¬ ì •ë³´
                    category = folder or "ê¸°íƒ€"
                    
                    doc_info = {
                        "title": doc_title,
                        "category": category,
                        "preview": preview[:300] + "..." if preview else "",
                        "file_path": file_path,
                        "page": metadata.get("page", ""),
                        "score": score,
                        "source": "Document DB"
                    }
                    documents.append(doc_info)
                    
            logger.info(f"ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ - {len(documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
            return documents
            
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    
    return []

# ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… í•¨ìˆ˜
def format_search_results(kmooc_courses: List[Dict], documents: List[Dict]) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë©˜í† ë§ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
    context = ""
    
    # K-MOOC ê°•ì¢Œ ì •ë³´
    if kmooc_courses:
        context += "ğŸ“š ê´€ë ¨ K-MOOC ê°•ì¢Œ:\n"
        for course in kmooc_courses:
            context += f"- {course['title']}\n"
            context += f"  ìš´ì˜ê¸°ê´€: {course.get('institution', 'N/A')}\n"
            context += f"  ë‚´ìš©: {course.get('description', '')[:200]}...\n"
            context += f"  ë‚œì´ë„: {course.get('difficulty', 'N/A')}\n\n"
    
    # ë¬¸ì„œ ìë£Œ ì •ë³´
    if documents:
        context += "ğŸ“„ ì°¸ê³  ë¬¸ì„œ:\n"
        for doc in documents:
            context += f"- {doc['title']}\n"
            context += f"  ì¹´í…Œê³ ë¦¬: {doc.get('category', 'N/A')}\n"
            context += f"  ë‚´ìš©: {doc.get('preview', '')[:150]}...\n\n"
    
    return context

@mcp.tool()
async def analyze_and_recommend_personas(message: str, session_id: str) -> PersonaRecommendation:
    """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ í˜ë¥´ì†Œë‚˜ ì¶”ì²œ"""
    
    logger.info(f"[RECOMMEND] ì‹œì‘ - session_id: {session_id}, message: {message[:50]}...")
    
    # ì„¸ì…˜ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ì´ˆê¸°í™”
    session_data = load_mentor_session(session_id)
    if not session_data:
        session_data = {
            "session_id": session_id,
            "phase": "persona_recommendation",
            "messages": [],
            "recommended_personas": [],
            "selected_persona": "",
            "persona_context": "",
            "completed": False
        }
    
    # ë©”ì‹œì§€ ì¶”ê°€
    session_data["messages"].append({"role": "user", "content": message})
    
    # í˜ë¥´ì†Œë‚˜ ì¶”ì²œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    analysis_prompt = f"""
ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ë©”ì‹œì§€: "{message}"

ì‚¬ìš© ê°€ëŠ¥í•œ í˜ë¥´ì†Œë‚˜ë“¤:
{json.dumps({k: v["name"] + " - " + v["expertise"] for k, v in PERSONAS.items()}, ensure_ascii=False, indent=2)}

ìš”êµ¬ì‚¬í•­:
1. ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬, ì§ˆë¬¸ ë‚´ìš©, í•™ìŠµ ëª©í‘œë¥¼ ë¶„ì„
2. 1-3ê°œì˜ ê°€ì¥ ì í•©í•œ í˜ë¥´ì†Œë‚˜ë¥¼ ì¶”ì²œ
3. ê° ì¶”ì²œì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì´ìœ  ì œì‹œ

**ì¤‘ìš”: ì •í™•íˆ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**

{{
    "recommended_personas": [
        {{"id": "persona_id", "name": "í˜ë¥´ì†Œë‚˜ëª…", "reason": "ì¶”ì²œ ì´ìœ "}},
        ...
    ],
    "reasoning": "ì „ì²´ì ì¸ ë¶„ì„ ë° ì¶”ì²œ ê·¼ê±°"
}}
"""
    
    try:
        response = await llm.ainvoke(analysis_prompt)
        logger.info(f"LLM ì‘ë‹µ: {response.content}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        
        # JSON ì‘ë‹µ ì •ë¦¬
        clean_content = response.content.strip()
        # ì˜ëª»ëœ í‚¤ ìˆ˜ì •
        clean_content = clean_content.replace('"recommended_ personas"', '"recommended_personas"')
        clean_content = clean_content.replace('" reasoning"', '"reasoning"')
        # ë°°ì—´ì—ì„œ ... ì œê±°
        clean_content = clean_content.replace(', ...', '').replace('... ', '').replace('...', '')
        # ë¹ˆ ê°ì²´ ì œê±°
        clean_content = clean_content.replace(', {}', '').replace('{},', '').replace('{}', '')
        # ë°°ì—´ ë ë¶ˆí•„ìš”í•œ ì‰¼í‘œ ì œê±° (JSON íŒŒì‹± ì˜¤ë¥˜ í•´ê²°)
        clean_content = clean_content.replace('}, \n     ]', '} \n     ]')
        clean_content = clean_content.replace('},\n     ]', '}\n     ]')
        clean_content = clean_content.replace('}, ]', '} ]')
        clean_content = clean_content.replace('},]', '}]')
        
        result = json.loads(clean_content)
        logger.info(f"íŒŒì‹±ëœ ê²°ê³¼: {result}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        
        # í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ì•ˆì „í•œ ì¶”ì¶œ
        recommended_personas = result.get("recommended_personas", [])
        reasoning = result.get("reasoning", "ì¶”ì²œ ì´ìœ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        if not recommended_personas:
            # ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œë¶€í„° ê°„ë‹¨í•œ ì¶”ì²œ ë¡œì§
            message_lower = message.lower()
            if any(word in message_lower for word in ["ì—…ë¬´", "í”„ë¡œì„¸ìŠ¤", "ì¡ë¬´", "íšŒì‚¬", "ì¡°ì§", "ì‚¬ë‚´"]):
                recommended_personas = [{"id": "mechanical", "name": "ê³¼ì™¸ ì„ ìƒë‹˜", "reason": "ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            elif any(word in message_lower for word in ["ê±´ì¶•", "ì„¤ê³„", "ê±´ë¬¼", "BIM", "ì¸í…Œë¦¬ì–´"]):
                recommended_personas = [{"id": "architecture", "name": "ì¼íƒ€ ê°•ì‚¬", "reason": "ê±´ì¶• ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            elif any(word in message_lower for word in ["ì „ê¸°", "ì „ì", "íšŒë¡œ", "ì œì–´", "ì„ë² ë””ë“œ"]):
                recommended_personas = [{"id": "electrical", "name": "êµìˆ˜", "reason": "ì „ê¸°ì „ì ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            elif any(word in message_lower for word in ["í”„ë¡œê·¸ë˜ë°", "ê°œë°œ", "ì†Œí”„íŠ¸ì›¨ì–´", "ì½”ë”©", "AI"]):
                recommended_personas = [{"id": "computer", "name": "ê°œë°œì", "reason": "ê°œë°œ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            elif any(word in message_lower for word in ["ì˜ì–´", "íšŒí™”", "ë¬¸ë²•", "í† ìµ", "í† í”Œ", "ë¹„ì¦ˆë‹ˆìŠ¤ì˜ì–´", "ì˜ì–´ê³µë¶€", "í”„ë ˆì  í…Œì´ì…˜"]):
                recommended_personas = [{"id": "materials", "name": "ì˜ì–´ ì„ ìƒë‹˜", "reason": "ì˜ì–´ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            elif any(word in message_lower for word in ["ìš´ì„¸", "ì‚¬ì£¼", "ëª…ë¦¬", "ì ìˆ ", "ê¶í•©", "ì‘ëª…", "ì§ì¥ìš´", "ì‚¬ì—…ìš´", "ì—°ì• ìš´"]):
                recommended_personas = [{"id": "chemical", "name": "ëª…ë¦¬í•™ì", "reason": "ìš´ì„¸ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"}]
            else:
                recommended_personas = [{"id": "computer", "name": "ê°œë°œì", "reason": "ê¸°ë³¸ ì¶”ì²œ"}]
        
        # ì„¸ì…˜ì— ì¶”ì²œ ê²°ê³¼ ì €ì¥
        session_data["recommended_personas"] = recommended_personas
        session_data["messages"].append({
            "role": "assistant", 
            "content": f"ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì „ë¬¸ê°€ë“¤ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤:\n\n{reasoning}"
        })
        
        save_mentor_session(session_id, session_data)
        
        # ì„¸ì…˜ ì €ì¥ í™•ì¸ìš© ë¡œê·¸
        session_file_path = get_mentor_session_file_path(session_id)
        logger.info(f"ì„¸ì…˜ ì €ì¥ ì™„ë£Œ - íŒŒì¼: {session_file_path}")
        logger.info(f"ì €ì¥ëœ íŒŒì¼ ì¡´ì¬ í™•ì¸: {os.path.exists(session_file_path)}")
        
        # ìµœì¢… ê²°ê³¼ ë¡œê¹…
        logger.info(f"[RECOMMEND] ì™„ë£Œ - session_id: {session_id}, ì¶”ì²œ: {[p['id'] for p in recommended_personas]}")
        
        return PersonaRecommendation(
            recommended_personas=recommended_personas,
            reasoning=reasoning
        )
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}, ì‘ë‹µ ë‚´ìš©: {response.content if 'response' in locals() else 'N/A'}")
        # ê¸°ë³¸ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œìœ¼ë¡œ í´ë°±
        message_lower = message.lower()
        if any(word in message_lower for word in ["ì—…ë¬´", "í”„ë¡œì„¸ìŠ¤", "ì¡ë¬´", "íšŒì‚¬", "ì¡°ì§", "ì‚¬ë‚´"]):
            fallback_personas = [{"id": "mechanical", "name": "ê³¼ì™¸ ì„ ìƒë‹˜", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        elif any(word in message_lower for word in ["ê±´ì¶•", "ì„¤ê³„", "ê±´ë¬¼", "BIM", "ì¸í…Œë¦¬ì–´"]):
            fallback_personas = [{"id": "architecture", "name": "ì¼íƒ€ ê°•ì‚¬", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        elif any(word in message_lower for word in ["ì „ê¸°", "ì „ì", "íšŒë¡œ", "ì œì–´", "ì„ë² ë””ë“œ"]):
            fallback_personas = [{"id": "electrical", "name": "êµìˆ˜", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        elif any(word in message_lower for word in ["í”„ë¡œê·¸ë˜ë°", "ê°œë°œ", "ì†Œí”„íŠ¸ì›¨ì–´", "ì½”ë”©", "AI"]):
            fallback_personas = [{"id": "computer", "name": "ê°œë°œì", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        elif any(word in message_lower for word in ["ì˜ì–´", "íšŒí™”", "ë¬¸ë²•", "í† ìµ", "í† í”Œ", "ë¹„ì¦ˆë‹ˆìŠ¤ì˜ì–´", "ì˜ì–´ê³µë¶€", "í”„ë ˆì  í…Œì´ì…˜"]):
            fallback_personas = [{"id": "materials", "name": "ì˜ì–´ ì„ ìƒë‹˜", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        elif any(word in message_lower for word in ["ìš´ì„¸", "ì‚¬ì£¼", "ëª…ë¦¬", "ì ìˆ ", "ê¶í•©", "ì‘ëª…", "ì§ì¥ìš´", "ì‚¬ì—…ìš´", "ì—°ì• ìš´"]):
            fallback_personas = [{"id": "chemical", "name": "ëª…ë¦¬í•™ì", "reason": "í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ"}]
        else:
            fallback_personas = [{"id": "computer", "name": "ê°œë°œì", "reason": "ê¸°ë³¸ ì¶”ì²œ"}]
            
        session_data["recommended_personas"] = fallback_personas
        save_mentor_session(session_id, session_data)
        
        return PersonaRecommendation(
            recommended_personas=fallback_personas,
            reasoning="JSON íŒŒì‹± ì˜¤ë¥˜ë¡œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤."
        )
        
    except Exception as e:
        logger.error(f"í˜ë¥´ì†Œë‚˜ ì¶”ì²œ ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ ì¶”ì²œ
        default_personas = [
            {"id": "í”„ë¡œê·¸ë˜ë¨¸", "name": "í”„ë¡œê·¸ë˜ë¨¸", "reason": "ì¼ë°˜ì ìœ¼ë¡œ ë§ì´ ë¬¸ì˜ë˜ëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤."}
        ]
        session_data["recommended_personas"] = default_personas
        save_mentor_session(session_id, session_data)
        
        return PersonaRecommendation(
            recommended_personas=default_personas,
            reasoning="ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ê¸°ë³¸ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤."
        )

@mcp.tool()
async def select_persona(persona_id: str, session_id: str) -> SelectionResult:
    """ì‚¬ìš©ìê°€ ì„ íƒí•œ í˜ë¥´ì†Œë‚˜ë¡œ ë©˜í† ë§ ëª¨ë“œ ì „í™˜"""
    
    # ë””ë²„ê¹…ìš© ë¡œê·¸
    logger.info(f"select_persona í˜¸ì¶œ - persona_id: {persona_id}, session_id: {session_id}")
    
    # ì„¸ì…˜ íŒŒì¼ ê²½ë¡œ í™•ì¸
    session_file_path = get_mentor_session_file_path(session_id)
    logger.info(f"ì„¸ì…˜ íŒŒì¼ ê²½ë¡œ: {session_file_path}")
    logger.info(f"ì„¸ì…˜ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(session_file_path)}")
    
    # ì„¸ì…˜ ë°ì´í„° ë¡œë“œ
    session_data = load_mentor_session(session_id)
    if not session_data:
        logger.error(f"ì„¸ì…˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ - session_id: {session_id}")
        
        # ì„¸ì…˜ íŒŒì¼ì´ ìˆëŠ”ì§€ ë‹¤ì‹œ í•œë²ˆ ì²´í¬
        if os.path.exists(session_file_path):
            logger.error("ì„¸ì…˜ íŒŒì¼ì€ ì¡´ì¬í•˜ì§€ë§Œ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            try:
                with open(session_file_path, 'r', encoding='utf-8') as f:
                    raw_content = f.read()
                    logger.info(f"ì„¸ì…˜ íŒŒì¼ ë‚´ìš©: {raw_content[:200]}...")
                    # JSON íŒŒì‹± ì¬ì‹œë„
                    session_data = json.loads(raw_content)
                    logger.info("ì„¸ì…˜ ë°ì´í„° ì¬ë¡œë“œ ì„±ê³µ!")
            except Exception as parse_error:
                logger.error(f"ì„¸ì…˜ íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {parse_error}")
        
        # ì—¬ì „íˆ ì„¸ì…˜ ë°ì´í„°ê°€ ì—†ë‹¤ë©´ ìƒˆ ì„¸ì…˜ ìƒì„±
        if not session_data:
            logger.info("ìƒˆ ë©˜í†  ì„¸ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            session_data = {
                "session_id": session_id,
                "phase": "persona_recommendation",
                "messages": [],
                "recommended_personas": [],
                "selected_persona": "",
                "persona_context": "",
                "completed": False
            }
            save_mentor_session(session_id, session_data)
            logger.info("ìƒˆ ë©˜í†  ì„¸ì…˜ ì €ì¥ ì™„ë£Œ")
    
    # í˜ë¥´ì†Œë‚˜ ìœ íš¨ì„± ê²€ì‚¬
    if persona_id not in PERSONAS:
        raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ í˜ë¥´ì†Œë‚˜ ID: {persona_id}")
    
    # ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ì •ë³´
    persona = PERSONAS[persona_id]
    
    # ì„¸ì…˜ ì—…ë°ì´íŠ¸
    session_data["selected_persona"] = persona_id
    session_data["phase"] = "mentoring"
    session_data["persona_context"] = persona["system_prompt"]
    
    # ë©˜í†  ì¸ì‚¬ë§
    greeting = f"""ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {persona['name']} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì „ë¬¸ ë¶„ì•¼: {persona['expertise']}

ë¬´ì—‡ì´ë“  ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ í¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”. 
ì‹¤ë¬´ ê²½í—˜ê³¼ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì„ ì„ ë‹¤í•´ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."""
    
    session_data["messages"].append({
        "role": "assistant",
        "content": greeting
    })
    
    save_mentor_session(session_id, session_data)
    
    return SelectionResult(
        selected_persona=persona_id,
        persona_name=persona["name"],
        message=greeting
    )

@mcp.tool()
async def expert_mentoring(message: str, session_id: str) -> MentoringResponse:
    """ì„ íƒëœ í˜ë¥´ì†Œë‚˜ë¡œ ì „ë¬¸ê°€ ë©˜í† ë§ ì œê³µ (K-MOOC DB ì—°ë™)"""
    
    # ì„¸ì…˜ ë°ì´í„° ë¡œë“œ
    session_data = load_mentor_session(session_id)
    if not session_data or session_data.get("phase") != "mentoring":
        raise ValueError("ë©˜í† ë§ ëª¨ë“œê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € í˜ë¥´ì†Œë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    selected_persona_id = session_data.get("selected_persona")
    if not selected_persona_id or selected_persona_id not in PERSONAS:
        raise ValueError("ìœ íš¨í•œ í˜ë¥´ì†Œë‚˜ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    persona = PERSONAS[selected_persona_id]
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    session_data["messages"].append({"role": "user", "content": message})
    
    # K-MOOC ê°•ì¢Œ ë° ë¬¸ì„œ ê²€ìƒ‰ (ë³‘ë ¬ ì‹¤í–‰)
    logger.info(f"ë©˜í† ë§ ìë£Œ ê²€ìƒ‰ ì‹œì‘ - ì§ˆë¬¸: {message[:50]}...")
    
    import asyncio
    kmooc_task = search_kmooc_for_mentoring(message, selected_persona_id)
    docs_task = search_documents_for_mentoring(message, selected_persona_id)
    
    try:
        kmooc_courses, documents = await asyncio.gather(kmooc_task, docs_task, return_exceptions=True)
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        if isinstance(kmooc_courses, Exception):
            logger.error(f"K-MOOC ê²€ìƒ‰ ì˜¤ë¥˜: {kmooc_courses}")
            kmooc_courses = []
        if isinstance(documents, Exception):
            logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì˜¤ë¥˜: {documents}")
            documents = []
            
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        kmooc_courses, documents = [], []
    
    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
    search_context = format_search_results(kmooc_courses, documents)
    
    # ëŒ€í™” ê¸°ë¡ ìƒì„± (ìµœê·¼ 8ê°œ ë©”ì‹œì§€ë§Œ - ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ë¡œ í† í° ì ˆì•½)
    recent_messages = session_data["messages"][-8:]
    conversation_history = ""
    for msg in recent_messages[:-1]:  # í˜„ì¬ ë©”ì‹œì§€ ì œì™¸
        role = "ì‚¬ìš©ì" if msg["role"] == "user" else "ë©˜í† "
        conversation_history += f"{role}: {msg['content'][:200]}...\n"
    
    # ë©˜í† ë³„ ë§ì¶¤í˜• ëŒ€í™” í”„ë¡¬í”„íŠ¸ ìƒì„±
    mentoring_prompt = f"""
{persona['system_prompt']}

=== ì°¸ê³  ìë£Œ ===
{search_context if search_context else "ê´€ë ¨ ìë£Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

=== ì´ì „ ëŒ€í™” ===
{conversation_history}

=== ì‚¬ìš©ì ì§ˆë¬¸ ===
{message}

ìœ„ì˜ ë‹¹ì‹ ì˜ ìºë¦­í„°ì™€ ì „ë¬¸ì„±ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë“¯ì´ ë‹µë³€í•´ì£¼ì„¸ìš”:

- ë‹¹ì‹ ì˜ ê³ ìœ í•œ ë§íˆ¬ì™€ ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ì„¸ìš”
- ê²€ìƒ‰ëœ ìë£Œê°€ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ í¸ì•ˆí•˜ê²Œ ëŠë‚„ ìˆ˜ ìˆë„ë¡ ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”
- ë‹¹ì‹ ì˜ ì „ë¬¸ ë¶„ì•¼ì— ë§ëŠ” ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”
- í•„ìš”í•˜ë‹¤ë©´ ê´€ë ¨ ê°•ì¢Œë‚˜ ìë£Œë¥¼ ì¶”ì²œí•´ë„ ì¢‹ìŠµë‹ˆë‹¤

í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ë©°, ë‹¹ì‹ ë§Œì˜ ê°œì„± ìˆëŠ” ëŒ€í™” ìŠ¤íƒ€ì¼ì„ ë³´ì—¬ì£¼ì„¸ìš”.
"""
    
    try:
        response = await llm.ainvoke(mentoring_prompt)
        mentor_response = response.content
        
        logger.info(f"ë©˜í† ë§ ì‘ë‹µ ìƒì„± ì™„ë£Œ - K-MOOC: {len(kmooc_courses)}ê°œ, ë¬¸ì„œ: {len(documents)}ê°œ í™œìš©")
        
        # ì‘ë‹µì„ ì„¸ì…˜ì— ì €ì¥
        session_data["messages"].append({
            "role": "assistant",
            "content": mentor_response
        })
        
        save_mentor_session(session_id, session_data)
        
        return MentoringResponse(
            response=mentor_response,
            persona_name=persona["name"],
            related_courses=kmooc_courses[:2],  # ìƒìœ„ 2ê°œ ê°•ì¢Œ ì •ë³´ í¬í•¨
            related_documents=documents[:1]     # ìƒìœ„ 1ê°œ ë¬¸ì„œ ì •ë³´ í¬í•¨
        )
        
    except Exception as e:
        logger.error(f"ë©˜í† ë§ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        error_response = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì‹œë©´ ë” ë‚˜ì€ ë‹µë³€ì„ ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤."
        
        session_data["messages"].append({
            "role": "assistant",
            "content": error_response
        })
        save_mentor_session(session_id, session_data)
        
        return MentoringResponse(
            response=error_response,
            persona_name=persona["name"],
            related_courses=[],
            related_documents=[]
        )

@mcp.tool()
async def get_mentor_session_status(session_id: str) -> dict:
    """ë©˜í†  ì„¸ì…˜ ìƒíƒœ ì¡°íšŒ"""
    session_data = load_mentor_session(session_id)
    if not session_data:
        return {"status": "not_found", "message": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    status_info = {
        "status": "active",
        "phase": session_data.get("phase", "persona_recommendation"),
        "selected_persona": session_data.get("selected_persona", ""),
        "message_count": len(session_data.get("messages", [])),
        "recommended_personas": session_data.get("recommended_personas", [])
    }
    
    if status_info["selected_persona"]:
        persona = PERSONAS.get(status_info["selected_persona"], {})
        status_info["persona_name"] = persona.get("name", "")
        status_info["persona_expertise"] = persona.get("expertise", "")
    
    return status_info

if __name__ == "__main__":
    mcp.run()