{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd4bb5-b121-4873-925d-2ce20942bb4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MCP tools count: 1\n",
      "Tools: ['get_weather']\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36magent\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mtools\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "It's always Sunny in ÏÑúÏö∏\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36magent\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Ïò§Îäò ÏÑúÏö∏ÏùÄ Ìï≠ÏÉÅ ÌôîÏ∞ΩÌïòÎÑ§Ïöî! ÎßëÏùÄ ÌïòÎäòÏùÑ Î≥º Ïàò ÏûàÏùÑ Í≤É Í∞ôÏïÑÏöî. ÎÇ†Ïî®Í∞Ä Ï¢ãÏúºÎãà Í∏∞Î∂ÑÎèÑ ÏÉÅÏæåÌïòÏã§ Í±∞ÏòàÏöî."
     ]
    }
   ],
   "source": [
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils import astream_graph\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\",\n",
    "    model=\"midm-2.0-base-q8\",\n",
    "    temperature=0.1,  # 0.0ÏóêÏÑú 0.1Î°ú Î≥ÄÍ≤Ω\n",
    "    max_tokens=8192,\n",
    ")\n",
    "\n",
    "\n",
    "# StdIO ÏÑúÎ≤Ñ ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "# - command: Python Ïù∏ÌÑ∞ÌîÑÎ¶¨ÌÑ∞ Í≤ΩÎ°ú\n",
    "# - args: Ïã§ÌñâÌï† MCP ÏÑúÎ≤Ñ Ïä§ÌÅ¨Î¶ΩÌä∏\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    args=[\"servers/user_assessment.py\"],\n",
    ")\n",
    "\n",
    "# StdIO ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÏÑúÎ≤ÑÏôÄ ÌÜµÏã†\n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    # ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÑ∏ÏÖò ÏÉùÏÑ±\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # Ïó∞Í≤∞ Ï¥àÍ∏∞Ìôî\n",
    "        await session.initialize()\n",
    "\n",
    "        # MCP ÎèÑÍµ¨ Î°úÎìú\n",
    "        tools = await load_mcp_tools(session)\n",
    "        print(f\"Loaded MCP tools count: {len(tools)}\")\n",
    "        print(\"Tools:\", [tool.name for tool in tools])\n",
    "\n",
    "        # ÏóêÏù¥Ï†ÑÌä∏ ÏÉùÏÑ±\n",
    "        agent = create_react_agent(llm, tools)\n",
    "\n",
    "        # ÏóêÏù¥Ï†ÑÌä∏ ÏùëÎãµ Ïä§Ìä∏Î¶¨Î∞ç\n",
    "        # await astream_graph(agent, {\"messages\": [(\"user\", \"dh\")]})\n",
    "        await astream_graph(agent, {\"messages\": \"Ïò§Îäò ÎÇ†Ïî® Ïñ¥Îïå\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6bbae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 tools from servers/user_assessment.py: ['user_profiling']\n",
      "Loaded 1 tools from servers/generate_curriculum.py: ['get_weather']\n",
      "Loaded 1 tools from servers/evaluate_user.py: ['get_weather']\n",
      "Total tools loaded: 3\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36magent\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mtools\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "It's always Sunny in ÏÑúÏö∏\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36magent\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Ïò§Îäò ÏÑúÏö∏ÏùÄ Ìï≠ÏÉÅ ÎßëÏïÑÏöî! ÎÇ†Ïî®Í∞Ä Ï†ïÎßê Ï¢ãÎÑ§Ïöî. ÌòπÏãú Ïò§Îäò ÌäπÎ≥ÑÌûà Í≥ÑÌöçÌïòÍ≥† Í≥ÑÏã† Ïùº ÏûàÏúºÏÑ∏Ïöî?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node': 'agent',\n",
       " 'content': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'midm-2.0-base-q8', 'system_fingerprint': 'fp_ollama'}, id='run--92518610-8f53-4108-a8f7-9f903517ba3d'),\n",
       " 'metadata': {'langgraph_step': 3,\n",
       "  'langgraph_node': 'agent',\n",
       "  'langgraph_triggers': ('branch:to:agent',),\n",
       "  'langgraph_path': ('__pregel_pull', 'agent'),\n",
       "  'langgraph_checkpoint_ns': 'agent:77b190fc-e06b-c14d-b065-7cda89ddf209',\n",
       "  'checkpoint_ns': 'agent:77b190fc-e06b-c14d-b065-7cda89ddf209',\n",
       "  'ls_provider': 'openai',\n",
       "  'ls_model_name': 'midm-2.0-base-q8',\n",
       "  'ls_model_type': 'chat',\n",
       "  'ls_temperature': 0.1,\n",
       "  'ls_max_tokens': 8192}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils import astream_graph\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\",\n",
    "    model=\"midm-2.0-base-q8\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=8192,\n",
    ")\n",
    "\n",
    "# Ïó¨Îü¨ MCP ÏÑúÎ≤Ñ ÎèôÏãú Ïó∞Í≤∞\n",
    "server_scripts = [\n",
    "    \"servers/user_assessment.py\",\n",
    "    \"servers/generate_curriculum.py\",\n",
    "    \"servers/evaluate_user.py\"\n",
    "]\n",
    "\n",
    "sessions = []\n",
    "stdio_clients = []\n",
    "all_tools = []\n",
    "\n",
    "\n",
    "# Í∞Å ÏÑúÎ≤ÑÎ≥ÑÎ°ú Ïó∞Í≤∞\n",
    "for server_script in server_scripts:\n",
    "    server_params = StdioServerParameters(\n",
    "        command=\"python\",\n",
    "        args=[server_script],\n",
    "    )\n",
    "\n",
    "    # StdIO ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉùÏÑ±\n",
    "    stdio_client_instance = stdio_client(server_params)\n",
    "    read, write = await stdio_client_instance.__aenter__()\n",
    "\n",
    "    # ÏÑ∏ÏÖò ÏÉùÏÑ±\n",
    "    session = ClientSession(read, write)\n",
    "    await session.__aenter__()\n",
    "    await session.initialize()\n",
    "\n",
    "    # Ï†ÄÏû• (ÎÇòÏ§ëÏóê Ï†ïÎ¶¨ÌïòÍ∏∞ ÏúÑÌï¥)\n",
    "    stdio_clients.append(stdio_client_instance)\n",
    "    sessions.append(session)\n",
    "\n",
    "    # Ìï¥Îãπ ÏÑúÎ≤ÑÏùò ÎèÑÍµ¨ Î°úÎìú\n",
    "    tools = await load_mcp_tools(session)\n",
    "    all_tools.extend(tools)\n",
    "    print(f\"Loaded {len(tools)} tools from {server_script}: {[t.name for t in tools]}\")\n",
    "\n",
    "print(f\"Total tools loaded: {len(all_tools)}\")\n",
    "\n",
    "# Î™®Îì† ÎèÑÍµ¨Î°ú ÏóêÏù¥Ï†ÑÌä∏ ÏÉùÏÑ±\n",
    "agent = create_react_agent(llm, all_tools)\n",
    "\n",
    "# ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏ÏúºÎ°ú ÌÖåÏä§Ìä∏\n",
    "await astream_graph(agent, {\"messages\": \"Ïò§Îäò ÎÇ†Ïî® Ïñ¥ÎñÑ ?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c4e2218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36magent\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "ÌååÏù¥Ïç¨ÏùÑ Î∞∞Ïö∞Í≥† Ïã∂ÏúºÏãúÍµ∞Ïöî! ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç Ïñ∏Ïñ¥ Ï§ëÏóêÏÑúÎèÑ ÌååÏù¥Ïç¨ÏùÄ Ï¥àÎ≥¥ÏûêÏóêÍ≤å Îß§Ïö∞ Ïù∏Í∏∞ ÏûàÎäî Ïñ∏Ïñ¥ÏòàÏöî. Ïñ¥Îñ§ Î∂ÄÎ∂ÑÏóê ÌäπÌûà Í¥ÄÏã¨Ïù¥ ÏûàÏúºÏã†Í∞ÄÏöî? Ïõπ Í∞úÎ∞ú, Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù, Ïù∏Í≥µÏßÄÎä• Îì± Íµ¨Ï≤¥Ï†ÅÏù∏ Î∂ÑÏïºÍ∞Ä ÏûàÏúºÏãúÎ©¥ ÏïåÎ†§Ï£ºÏÑ∏Ïöî."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node': 'agent',\n",
       " 'content': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'midm-2.0-base-q8', 'system_fingerprint': 'fp_ollama'}, id='run--c52fccf6-2ef1-4204-b859-1f4d6fc933a7'),\n",
       " 'metadata': {'langgraph_step': 1,\n",
       "  'langgraph_node': 'agent',\n",
       "  'langgraph_triggers': ('branch:to:agent',),\n",
       "  'langgraph_path': ('__pregel_pull', 'agent'),\n",
       "  'langgraph_checkpoint_ns': 'agent:05101a74-9377-e1ce-6bb7-f3ffbe6ff03f',\n",
       "  'checkpoint_ns': 'agent:05101a74-9377-e1ce-6bb7-f3ffbe6ff03f',\n",
       "  'ls_provider': 'openai',\n",
       "  'ls_model_name': 'midm-2.0-base-q8',\n",
       "  'ls_model_type': 'chat',\n",
       "  'ls_temperature': 0.1,\n",
       "  'ls_max_tokens': 8192}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"ÎÇòÎäî ÌååÏù¥Ïç¨ Î∞∞Ïö∞Í≥† Ïã∂Ïñ¥\"\n",
    "await astream_graph(agent, {\"messages\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a73edc5-bffe-4413-ae76-e2a35af3a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_tool_call(self):\n",
    "    \"\"\"Ìà¥ ÏßÅÏ†ë Ìò∏Ï∂ú ÌÖåÏä§Ìä∏\"\"\"\n",
    "    tools = await load_mcp_tools(self.session)\n",
    "    for tool in tools:\n",
    "        if tool.name == \"user_profiling\":\n",
    "            result = await tool.ainvoke({\"message\": \"ÌååÏù¥Ïç¨ Î∞∞Ïö∞Í≥† Ïã∂Ïñ¥Ïöî\"})\n",
    "            print(f\"Ìà¥ ÏßÅÏ†ë Ìò∏Ï∂ú Í≤∞Í≥º: {result}\")\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba1577-fde7-4790-8e8b-d9138fd90fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kt_competition/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'mermaid.ink'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41cbcbe-e0d7-4fe4-9218-a76fc23e04c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-05 21:03:57,580 - mcp.server.lowlevel.server - DEBUG - Initializing server 'UserProfiling'\n",
      "2025-09-05 21:03:57,581 - mcp.server.lowlevel.server - DEBUG - Registering handler for ListToolsRequest\n",
      "2025-09-05 21:03:57,582 - mcp.server.lowlevel.server - DEBUG - Registering handler for CallToolRequest\n",
      "2025-09-05 21:03:57,582 - mcp.server.lowlevel.server - DEBUG - Registering handler for ListResourcesRequest\n",
      "2025-09-05 21:03:57,583 - mcp.server.lowlevel.server - DEBUG - Registering handler for ReadResourceRequest\n",
      "2025-09-05 21:03:57,583 - mcp.server.lowlevel.server - DEBUG - Registering handler for PromptListRequest\n",
      "2025-09-05 21:03:57,584 - mcp.server.lowlevel.server - DEBUG - Registering handler for GetPromptRequest\n",
      "2025-09-05 21:03:57,585 - mcp.server.lowlevel.server - DEBUG - Registering handler for ListResourceTemplatesRequest\n",
      "2025-09-05 21:03:57,594 - __main__ - INFO - MCP ÏÑúÎ≤Ñ ÏãúÏûë...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Already running asyncio in this thread",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     33\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mMCP ÏÑúÎ≤Ñ ÏãúÏûë...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[43mmcp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstdio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kt_competition/lib/python3.11/site-packages/mcp/server/fastmcp/server.py:250\u001b[39m, in \u001b[36mFastMCP.run\u001b[39m\u001b[34m(self, transport, mount_path)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mmatch\u001b[39;00m transport:\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstdio\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[43manyio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_stdio_async\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msse\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    252\u001b[39m         anyio.run(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m.run_sse_async(mount_path))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/kt_competition/lib/python3.11/site-packages/anyio/_core/_eventloop.py:59\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(func, backend, backend_options, *args)\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAlready running \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masynclib_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in this thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     async_backend = get_async_backend(backend)\n",
      "\u001b[31mRuntimeError\u001b[39m: Already running asyncio in this thread"
     ]
    }
   ],
   "source": [
    "# user_assessment.pyÏóê Î°úÍ∑∏ Ï∂îÍ∞Ä\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Î°úÍπÖ ÏÑ§Ï†ï\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "mcp = FastMCP(\n",
    "    \"UserProfiling\",  # Ïù¥Î¶Ñ Î≥ÄÍ≤Ω\n",
    "    instructions=\"You are a learning mentor that profiles users for personalized education.\",\n",
    "    host=\"0.0.0.0\",\n",
    "    port=8005,\n",
    ")\n",
    "\n",
    "@mcp.tool()\n",
    "async def user_profiling(message: str) -> str:\n",
    "    logger.info(f\"user_profiling Ìà¥ Ìò∏Ï∂úÎê®! Î©îÏãúÏßÄ: {message}\")\n",
    "    \n",
    "    result = \"ÌååÏù¥Ïç¨ ÌïôÏäµÏóê Í¥ÄÏã¨Ïù¥ ÏûàÏúºÏãúÍµ∞Ïöî! Î™á Í∞ÄÏßÄ ÏßàÎ¨∏ÎìúÎ¶¥Í≤åÏöî.\"\n",
    "    \n",
    "    logger.info(f\"ÏùëÎãµ: {result}\")\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"MCP ÏÑúÎ≤Ñ ÏãúÏûë...\")\n",
    "    mcp.run(transport=\"stdio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c80e6-6e2e-4834-8aa9-d6f648661cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kt_competition",
   "language": "python",
   "name": "kt_competition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
