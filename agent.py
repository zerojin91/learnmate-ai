"""
MCP Agent ëª¨ë“ˆ - agent.ipynbì˜ ë¡œì§ì„ ëª¨ë“ˆí™”
"""

from typing import AsyncGenerator, Optional, List, Dict
import json

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from langchain_mcp_adapters.tools import load_mcp_tools
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from utils import astream_graph, trim_conversation_history, log_token_usage
from config import Config


class MCPAgent:
    """MCP ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ - ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ í¬í•¨"""
    
    def __init__(self, server_script: str = "servers/user_assessment.py"):
        self.server_script = server_script
        self.agent = None
        self.session = None
        self.stdio_client = None
        self.read = None
        self.write = None
        self.initialized = False
        
        # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
        self.conversation_history: List[Dict[str, str]] = []
        
        # LLM ì„¤ì • - Configì—ì„œ ê°€ì ¸ì˜¤ê¸°
        self.llm = ChatOpenAI(
            base_url=Config.LLM_BASE_URL,
            api_key=Config.LLM_API_KEY,
            model=Config.LLM_MODEL,
            temperature=Config.LLM_TEMPERATURE,
            max_tokens=Config.LLM_MAX_TOKENS,
        )
    
    async def initialize(self):
        """MCP ì—ì´ì „íŠ¸ ì´ˆê¸°í™” - ì›ë˜ ì½”ë“œì™€ ë™ì¼í•œ ë°©ì‹"""
        if self.initialized:
            return
            
        try:
            # StdIO ì„œë²„ íŒŒë¼ë¯¸í„° ì„¤ì • (ì›ë˜ ì½”ë“œì™€ ë™ì¼)
            server_params = StdioServerParameters(
                command="python",
                args=[self.server_script],
            )
            
            # StdIO í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë²„ì™€ í†µì‹ 
            self.stdio_client = stdio_client(server_params)
            self.read, self.write = await self.stdio_client.__aenter__()
            
            # í´ë¼ì´ì–¸íŠ¸ ì„¸ì…˜ ìƒì„±
            self.session = ClientSession(self.read, self.write)
            await self.session.__aenter__()
            
            # ì—°ê²° ì´ˆê¸°í™”
            await self.session.initialize()
            
            # MCP ë„êµ¬ ë¡œë“œ
            tools = await load_mcp_tools(self.session)
            print(f"Loaded MCP tools count: {len(tools)}")
            print("Tools:", [tool.name for tool in tools])
            
            # ì—ì´ì „íŠ¸ ìƒì„±
            self.agent = create_react_agent(self.llm, tools)
            self.initialized = True
            print(f"MCP Agent initialized successfully with {self.server_script}!")
            
        except Exception as e:
            print(f"Failed to initialize MCP Agent: {e}")
            raise e
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.session:
                await self.session.__aexit__(None, None, None)
            if self.stdio_client:
                await self.stdio_client.__aexit__(None, None, None)
            self.initialized = False
        except Exception as e:
            print(f"Cleanup error: {e}")

    async def chat_with_astream_graph(self, message: str):
        """utils.pyì˜ astream_graphë¥¼ ì§ì ‘ ì‚¬ìš© (ì›ë˜ ì½”ë“œì™€ ë™ì¼)"""
        if not self.initialized:
            await self.initialize()
        
        try:
            # ì›ë˜ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ astream_graph ì‚¬ìš©
            await astream_graph(self.agent, {"messages": message})
        except Exception as e:
            print(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    async def chat_stream(self, message: str) -> AsyncGenerator[dict, None]:
        """ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì‘ë‹µ - ì›¹ APIìš© (ì´ì „ ë²„ì „ í˜¸í™˜ì„±)"""
        if not self.initialized:
            await self.initialize()
        
        try:
            # ì—ì´ì „íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
            async for chunk in self.agent.astream(
                {"messages": message}, 
                stream_mode="messages"
            ):
                chunk_msg, metadata = chunk
                node = metadata.get("langgraph_node", "unknown")
                
                # ë©”ì‹œì§€ ë‚´ìš© ì¶”ì¶œ ë° ì „ì†¡
                if hasattr(chunk_msg, 'content'):
                    content = self._extract_content(chunk_msg.content)
                    if content:
                        yield {
                            "type": "message",
                            "content": content,
                            "node": node
                        }
                        
        except Exception as e:
            yield {
                "type": "error",
                "content": f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }

    async def chat(self, message: str) -> AsyncGenerator[dict, None]:
        """ë©€í‹°í„´ ëŒ€í™” ì²˜ë¦¬ - í† í° ê´€ë¦¬ í¬í•¨"""
        if not self.initialized:
            await self.initialize()
        
        try:
            # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            self.conversation_history.append({"role": "user", "content": message})
            
            # í† í° ì œí•œì— ë§ê²Œ ëŒ€í™” ê¸°ë¡ ì •ë¦¬
            max_tokens = Config.get_effective_max_tokens()
            self.conversation_history = trim_conversation_history(self.conversation_history, max_tokens)
            
            # í† í° ì‚¬ìš©ëŸ‰ ë¡œê·¸
            log_token_usage(self.conversation_history)
            
            # ëŒ€í™” ê¸°ë¡ì„ LangChain ë©”ì‹œì§€ í˜•íƒœë¡œ ë³€í™˜
            from langchain_core.messages import HumanMessage, AIMessage
            
            messages = []
            for item in self.conversation_history:
                if item["role"] == "user":
                    messages.append(HumanMessage(content=item["content"]))
                elif item["role"] == "assistant":
                    messages.append(AIMessage(content=item["content"]))
            
            # ì—ì´ì „íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
            response_content = ""
            async for chunk in self.agent.astream(
                {"messages": messages}, 
                stream_mode="messages"
            ):
                chunk_msg, metadata = chunk
                node = metadata.get("langgraph_node", "unknown")
                
                # ë©”ì‹œì§€ ë‚´ìš© ì¶”ì¶œ ë° ì „ì†¡
                if hasattr(chunk_msg, 'content'):
                    content = self._extract_content(chunk_msg.content)
                    if content:
                        response_content += content
                        yield {
                            "type": "message",
                            "content": content,
                            "node": node
                        }
            
            # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            if response_content:
                self.conversation_history.append({"role": "assistant", "content": response_content})
                # ì‘ë‹µ ì¶”ê°€ í›„ ë‹¤ì‹œ í† í° ì œí•œ í™•ì¸
                self.conversation_history = trim_conversation_history(self.conversation_history, max_tokens)
                        
        except Exception as e:
            yield {
                "type": "error",
                "content": f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }

    def clear_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.conversation_history = []
        print("ğŸ’¬ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _extract_content(self, content) -> Optional[str]:
        """ë©”ì‹œì§€ ë‚´ìš© ì¶”ì¶œ í—¬í¼ í•¨ìˆ˜"""
        if isinstance(content, str):
            return content
        elif isinstance(content, list):
            for item in content:
                if isinstance(item, dict) and "text" in item:
                    return item["text"]
        return None

    async def switch_server(self, new_server_script: str):
        """ì„œë²„ ë™ì  ì „í™˜ - í•µì‹¬ ê¸°ëŠ¥!"""
        if self.initialized:
            await self.cleanup()
        
        self.server_script = new_server_script
        await self.initialize()
        print(f"Switched to server: {new_server_script}")


# ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë²„ë“¤ ì •ì˜
AVAILABLE_SERVERS = {
    "weather": "servers/user_assessment.py",
    "curriculum": "servers/generate_curriculum.py", 
    "evaluation": "servers/evaluate_user.py"
}

async def create_agent(server_type: str = "weather") -> MCPAgent:
    """ì„œë²„ íƒ€ì…ìœ¼ë¡œ ì—ì´ì „íŠ¸ ìƒì„±"""
    if server_type not in AVAILABLE_SERVERS:
        raise ValueError(f"Unknown server type: {server_type}. Available: {list(AVAILABLE_SERVERS.keys())}")
    
    server_script = AVAILABLE_SERVERS[server_type]
    agent = MCPAgent(server_script)
    await agent.initialize()
    return agent
