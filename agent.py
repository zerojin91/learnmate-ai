"""
MCP Agent ëª¨ë“ˆ - Stateful Multi-Agent Systemê³¼ ì—°ë™
"""

from typing import AsyncGenerator, Optional, List, Dict
import json
import re
from pydantic import BaseModel, Field
from enum import Enum

from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from utils import astream_graph, trim_conversation_history, log_token_usage, apply_chat_template
from config import Config

class ActionType(str, Enum):
    """ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ì•¡ì…˜ ìœ í˜•"""
    GENERAL_CHAT = "general_chat"           # ì¼ë°˜ ëŒ€í™”
    USER_PROFILING = "user_profiling"       # í•™ìŠµ í”„ë¡œí•„ ìˆ˜ì§‘ í•„ìš”
    GENERATE_CURRICULUM = "generate_curriculum"  # ì»¤ë¦¬í˜ëŸ¼ ìƒì„±

class ActionClassification(BaseModel):
    """ì•¡ì…˜ ë¶„ë¥˜ ê²°ê³¼"""
    action: ActionType = Field(description="ìˆ˜í–‰í•  ì•¡ì…˜ íƒ€ì…")
    
class MultiMCPAgent:
    """ì—¬ëŸ¬ MCP ì„œë²„ë¥¼ ë™ì‹œì— ì—°ê²°í•˜ëŠ” ì—ì´ì „íŠ¸ with Stateful Assessment"""
    
    def __init__(self, server_scripts: List[str]):
        self.server_scripts = server_scripts
        self.client = None
        self.agent = None
        self.initialized = False
        
        # ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
        self.current_session_id = None
        
        # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ - ê¸°ë³¸ ì¸ì‚¬ë§ í¬í•¨
        self.conversation_history: List[Dict[str, str]] = [
            {
                "role": "assistant", 
                "content": "ì•ˆë…•í•˜ì„¸ìš”! LearnAI ì…ë‹ˆë‹¤. ì–´ë–¤ ì£¼ì œì— ëŒ€í•´ ë°°ìš°ê³  ì‹¶ìœ¼ì‹ ì§€ ì•Œë ¤ì£¼ì‹œë©´ ë§ì¶¤í˜• í•™ìŠµ ê³„íšì„ í•¨ê»˜ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤!"
            }
        ]
        self.max_tokens = Config.LLM_MAX_TOKENS

        # LLM ì„¤ì •
        self.llm = ChatOpenAI(
            base_url=Config.LLM_BASE_URL,
            api_key=Config.LLM_API_KEY,
            model=Config.LLM_MODEL,
            temperature=Config.LLM_TEMPERATURE,
            max_tokens=self.max_tokens,
            model_kwargs={"max_completion_tokens": None}  # Friendli.aiì—ì„œ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒë¼ë¯¸í„° ì œê±°
        )
         
    async def initialize(self):
        """ì—¬ëŸ¬ MCP ì„œë²„ ë™ì‹œ ì´ˆê¸°í™” - ê³µì‹ ë°©ë²• ì‚¬ìš©"""
        if self.initialized:
            return
            
        try:
            # MCP ì„œë²„ ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            server_configs = {}
            for i, server_script in enumerate(self.server_scripts):
                server_name = f"server_{i}"
                server_configs[server_name] = {
                    "command": "python",
                    "args": [server_script],
                    "transport": "stdio"
                }
            
            print(f"ì„œë²„ ì„¤ì •: {server_configs}")
            
            # MultiServerMCPClient ìƒì„±
            self.client = MultiServerMCPClient(server_configs)
            
            # ëª¨ë“  ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
            tools = await self.client.get_tools()
            print(f"ë¡œë“œëœ ë„êµ¬ë“¤: {[tool.name for tool in tools]}")
            
            # ReAct ì—ì´ì „íŠ¸ ìƒì„±
            self.agent = create_react_agent(self.llm, tools)
            
            self.initialized = True
            print(f"âœ… MultiMCP Agent ì´ˆê¸°í™” ì™„ë£Œ - {len(tools)}ê°œ ë„êµ¬ ë¡œë“œë¨!")
            
        except Exception as e:
            print(f"âŒ MultiMCP Agent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            await self.cleanup()
            raise e
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.client:
                # MultiServerMCPClientëŠ” close ë©”ì„œë“œê°€ ì—†ìœ¼ë¯€ë¡œ ì œê±°
                pass
            self.initialized = False
        except Exception as e:
            print(f"Cleanup error: {e}")
    
    def _extract_session_id(self, response_content: str) -> Optional[str]:
        """ì‘ë‹µì—ì„œ ì„¸ì…˜ ID ì¶”ì¶œ"""
        session_match = re.search(r'Session:\s*([a-zA-Z0-9-]+)', response_content)
        if session_match:
            return session_match.group(1)
        return None
    
    
    async def chat(self, message: str) -> AsyncGenerator[dict, None]:
        """ë©€í‹°í„´ ëŒ€í™” ì²˜ë¦¬ - Stateful Assessment ì§€ì›"""
        if not self.initialized:
            await self.initialize()
        
        try:
            print(f"ğŸ“ ì‚¬ìš©ì ë©”ì‹œì§€: {message}")
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€ (ì›ë³¸ ì €ì¥)
            self.conversation_history.append({"role": "user", "content": message})
            
            # í† í° ì œí•œì— ë§ê²Œ ëŒ€í™” ê¸°ë¡ ì •ë¦¬
            self.conversation_history = trim_conversation_history(self.conversation_history, self.max_tokens)
            
            # í† í° ì‚¬ìš©ëŸ‰ ë¡œê·¸
            log_token_usage(self.conversation_history)
            
            # MCP ë°©ì‹: ReAct ì—ì´ì „íŠ¸ê°€ í•„ìš”í•œ ë„êµ¬ë¥¼ ìë™ìœ¼ë¡œ ì„ íƒ
            async for chunk in self._handle_unified_conversation(message):
                yield chunk
                        
        except Exception as e:
            yield {
                "type": "error",
                "content": f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
    
    
    async def _classify_user_intent(self, message: str) -> ActionClassification:
        """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¶„ë¥˜í•˜ì—¬ ì ì ˆí•œ ì•¡ì…˜ ê²°ì •"""
        classification_prompt = f"""ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë‹¤ìŒ 3ê°€ì§€ ì•¡ì…˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:

1. **general_chat**: ì¼ë°˜ì ì¸ ì¸ì‚¬, ì•ˆë¶€, ê°ì‚¬ ë“± í•™ìŠµê³¼ ë¬´ê´€í•œ ëŒ€í™”
2. **user_profiling**: í•™ìŠµ ê´€ë ¨ ìš”ì²­ì´ì§€ë§Œ ì‚¬ìš©ì í”„ë¡œí•„ì´ í•„ìš”í•œ ê²½ìš°
3. **generate_curriculum**: ì´ë¯¸ í•™ìŠµ í”„ë¡œí•„ì´ ìˆê³  ì»¤ë¦¬í˜ëŸ¼/ê³„íš ìƒì„±ì„ ìš”ì²­í•˜ëŠ” ê²½ìš°

ì‚¬ìš©ì ë©”ì‹œì§€: "{message}"

## ë¶„ë¥˜ ê¸°ì¤€:
- "ì•ˆë…•", "ê³ ë§ˆì›Œ", "ì˜ê°€" ë“± â†’ general_chat
- "~ë°°ìš°ê³  ì‹¶ì–´", "~ê³µë¶€í•˜ê³  ì‹¶ì–´", "~ê°€ë¥´ì³ì¤˜" ë“± â†’ user_profiling  
- "ì»¤ë¦¬í˜ëŸ¼ ë§Œë“¤ì–´ì¤˜", "í•™ìŠµê³„íš ì„¸ì›Œì¤˜", "ë¡œë“œë§µ ë³´ì—¬ì¤˜" ë“± â†’ generate_curriculum

ì •í™•í•œ ì•¡ì…˜ë§Œ ì„ íƒí•˜ì„¸ìš”."""

        try:
            classifier_model = self.llm.with_structured_output(ActionClassification)
            result = classifier_model.invoke(classification_prompt)
            print(f"ğŸ” ì˜ë„ ë¶„ë¥˜ ê²°ê³¼: {result.action}")
            return result
        except Exception as e:
            print(f"âŒ ì˜ë„ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì¼ë°˜ ëŒ€í™” ì„ íƒ
            return ActionClassification(action=ActionType.GENERAL_CHAT)

    async def _handle_user_profiling(self, message: str) -> AsyncGenerator[dict, None]:
        """user_profiling ë„êµ¬ë¥¼ ì‚¬ìš©í•œ í”„ë¡œí•„ ìˆ˜ì§‘"""
        print(f"ğŸ“Š ì‚¬ìš©ì í”„ë¡œí•„ë§ ì‹œì‘")
        
        try:
            # user_profiling ë„êµ¬ ì°¾ê¸°
            tools = await self.client.get_tools()
            user_profiling_tool = next((tool for tool in tools if tool.name == "user_profiling"), None)
            
            if not user_profiling_tool:
                yield {"type": "error", "content": "ì‚¬ìš©ì í”„ë¡œí•„ë§ ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
                return
            
            # ë„êµ¬ ì‹¤í–‰
            tool_args = {"user_message": message, "session_id": self.current_session_id}
            print(f"ğŸ”§ user_profiling í˜¸ì¶œ: {tool_args}")
            
            result = await user_profiling_tool.ainvoke(tool_args)
            
            if result:
                print(result, end="", flush=True)
                self.conversation_history.append({"role": "assistant", "content": result})
                
                # ë„êµ¬ í˜¸ì¶œ í›„ ìµœì‹  í”„ë¡œí•„ ì •ë³´ ë¡œë“œ
                profile_data = None
                try:
                    from servers.user_assessment import load_session
                    if self.current_session_id:
                        session_data = load_session(self.current_session_id)
                        if session_data:
                            profile_info = {
                                'topic': session_data.get('topic', ''),
                                'constraints': session_data.get('constraints', ''),
                                'goal': session_data.get('goal', '')
                            }
                            # ë¹ˆ ê°’ë„ í¬í•¨í•˜ì—¬ ì „ì²´ í”„ë¡œí•„ ì •ë³´ ì „ë‹¬ (UIì—ì„œ ìƒíƒœ í‘œì‹œë¥¼ ìœ„í•´)
                            profile_data = profile_info
                            print(f"ğŸ“Š ìµœì‹  í”„ë¡œí•„ ë¡œë“œ: {profile_data}")
                except Exception as e:
                    print(f"í”„ë¡œí•„ ë¡œë“œ ì˜¤ë¥˜: {e}")
                
                response_data = {"type": "message", "content": result, "node": "user_profiling"}
                if profile_data:
                    response_data["profile"] = profile_data
                    
                yield response_data
                
        except Exception as e:
            print(f"âŒ ì‚¬ìš©ì í”„ë¡œí•„ë§ ì˜¤ë¥˜: {e}")
            yield {"type": "error", "content": f"í”„ë¡œí•„ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    async def _handle_curriculum_generation(self, message: str) -> AsyncGenerator[dict, None]:
        """generate_curriculum_from_session ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ì»¤ë¦¬í˜ëŸ¼ ìƒì„±"""
        print(f"ğŸ“š ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì‹œì‘")
        
        try:
            # generate_curriculum_from_session ë„êµ¬ ì°¾ê¸°
            tools = await self.client.get_tools()
            curriculum_tool = next((tool for tool in tools if tool.name == "generate_curriculum_from_session"), None)
            
            if not curriculum_tool:
                yield {"type": "error", "content": "ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
                return
            
            # ë„êµ¬ ì‹¤í–‰ (ì‚¬ìš©ì ë©”ì‹œì§€ë„ ì „ë‹¬)
            tool_args = {
                "session_id": self.current_session_id,
                "user_message": message
            }
            print(f"ğŸ”§ generate_curriculum_from_session í˜¸ì¶œ: {tool_args}")
            
            result = await curriculum_tool.ainvoke(tool_args)
            
            if result:
                print(result, end="", flush=True)
                self.conversation_history.append({"role": "assistant", "content": result})
                
                # ì»¤ë¦¬í˜ëŸ¼ JSON ë°ì´í„° íŒŒì‹± ì‹œë„
                try:
                    # resultê°€ JSON í˜•íƒœì¸ì§€ í™•ì¸í•˜ê³  íŒŒì‹±
                    if result.strip().startswith('{') and '"title"' in result and '"modules"' in result:
                        import json
                        curriculum_data = json.loads(result)
                        print(f"ğŸ“š ì»¤ë¦¬í˜ëŸ¼ ë°ì´í„° íŒŒì‹± ì„±ê³µ: {curriculum_data.get('title', 'Unknown')}")
                        
                        # curriculum ì†ì„±ìœ¼ë¡œ ì „ë‹¬
                        yield {"type": "message", "content": result, "curriculum": curriculum_data, "node": "generate_curriculum"}
                    else:
                        # ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ
                        yield {"type": "message", "content": result, "node": "generate_curriculum"}
                        
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ ì»¤ë¦¬í˜ëŸ¼ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                    # JSON íŒŒì‹± ì‹¤íŒ¨í•´ë„ ì¼ë°˜ ì‘ë‹µìœ¼ë¡œ ì²˜ë¦¬
                    yield {"type": "message", "content": result, "node": "generate_curriculum"}
                
        except Exception as e:
            print(f"âŒ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì˜¤ë¥˜: {e}")
            yield {"type": "error", "content": f"ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    async def _handle_general_chat(self, message: str) -> AsyncGenerator[dict, None]:
        """ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬ (ë„êµ¬ ì—†ì´)"""
        print(f"ğŸ’¬ ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬")
        
        try:
            # LearnAI ì„±ê²©ì˜ ì¼ë°˜ ëŒ€í™” í”„ë¡¬í”„íŠ¸
            system_prompt = """ë‹¹ì‹ ì€ LearnAIì˜ ì¹œê·¼í•œ í•™ìŠµ ë©˜í† ì…ë‹ˆë‹¤.
            
ë”°ëœ»í•˜ê³  ê²©ë ¤í•˜ëŠ” ì„±ê²©ìœ¼ë¡œ ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”.
ì¼ë°˜ì ì¸ ì¸ì‚¬, ì•ˆë¶€, ê°ì‚¬ ë“±ì— ì¹œê·¼í•˜ê²Œ ì‘ë‹µí•˜ë˜, 
í•­ìƒ í•™ìŠµì— ëŒ€í•œ ê´€ì‹¬ì„ ì—´ì–´ë‘ê³  ë„ì›€ì´ í•„ìš”í•˜ë©´ ì–¸ì œë“  ë§í•´ë‹¬ë¼ê³  ê²©ë ¤í•˜ì„¸ìš”."""

            from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
            
            messages = [SystemMessage(content=system_prompt)]
            
            # ìµœê·¼ ëŒ€í™” ê¸°ë¡ë§Œ í¬í•¨ (í† í° ì ˆì•½)
            for item in self.conversation_history[-4:]:
                if item["role"] == "user":
                    messages.append(HumanMessage(content=item["content"]))
                elif item["role"] == "assistant":
                    messages.append(AIMessage(content=item["content"]))
            
            # LLM ì§ì ‘ í˜¸ì¶œ (ë„êµ¬ ì—†ì´)
            response_content = ""
            async for chunk in self.llm.astream(messages):
                if hasattr(chunk, 'content') and chunk.content:
                    response_content += chunk.content
                    print(chunk.content, end="", flush=True)
                    yield {"type": "message", "content": chunk.content, "node": "general_chat"}
            
            if response_content:
                self.conversation_history.append({"role": "assistant", "content": response_content})
                
        except Exception as e:
            print(f"âŒ ì¼ë°˜ ëŒ€í™” ì˜¤ë¥˜: {e}")
            yield {"type": "error", "content": f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    async def _handle_unified_conversation(self, message: str) -> AsyncGenerator[dict, None]:
        """ë¶„ë¥˜ ê¸°ë°˜ ëŒ€í™” ì²˜ë¦¬ - with_structured_outputìœ¼ë¡œ ëª…í™•í•œ ì•¡ì…˜ ì„ íƒ"""
        print(f"ğŸ¤– ë¶„ë¥˜ ê¸°ë°˜ ëŒ€í™” ì²˜ë¦¬ ì‹œì‘")
        
        try:
            # 1. ì‚¬ìš©ì ì˜ë„ ë¶„ë¥˜
            classification = await self._classify_user_intent(message)
            
            # 2. ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ì²˜ë¦¬
            if classification.action == ActionType.USER_PROFILING:
                async for chunk in self._handle_user_profiling(message):
                    yield chunk
                    
            elif classification.action == ActionType.GENERATE_CURRICULUM:
                async for chunk in self._handle_curriculum_generation(message):
                    yield chunk
                    
            else:  # GENERAL_CHAT
                async for chunk in self._handle_general_chat(message):
                    yield chunk
                
        except Exception as e:
            print(f"âŒ í†µí•© ëŒ€í™” ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            yield {
                "type": "error",
                "content": f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
    
    def clear_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.conversation_history = []
        self.current_session_id = None
        print("ğŸ’¬ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _extract_content(self, content) -> Optional[str]:
        """ë©”ì‹œì§€ ë‚´ìš© ì¶”ì¶œ í—¬í¼ í•¨ìˆ˜"""
        if isinstance(content, str):
            return content
        elif isinstance(content, list):
            for item in content:
                if isinstance(item, dict) and "text" in item:
                    return item["text"]
        return None


# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
MultiAgentSystem = MultiMCPAgent
