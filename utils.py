"""
í†µí•© ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ - í† í° ê´€ë¦¬ + LangGraph ìŠ¤íŠ¸ë¦¬ë°
"""
from typing import Any, Dict, List, Callable, Optional
from langchain_core.messages import BaseMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph.state import CompiledStateGraph
import uuid
from config import Config


# =============================================================================
# í† í° ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°
# =============================================================================

def estimate_tokens(text: str) -> int:
    """
    í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ëŒ€ëµì ìœ¼ë¡œ ì¶”ì •í•©ë‹ˆë‹¤.
    
    Args:
        text (str): í† í° ìˆ˜ë¥¼ ê³„ì‚°í•  í…ìŠ¤íŠ¸
        
    Returns:
        int: ì¶”ì •ëœ í† í° ìˆ˜
    """
    return len(text) // Config.AVERAGE_CHARS_PER_TOKEN


def calculate_conversation_tokens(conversation_history: List[Dict[str, str]]) -> int:
    """
    ëŒ€í™” ê¸°ë¡ì˜ ì´ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        conversation_history: ëŒ€í™” ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        int: ì´ í† í° ìˆ˜
    """
    total_tokens = 0
    for message in conversation_history:
        total_tokens += estimate_tokens(message.get("content", ""))
    return total_tokens


def trim_conversation_history(conversation_history: List[Dict[str, str]], max_tokens: int) -> List[Dict[str, str]]:
    """
    ëŒ€í™” ê¸°ë¡ì„ í† í° ì œí•œì— ë§ê²Œ ì˜ë¼ëƒ…ë‹ˆë‹¤.
    ìµœì‹  ë©”ì‹œì§€ë¶€í„° ìœ ì§€í•˜ë©°, í† í° ì œí•œì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
    ê³¼ê±° ê¸°ë¡ë¶€í„° ìë™ìœ¼ë¡œ ì‚­ì œë©ë‹ˆë‹¤.
    
    Args:
        conversation_history: ì „ì²´ ëŒ€í™” ê¸°ë¡
        max_tokens: ìµœëŒ€ í† í° ìˆ˜
        
    Returns:
        List[Dict[str, str]]: í† í° ì œí•œì— ë§ëŠ” ëŒ€í™” ê¸°ë¡
    """
    if not conversation_history:
        return []
    
    original_count = len(conversation_history)
    
    # ìµœì‹  ë©”ì‹œì§€ë¶€í„° ì—­ìˆœìœ¼ë¡œ í™•ì¸
    trimmed_history = []
    current_tokens = 0
    
    for message in reversed(conversation_history):
        message_tokens = estimate_tokens(message.get("content", ""))
        
        # í† í° ì œí•œì„ ì´ˆê³¼í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
        if current_tokens + message_tokens <= max_tokens:
            trimmed_history.insert(0, message)  # ì•ìª½ì— ì‚½ì…í•˜ì—¬ ìˆœì„œ ìœ ì§€
            current_tokens += message_tokens
        else:
            # í† í° ì œí•œ ì´ˆê³¼ì‹œ ë” ì´ìƒ ì¶”ê°€í•˜ì§€ ì•ŠìŒ (ê³¼ê±° ê¸°ë¡ ì‚­ì œ)
            break
    
    # ëŒ€í™” ê¸°ë¡ì´ ì˜ë ¸ëŠ”ì§€ ë¡œê·¸ ì¶œë ¥
    if len(trimmed_history) < original_count:
        deleted_count = original_count - len(trimmed_history)
        print(f"ğŸ—‘ï¸  ëŒ€í™” ê¸°ë¡ ì •ë¦¬: {deleted_count}ê°œ ê³¼ê±° ë©”ì‹œì§€ ì‚­ì œë¨ (í† í° ì ˆì•½: {current_tokens}/{max_tokens})")
    
    return trimmed_history


def log_token_usage(conversation_history: List[Dict[str, str]]):
    """
    í† í° ì‚¬ìš©ëŸ‰ì„ ë¡œê·¸ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    current_tokens = calculate_conversation_tokens(conversation_history)
    max_tokens = Config.get_effective_max_tokens()
    usage_percent = current_tokens/max_tokens*100
    
    print(f"ğŸ“Š í† í° ì‚¬ìš©ëŸ‰: {current_tokens}/{max_tokens} ({usage_percent:.1f}%)")
    
    # ë‹¨ê³„ë³„ ê²½ê³ 
    if usage_percent > 90:
        print("ğŸš¨ í† í° ì‚¬ìš©ëŸ‰ ìœ„í—˜! ê³§ ê³¼ê±° ë©”ì‹œì§€ê°€ ì‚­ì œë©ë‹ˆë‹¤.")
    elif usage_percent > 80:
        print("âš ï¸  í† í° ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ëŒ€í™” ê¸°ë¡ì´ ê³§ ì •ë¦¬ë  ì˜ˆì •ì…ë‹ˆë‹¤.")
    elif usage_percent > 60:
        print("ğŸ“ˆ í† í° ì‚¬ìš©ëŸ‰ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")


def apply_chat_template(conversation_history: List[Dict[str, str]], modified_message: str, system_prompt: str) -> str:
    """
    HuggingFace ìŠ¤íƒ€ì¼ Chat Templateìœ¼ë¡œ ëŒ€í™” ê¸°ë¡ì„ í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        conversation_history: ì „ì²´ ëŒ€í™” ê¸°ë¡
        modified_message: ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ (íˆ´ ì‚¬ìš©í•´ ì¶”ê°€ëœ)
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        
    Returns:
        str: Chat Template í˜•ì‹ì˜ ì „ì²´ í”„ë¡¬í”„íŠ¸
    """
    template = ""
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
    template += f"<|start_header_id|>system<|end_header_id|>\n\n{system_prompt}<|eot_id|>"
    
    # ëŒ€í™” ê¸°ë¡ ì²˜ë¦¬
    for i, item in enumerate(conversation_history):
        role = item["role"]
        if role == "user":
            role = "user"
            # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ "(íˆ´ ì‚¬ìš©í•´)" ì¶”ê°€
            content = modified_message if i == len(conversation_history) - 1 else item["content"]
        elif role == "assistant":
            role = "assistant"
            content = item["content"]
        else:
            continue
        
        template += f"<|start_header_id|>{role}<|end_header_id|>\n\n{content}<|eot_id|>"
    
    # assistant ì‘ë‹µ ì‹œì‘ í† í° ì¶”ê°€
    template += "<|start_header_id|>assistant<|end_header_id|>\n\n"
    
    return template


# =============================================================================
# LangGraph ìŠ¤íŠ¸ë¦¬ë° ìœ í‹¸ë¦¬í‹°
# =============================================================================

def random_uuid():
    return str(uuid.uuid4())


async def astream_graph(
    graph: CompiledStateGraph,
    inputs: dict,
    config: Optional[RunnableConfig] = None,
    node_names: List[str] = [],
    callback: Optional[Callable] = None,
    stream_mode: str = "messages",
    include_subgraphs: bool = False,
) -> Dict[str, Any]:
    """
    LangGraphì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ê³  ì§ì ‘ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        graph (CompiledStateGraph): ì‹¤í–‰í•  ì»´íŒŒì¼ëœ LangGraph ê°ì²´
        inputs (dict): ê·¸ë˜í”„ì— ì „ë‹¬í•  ì…ë ¥ê°’ ë”•ì…”ë„ˆë¦¬
        config (Optional[RunnableConfig]): ì‹¤í–‰ ì„¤ì • (ì„ íƒì )
        node_names (List[str], optional): ì¶œë ¥í•  ë…¸ë“œ ì´ë¦„ ëª©ë¡. ê¸°ë³¸ê°’ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        callback (Optional[Callable], optional): ê° ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜. ê¸°ë³¸ê°’ì€ None
            ì½œë°± í•¨ìˆ˜ëŠ” {"node": str, "content": Any} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.
        stream_mode (str, optional): ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ("messages" ë˜ëŠ” "updates"). ê¸°ë³¸ê°’ì€ "messages"
        include_subgraphs (bool, optional): ì„œë¸Œê·¸ë˜í”„ í¬í•¨ ì—¬ë¶€. ê¸°ë³¸ê°’ì€ False

    Returns:
        Dict[str, Any]: ìµœì¢… ê²°ê³¼ (ì„ íƒì )
    """
    config = config or {}
    final_result = {}

    def format_namespace(namespace):
        return namespace[-1].split(":")[0] if len(namespace) > 0 else "root graph"

    prev_node = ""

    if stream_mode == "messages":
        async for chunk_msg, metadata in graph.astream(
            inputs, config, stream_mode=stream_mode
        ):
            curr_node = metadata["langgraph_node"]
            final_result = {
                "node": curr_node,
                "content": chunk_msg,
                "metadata": metadata,
            }

            # node_namesê°€ ë¹„ì–´ìˆê±°ë‚˜ í˜„ì¬ ë…¸ë“œê°€ node_namesì— ìˆëŠ” ê²½ìš°ì—ë§Œ ì²˜ë¦¬
            if not node_names or curr_node in node_names:
                # ì½œë°± í•¨ìˆ˜ê°€ ìˆëŠ” ê²½ìš° ì‹¤í–‰
                if callback:
                    result = callback({"node": curr_node, "content": chunk_msg})
                    if hasattr(result, "__await__"):
                        await result
                # ì½œë°±ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶œë ¥
                else:
                    # ë…¸ë“œê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ êµ¬ë¶„ì„  ì¶œë ¥
                    if curr_node != prev_node:
                        print("\n" + "=" * 50)
                        print(f"ğŸ”„ Node: \033[1;36m{curr_node}\033[0m ğŸ”„")
                        print("- " * 25)

                    # Claude/Anthropic ëª¨ë¸ì˜ í† í° ì²­í¬ ì²˜ë¦¬ - í•­ìƒ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                    if hasattr(chunk_msg, "content"):
                        # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ content (Anthropic/Claude ìŠ¤íƒ€ì¼)
                        if isinstance(chunk_msg.content, list):
                            for item in chunk_msg.content:
                                if isinstance(item, dict) and "text" in item:
                                    print(item["text"], end="", flush=True)
                        # ë¬¸ìì—´ í˜•íƒœì˜ content
                        elif isinstance(chunk_msg.content, str):
                            print(chunk_msg.content, end="", flush=True)
                    # ê·¸ ì™¸ í˜•íƒœì˜ chunk_msg ì²˜ë¦¬
                    else:
                        print(chunk_msg, end="", flush=True)

                prev_node = curr_node

    elif stream_mode == "updates":
        # ì—ëŸ¬ ìˆ˜ì •: ì–¸íŒ¨í‚¹ ë°©ì‹ ë³€ê²½
        # REACT ì—ì´ì „íŠ¸ ë“± ì¼ë¶€ ê·¸ë˜í”„ì—ì„œëŠ” ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ë§Œ ë°˜í™˜í•¨
        async for chunk in graph.astream(
            inputs, config, stream_mode=stream_mode, subgraphs=include_subgraphs
        ):
            # ë°˜í™˜ í˜•ì‹ì— ë”°ë¼ ì²˜ë¦¬ ë°©ë²• ë¶„ê¸°
            if isinstance(chunk, tuple) and len(chunk) == 2:
                # ê¸°ì¡´ ì˜ˆìƒ í˜•ì‹: (namespace, chunk_dict)
                namespace, node_chunks = chunk
            else:
                # ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ë§Œ ë°˜í™˜í•˜ëŠ” ê²½ìš° (REACT ì—ì´ì „íŠ¸ ë“±)
                namespace = []  # ë¹ˆ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ (ë£¨íŠ¸ ê·¸ë˜í”„)
                node_chunks = chunk  # chunk ìì²´ê°€ ë…¸ë“œ ì²­í¬ ë”•ì…”ë„ˆë¦¬

            # ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸í•˜ê³  í•­ëª© ì²˜ë¦¬
            if isinstance(node_chunks, dict):
                for node_name, node_chunk in node_chunks.items():
                    final_result = {
                        "node": node_name,
                        "content": node_chunk,
                        "namespace": namespace,
                    }

                    # node_namesê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ í•„í„°ë§
                    if len(node_names) > 0 and node_name not in node_names:
                        continue

                    # ì½œë°± í•¨ìˆ˜ê°€ ìˆëŠ” ê²½ìš° ì‹¤í–‰
                    if callback is not None:
                        result = callback({"node": node_name, "content": node_chunk})
                        if hasattr(result, "__await__"):
                            await result
                    # ì½œë°±ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶œë ¥
                    else:
                        # ë…¸ë“œê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ êµ¬ë¶„ì„  ì¶œë ¥ (messages ëª¨ë“œì™€ ë™ì¼í•˜ê²Œ)
                        if node_name != prev_node:
                            print("\n" + "=" * 50)
                            print(f"ğŸ”„ Node: \033[1;36m{node_name}\033[0m ğŸ”„")
                            print("- " * 25)

                        # ë…¸ë“œì˜ ì²­í¬ ë°ì´í„° ì¶œë ¥ - í…ìŠ¤íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ ì²˜ë¦¬
                        if isinstance(node_chunk, dict):
                            for k, v in node_chunk.items():
                                if isinstance(v, BaseMessage):
                                    # BaseMessageì˜ content ì†ì„±ì´ í…ìŠ¤íŠ¸ë‚˜ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°ë¥¼ ì²˜ë¦¬
                                    if hasattr(v, "content"):
                                        if isinstance(v.content, list):
                                            for item in v.content:
                                                if (
                                                    isinstance(item, dict)
                                                    and "text" in item
                                                ):
                                                    print(
                                                        item["text"], end="", flush=True
                                                    )
                                        else:
                                            print(v.content, end="", flush=True)
                                    else:
                                        v.pretty_print()
                                elif isinstance(v, list):
                                    for list_item in v:
                                        if isinstance(list_item, BaseMessage):
                                            if hasattr(list_item, "content"):
                                                if isinstance(list_item.content, list):
                                                    for item in list_item.content:
                                                        if (
                                                            isinstance(item, dict)
                                                            and "text" in item
                                                        ):
                                                            print(
                                                                item["text"],
                                                                end="",
                                                                flush=True,
                                                            )
                                                else:
                                                    print(
                                                        list_item.content,
                                                        end="",
                                                        flush=True,
                                                    )
                                            else:
                                                list_item.pretty_print()
                                        elif (
                                            isinstance(list_item, dict)
                                            and "text" in list_item
                                        ):
                                            print(list_item["text"], end="", flush=True)
                                        else:
                                            print(list_item, end="", flush=True)
                                elif isinstance(v, dict) and "text" in v:
                                    print(v["text"], end="", flush=True)
                                else:
                                    print(v, end="", flush=True)
                        elif node_chunk is not None:
                            if hasattr(node_chunk, "__iter__") and not isinstance(
                                node_chunk, str
                            ):
                                for item in node_chunk:
                                    if isinstance(item, dict) and "text" in item:
                                        print(item["text"], end="", flush=True)
                                    else:
                                        print(item, end="", flush=True)
                            else:
                                print(node_chunk, end="", flush=True)

                        # êµ¬ë¶„ì„ ì„ ì—¬ê¸°ì„œ ì¶œë ¥í•˜ì§€ ì•ŠìŒ (messages ëª¨ë“œì™€ ë™ì¼í•˜ê²Œ)

                    prev_node = node_name
            else:
                # ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš° ì „ì²´ ì²­í¬ ì¶œë ¥
                print("\n" + "=" * 50)
                print(f"ğŸ”„ Raw output ğŸ”„")
                print("- " * 25)
                print(node_chunks, end="", flush=True)
                # êµ¬ë¶„ì„ ì„ ì—¬ê¸°ì„œ ì¶œë ¥í•˜ì§€ ì•ŠìŒ
                final_result = {"content": node_chunks}

    else:
        raise ValueError(
            f"Invalid stream_mode: {stream_mode}. Must be 'messages' or 'updates'."
        )

    # í•„ìš”ì— ë”°ë¼ ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return final_result

async def ainvoke_graph(
    graph: CompiledStateGraph,
    inputs: dict,
    config: Optional[RunnableConfig] = None,
    node_names: List[str] = [],
    callback: Optional[Callable] = None,
    include_subgraphs: bool = True,
) -> Dict[str, Any]:
    """
    LangGraph ì•±ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        graph (CompiledStateGraph): ì‹¤í–‰í•  ì»´íŒŒì¼ëœ LangGraph ê°ì²´
        inputs (dict): ê·¸ë˜í”„ì— ì „ë‹¬í•  ì…ë ¥ê°’ ë”•ì…”ë„ˆë¦¬
        config (Optional[RunnableConfig]): ì‹¤í–‰ ì„¤ì • (ì„ íƒì )
        node_names (List[str], optional): ì¶œë ¥í•  ë…¸ë“œ ì´ë¦„ ëª©ë¡. ê¸°ë³¸ê°’ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        callback (Optional[Callable], optional): ê° ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜. ê¸°ë³¸ê°’ì€ None
            ì½œë°± í•¨ìˆ˜ëŠ” {"node": str, "content": Any} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.
        include_subgraphs (bool, optional): ì„œë¸Œê·¸ë˜í”„ í¬í•¨ ì—¬ë¶€. ê¸°ë³¸ê°’ì€ True

    Returns:
        Dict[str, Any]: ìµœì¢… ê²°ê³¼ (ë§ˆì§€ë§‰ ë…¸ë“œì˜ ì¶œë ¥)
    """
    config = config or {}
    final_result = {}

    def format_namespace(namespace):
        return namespace[-1].split(":")[0] if len(namespace) > 0 else "root graph"

    # subgraphs ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ ì„œë¸Œê·¸ë˜í”„ì˜ ì¶œë ¥ë„ í¬í•¨
    async for chunk in graph.astream(
        inputs, config, stream_mode="updates", subgraphs=include_subgraphs
    ):
        # ë°˜í™˜ í˜•ì‹ì— ë”°ë¼ ì²˜ë¦¬ ë°©ë²• ë¶„ê¸°
        if isinstance(chunk, tuple) and len(chunk) == 2:
            # ê¸°ì¡´ ì˜ˆìƒ í˜•ì‹: (namespace, chunk_dict)
            namespace, node_chunks = chunk
        else:
            # ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ë§Œ ë°˜í™˜í•˜ëŠ” ê²½ìš° (REACT ì—ì´ì „íŠ¸ ë“±)
            namespace = []  # ë¹ˆ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ (ë£¨íŠ¸ ê·¸ë˜í”„)
            node_chunks = chunk  # chunk ìì²´ê°€ ë…¸ë“œ ì²­í¬ ë”•ì…”ë„ˆë¦¬

        # ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸í•˜ê³  í•­ëª© ì²˜ë¦¬
        if isinstance(node_chunks, dict):
            for node_name, node_chunk in node_chunks.items():
                final_result = {
                    "node": node_name,
                    "content": node_chunk,
                    "namespace": namespace,
                }

                # node_namesê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ í•„í„°ë§
                if node_names and node_name not in node_names:
                    continue

                # ì½œë°± í•¨ìˆ˜ê°€ ìˆëŠ” ê²½ìš° ì‹¤í–‰
                if callback is not None:
                    result = callback({"node": node_name, "content": node_chunk})
                    # ì½”ë£¨í‹´ì¸ ê²½ìš° await
                    if hasattr(result, "__await__"):
                        await result
                # ì½œë°±ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶œë ¥
                else:
                    print("\n" + "=" * 50)
                    formatted_namespace = format_namespace(namespace)
                    if formatted_namespace == "root graph":
                        print(f"ğŸ”„ Node: \033[1;36m{node_name}\033[0m ğŸ”„")
                    else:
                        print(
                            f"ğŸ”„ Node: \033[1;36m{node_name}\033[0m in [\033[1;33m{formatted_namespace}\033[0m] ğŸ”„"
                        )
                    print("- " * 25)

                    # ë…¸ë“œì˜ ì²­í¬ ë°ì´í„° ì¶œë ¥
                    if isinstance(node_chunk, dict):
                        for k, v in node_chunk.items():
                            if isinstance(v, BaseMessage):
                                v.pretty_print()
                            elif isinstance(v, list):
                                for list_item in v:
                                    if isinstance(list_item, BaseMessage):
                                        list_item.pretty_print()
                                    else:
                                        print(list_item)
                            elif isinstance(v, dict):
                                for node_chunk_key, node_chunk_value in v.items():
                                    print(f"{node_chunk_key}:\n{node_chunk_value}")
                            else:
                                print(f"\033[1;32m{k}\033[0m:\n{v}")
                    elif node_chunk is not None:
                        if hasattr(node_chunk, "__iter__") and not isinstance(
                            node_chunk, str
                        ):
                            for item in node_chunk:
                                print(item)
                        else:
                            print(node_chunk)
                    print("=" * 50)
        else:
            # ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš° ì „ì²´ ì²­í¬ ì¶œë ¥
            print("\n" + "=" * 50)
            print(f"ğŸ”„ Raw output ğŸ”„")
            print("- " * 25)
            print(node_chunks)
            print("=" * 50)
            final_result = {"content": node_chunks}

    # ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return final_result
